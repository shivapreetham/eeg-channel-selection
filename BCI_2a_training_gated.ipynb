{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI 2a Gated EEG-ARNN Pipeline\n",
    "\n",
    "Subject-specific gated EEG-ARNN training on the BCI Competition IV 2a dataset:\n",
    "- Gated channel selection with per-subject 3-fold cross-validation (20 epochs)\n",
    "- Same model architecture and training utilities as the PhysioNet pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mne\n",
    "\n",
    "# IMPORTANT: Force reload train_utils to get latest fixes\n",
    "import importlib\n",
    "import train_utils\n",
    "importlib.reload(train_utils)\n",
    "\n",
    "from models import EEGARNN, ChannelSelector\n",
    "from train_utils import (\n",
    "    load_preprocessed_data, filter_classes, normalize_data,\n",
    "    cross_validate_subject, EEGDataset\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('ERROR')\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Verify the fix is loaded\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION: Checking if train_utils.py fix is loaded...\")\n",
    "print(\"=\"*80)\n",
    "import inspect\n",
    "source = inspect.getsource(load_preprocessed_data)\n",
    "if 'events_from_annotations' in source:\n",
    "    print(\"✓ GOOD: train_utils.py has the annotations fix!\")\n",
    "else:\n",
    "    print(\"✗ ERROR: train_utils.py is still using old code!\")\n",
    "    print(\"  → Please restart Jupyter kernel: Kernel → Restart Kernel\")\n",
    "    print(\"  → Then re-run all cells from the top\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_CONFIG = {\n",
    "    'data': {\n",
    "        'raw_dir': Path('data/BCI_2a'),\n",
    "        'subjects': [f'A0{i}' for i in range(1, 10)],\n",
    "        'selected_classes': [769, 770, 771, 772],\n",
    "        'tmin': 0.0,\n",
    "        'tmax': 4.0,\n",
    "        'baseline': None\n",
    "    },\n",
    "    'model': {\n",
    "        'hidden_dim': 40,\n",
    "        'epochs': 20,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32,\n",
    "        'n_folds': 3,\n",
    "        'patience': 8\n",
    "    },\n",
    "    'gating': {\n",
    "        'enabled': True,\n",
    "        'l1_lambda': 1e-3,\n",
    "        'gate_init': 0.9\n",
    "    },\n",
    "    'channel_selection': {\n",
    "        'k_values': [10, 15, 20, 25, 'all'],\n",
    "        'methods': ['ES', 'AS']\n",
    "    },\n",
    "    'output': {\n",
    "        'results_dir': Path('results/bci_2a'),\n",
    "        'models_dir': Path('saved_models/bci_2a'),\n",
    "        'gated_results_file': 'bci2a_gated_subject_results.csv',\n",
    "        'gate_importance_file': 'bci2a_gate_importances.csv',\n",
    "        'channel_selection_results_file': 'bci2a_channel_selection_results.csv',\n",
    "        'retrain_results_file': 'bci2a_retrain_results.csv',\n",
    "        'baseline_results_file': 'bci2a_baseline_subject_results.csv',\n",
    "        'comparison_file': 'bci2a_gated_vs_baseline.csv',\n",
    "        'results_summary_figure': 'bci2a_gated_results_summary.png',\n",
    "        'adjacency_prefix': 'bci2a_adjacency',\n",
    "        'config_file': 'bci2a_gated_experiment_config.json'\n",
    "    },\n",
    "    'max_subjects': None\n",
    "}\n",
    "\n",
    "EXPERIMENT_CONFIG['output']['results_dir'].mkdir(parents=True, exist_ok=True)\n",
    "EXPERIMENT_CONFIG['output']['models_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Experiment Configuration:')\n",
    "print(json.dumps(EXPERIMENT_CONFIG, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a2240",
   "metadata": {},
   "source": [
    "## Gated Model Utilities\n",
    "\n",
    "Learnable channel gates with L1 sparsity regularization for trial 4 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utilities for models with learnable channel gates\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def _init_gate_logits(num_channels: int, gate_init: float) -> torch.Tensor:\n",
    "    init = torch.full((num_channels,), float(gate_init), dtype=torch.float32)\n",
    "    init = torch.clamp(init, 1e-4, 1 - 1e-4)\n",
    "    return torch.logit(init)\n",
    "\n",
    "\n",
    "class GatedEEGARNN(EEGARNN):\n",
    "    '''EEG-ARNN variant with learnable channel gates.'''\n",
    "    def __init__(self, num_channels=64, num_timepoints=512, num_classes=4, hidden_dim=40, gate_init=0.9):\n",
    "        super().__init__(\n",
    "            num_channels=num_channels,\n",
    "            num_timepoints=num_timepoints,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dim=hidden_dim\n",
    "        )\n",
    "        gate_logits = _init_gate_logits(num_channels, gate_init)\n",
    "        self.gate_logits = nn.Parameter(gate_logits)\n",
    "        self.latest_gates = None\n",
    "\n",
    "    def get_gate_values(self):\n",
    "        return torch.sigmoid(self.gate_logits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_values = torch.sigmoid(self.gate_logits)\n",
    "        self.latest_gates = gate_values.detach().cpu()\n",
    "        x = x * gate_values.view(1, 1, -1, 1)\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "def train_epoch_with_gates(model, dataloader, criterion, optimizer, device, l1_lambda=0.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    gate_penalties, gate_means = [], []\n",
    "\n",
    "    for data, labels in dataloader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if l1_lambda > 0 and hasattr(model, 'get_gate_values'):\n",
    "            gate_values = model.get_gate_values()\n",
    "            gate_penalty = l1_lambda * gate_values.abs().mean()\n",
    "            loss = loss + gate_penalty\n",
    "            gate_penalties.append(gate_penalty.item())\n",
    "            gate_means.append(gate_values.mean().item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / max(len(dataloader), 1)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_penalty = float(np.mean(gate_penalties)) if gate_penalties else 0.0\n",
    "    avg_gate_mean = float(np.mean(gate_means)) if gate_means else 0.0\n",
    "\n",
    "    return avg_loss, accuracy, avg_penalty, avg_gate_mean\n",
    "\n",
    "\n",
    "def train_model_with_gates(model, train_loader, val_loader, device, epochs=100, lr=0.001,\n",
    "                           patience=10, l1_lambda=0.0):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=False\n",
    "    )\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'gate_penalty': [],\n",
    "        'gate_mean': []\n",
    "    }\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = deepcopy(model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc, gate_penalty, gate_mean = train_epoch_with_gates(\n",
    "            model, train_loader, criterion, optimizer, device, l1_lambda=l1_lambda\n",
    "        )\n",
    "        val_loss, val_acc, _, _ = train_utils.evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['gate_penalty'].append(gate_penalty)\n",
    "        history['gate_mean'].append(gate_mean)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"    Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return history, best_model_state\n",
    "\n",
    "\n",
    "def cross_validate_subject_with_gates(\n",
    "    data, labels, num_channels, num_timepoints, num_classes,\n",
    "    device, n_splits=3, epochs=30, lr=0.001, batch_size=64, patience=8,\n",
    "    l1_lambda=0.0, gate_init=0.9\n",
    "):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_results = []\n",
    "    adjacency_matrices = []\n",
    "    gate_values_per_fold = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(data, labels)):\n",
    "        print(f\"  Fold {fold + 1}/{n_splits}\", end=\" \", flush=True)\n",
    "\n",
    "        X_train, X_val = data[train_idx], data[val_idx]\n",
    "        y_train, y_val = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        X_train = train_utils.normalize_data(X_train)\n",
    "        X_val = train_utils.normalize_data(X_val)\n",
    "\n",
    "        train_dataset = train_utils.EEGDataset(X_train, y_train)\n",
    "        val_dataset = train_utils.EEGDataset(X_val, y_val)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        model = GatedEEGARNN(\n",
    "            num_channels=num_channels,\n",
    "            num_timepoints=num_timepoints,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dim=EXPERIMENT_CONFIG['model']['hidden_dim'],\n",
    "            gate_init=gate_init\n",
    "        ).to(device)\n",
    "\n",
    "        history, best_state = train_model_with_gates(\n",
    "            model, train_loader, val_loader, device,\n",
    "            epochs=epochs, lr=lr, patience=patience, l1_lambda=l1_lambda\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "        _, val_acc, val_preds, val_labels = train_utils.evaluate(\n",
    "            model, val_loader, nn.CrossEntropyLoss(), device\n",
    "        )\n",
    "\n",
    "        adj_matrix = model.get_final_adjacency_matrix()\n",
    "        adjacency_matrices.append(adj_matrix)\n",
    "\n",
    "        gate_values = model.get_gate_values().detach().cpu().numpy()\n",
    "        gate_values_per_fold.append(gate_values)\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'val_acc': val_acc,\n",
    "            'history': history,\n",
    "            'gate_mean': float(gate_values.mean()),\n",
    "            'gate_std': float(gate_values.std()),\n",
    "            'preds': val_preds,\n",
    "            'labels': val_labels\n",
    "        })\n",
    "\n",
    "        print(f\"-> Acc: {val_acc:.3f}\")\n",
    "\n",
    "    avg_adjacency = np.mean(adjacency_matrices, axis=0)\n",
    "    avg_gate_values = np.mean(np.stack(gate_values_per_fold, axis=0), axis=0)\n",
    "\n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'avg_accuracy': np.mean([r['val_acc'] for r in fold_results]),\n",
    "        'std_accuracy': np.std([r['val_acc'] for r in fold_results]),\n",
    "        'adjacency_matrix': avg_adjacency,\n",
    "        'gate_values_per_fold': gate_values_per_fold,\n",
    "        'avg_gate_values': avg_gate_values\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build BCI 2a Session Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = EXPERIMENT_CONFIG['data']['raw_dir']\n",
    "selected_classes = EXPERIMENT_CONFIG['data']['selected_classes']\n",
    "\n",
    "records = []\n",
    "missing_subjects = []\n",
    "\n",
    "for subject_id in EXPERIMENT_CONFIG['data']['subjects']:\n",
    "    gdf_path = raw_dir / f\"{subject_id}T.gdf\"\n",
    "    if not gdf_path.exists():\n",
    "        missing_subjects.append(subject_id)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        raw = mne.io.read_raw_gdf(gdf_path, preload=False, verbose='ERROR')\n",
    "        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        selected_event_ids = [event_ids[str(cls)] for cls in selected_classes if str(cls) in event_ids]\n",
    "        trial_mask = np.isin(events[:, 2], selected_event_ids) if selected_event_ids else np.array([])\n",
    "        num_trials = int(trial_mask.sum()) if trial_mask.size else 0\n",
    "    except Exception as exc:\n",
    "        print(f\"[warn] Could not parse {gdf_path.name}: {exc}\")\n",
    "        num_trials = 0\n",
    "\n",
    "    records.append({\n",
    "        'subject': subject_id,\n",
    "        'session': 'T',\n",
    "        'path': gdf_path,\n",
    "        'num_trials': num_trials\n",
    "    })\n",
    "\n",
    "bci_sessions = pd.DataFrame(records)\n",
    "motor_runs = bci_sessions[bci_sessions['num_trials'] > 0].copy()\n",
    "\n",
    "print(f\"Total subjects configured: {len(EXPERIMENT_CONFIG['data']['subjects'])}\")\n",
    "print(f\"Subjects with labelled training data: {motor_runs['subject'].nunique()}\")\n",
    "print(f\"Total labelled trials: {int(motor_runs['num_trials'].sum())}\")\n",
    "\n",
    "if missing_subjects:\n",
    "    print('Missing training files for subjects:', missing_subjects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_counts = (motor_runs.groupby('subject')['num_trials']\n",
    "                  .sum()\n",
    "                  .reset_index()\n",
    "                  .sort_values('subject'))\n",
    "\n",
    "selected_subjects = subject_counts['subject'].tolist()\n",
    "\n",
    "if not selected_subjects:\n",
    "    raise RuntimeError('No BCI 2a subjects with labelled trials were found.')\n",
    "\n",
    "max_subjects = EXPERIMENT_CONFIG.get('max_subjects')\n",
    "if max_subjects:\n",
    "    selected_subjects = selected_subjects[:max_subjects]\n",
    "    subject_counts = subject_counts[subject_counts['subject'].isin(selected_subjects)]\n",
    "\n",
    "print('Subject trial counts:')\n",
    "print(subject_counts.to_string(index=False))\n",
    "print(f\"\n",
    "Will train on {len(selected_subjects)} subjects\")\n",
    "print(f\"Selected subjects: {selected_subjects}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_data(subject_id, subject_sessions_df, config):\n",
    "    '''\n",
    "    Load all labelled motor imagery trials for a BCI 2a subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray or None\n",
    "        (n_trials, n_channels, n_timepoints)\n",
    "    labels : np.ndarray or None\n",
    "        (n_trials,)\n",
    "    channel_names : list[str] or None\n",
    "        Channel labels preserved from the recording\n",
    "    '''\n",
    "    subject_rows = subject_sessions_df[subject_sessions_df['subject'] == subject_id]\n",
    "\n",
    "    if subject_rows.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    selected_classes = config['data']['selected_classes']\n",
    "\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    channel_names = None\n",
    "\n",
    "    for _, row in subject_rows.iterrows():\n",
    "        gdf_path = Path(row['path'])\n",
    "        if not gdf_path.exists():\n",
    "            print(f\"[warn] Missing file: {gdf_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_gdf(gdf_path, preload=True, verbose='ERROR')\n",
    "            events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "            selected_event_ids = {str(cls): event_ids[str(cls)] for cls in selected_classes if str(cls) in event_ids}\n",
    "            if not selected_event_ids:\n",
    "                print(f\"[warn] No target events found in {gdf_path.name}\")\n",
    "                continue\n",
    "\n",
    "            epochs = mne.Epochs(\n",
    "                raw,\n",
    "                events,\n",
    "                event_id=selected_event_ids,\n",
    "                tmin=config['data']['tmin'],\n",
    "                tmax=config['data']['tmax'],\n",
    "                baseline=config['data']['baseline'],\n",
    "                preload=True,\n",
    "                event_repeated='merge',\n",
    "                picks='eeg',\n",
    "                verbose='ERROR'\n",
    "            )\n",
    "\n",
    "            data = epochs.get_data()\n",
    "            label_lookup = {event_ids[key]: int(key) for key in selected_event_ids}\n",
    "            labels = np.array([label_lookup[event_code] for event_code in epochs.events[:, 2]])\n",
    "\n",
    "            data, labels = filter_classes(data, labels, selected_classes)\n",
    "\n",
    "            if data.size == 0:\n",
    "                continue\n",
    "\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "            if channel_names is None:\n",
    "                channel_names = epochs.ch_names\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(f\"[warn] Failed to load {gdf_path.name}: {exc}\")\n",
    "            continue\n",
    "\n",
    "    if not all_data:\n",
    "        return None, None, None\n",
    "\n",
    "    data = np.concatenate(all_data, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return data, labels, channel_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "Train subject-specific models with 3-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_results = []\n",
    "gate_analysis_records = []\n",
    "\n",
    "for subject_id in tqdm(selected_subjects, desc='Training subjects (gated)'):\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training subject: {subject_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data, labels, channel_names = load_subject_data(\n",
    "        subject_id,\n",
    "        motor_runs,\n",
    "        EXPERIMENT_CONFIG\n",
    "    )\n",
    "\n",
    "    if data is None or len(data) < 30:\n",
    "        print(f\"Skipping {subject_id}: insufficient data\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(f\"Labels: {np.unique(labels, return_counts=True)}\")\n",
    "    print(f\"Channels: {len(channel_names)}\")\n",
    "\n",
    "    num_channels = data.shape[1]\n",
    "    num_timepoints = data.shape[2]\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    model_cfg = EXPERIMENT_CONFIG['model']\n",
    "    gating_cfg = EXPERIMENT_CONFIG.get('gating', {})\n",
    "\n",
    "    cv_results = cross_validate_subject_with_gates(\n",
    "        data, labels,\n",
    "        num_channels=num_channels,\n",
    "        num_timepoints=num_timepoints,\n",
    "        num_classes=num_classes,\n",
    "        device=device,\n",
    "        n_splits=model_cfg['n_folds'],\n",
    "        epochs=model_cfg['epochs'],\n",
    "        lr=model_cfg['learning_rate'],\n",
    "        batch_size=model_cfg['batch_size'],\n",
    "        patience=model_cfg.get('patience', 8),\n",
    "        l1_lambda=gating_cfg.get('l1_lambda', 0.0),\n",
    "        gate_init=gating_cfg.get('gate_init', 0.9)\n",
    "    )\n",
    "\n",
    "    gate_values = cv_results['avg_gate_values']\n",
    "    gate_stats = {\n",
    "        'mean': float(gate_values.mean()),\n",
    "        'std': float(gate_values.std()),\n",
    "        'min': float(gate_values.min()),\n",
    "        'max': float(gate_values.max())\n",
    "    }\n",
    "\n",
    "    print(f\"Gated accuracy: {cv_results['avg_accuracy']:.4f} +/- {cv_results['std_accuracy']:.4f}\")\n",
    "    print(f\"Gate mean: {gate_stats['mean']:.4f} | min: {gate_stats['min']:.4f} | max: {gate_stats['max']:.4f}\")\n",
    "\n",
    "    result = {\n",
    "        'subject': subject_id,\n",
    "        'num_trials': int(len(data)),\n",
    "        'num_channels': int(num_channels),\n",
    "        'num_timepoints': int(num_timepoints),\n",
    "        'num_classes': int(num_classes),\n",
    "        'gated_acc': float(cv_results['avg_accuracy']),\n",
    "        'gated_std': float(cv_results['std_accuracy']),\n",
    "        'adjacency_matrix': cv_results['adjacency_matrix'],\n",
    "        'channel_names': channel_names,\n",
    "        'gate_values': gate_values.tolist(),\n",
    "        'gate_values_per_fold': [gv.tolist() for gv in cv_results['gate_values_per_fold']],\n",
    "        'gate_mean': gate_stats['mean'],\n",
    "        'gate_std': gate_stats['std'],\n",
    "        'gate_min': gate_stats['min'],\n",
    "        'gate_max': gate_stats['max'],\n",
    "        'fold_results': cv_results['fold_results']\n",
    "    }\n",
    "\n",
    "    all_results.append(result)\n",
    "\n",
    "    for channel_name, gate_value in zip(channel_names, gate_values):\n",
    "        gate_analysis_records.append({\n",
    "            'subject': subject_id,\n",
    "            'channel': channel_name,\n",
    "            'gate_value': float(gate_value)\n",
    "        })\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Training complete for {len(all_results)} subjects\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802a342",
   "metadata": {},
   "source": [
    "## Channel Gate Analysis\n",
    "\n",
    "Aggregate the learned gate strengths across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8af767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gate_importance_df = pd.DataFrame(gate_analysis_records)\n",
    "\n",
    "if len(gate_importance_df) > 0:\n",
    "    subject_gate_summary = gate_importance_df.groupby('subject')['gate_value'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "    print('Per-subject gate statistics:')\n",
    "    display(subject_gate_summary)\n",
    "\n",
    "    channel_gate_summary = (\n",
    "        gate_importance_df.groupby('channel')['gate_value']\n",
    "        .agg(['mean', 'std'])\n",
    "        .sort_values('mean', ascending=False)\n",
    "    )\n",
    "    print('Top channels by mean gate value:')\n",
    "    display(channel_gate_summary.head(15))\n",
    "\n",
    "    gate_importance_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['gate_importance_file']\n",
    "    channel_gate_summary.reset_index().to_csv(gate_importance_path, index=False)\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Gate importance saved to: {gate_importance_path}\")\n",
    "\n",
    "    channel_gate_summary_df = channel_gate_summary.reset_index()\n",
    "else:\n",
    "    print('No gate values recorded. Ensure training ran successfully.')\n",
    "    channel_gate_summary_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Selection Experiments\n",
    "\n",
    "Test different k values with Edge Selection and Aggregation Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_selection_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    for result in tqdm(all_results, desc=\"Channel selection experiments\"):\n",
    "        subject_id = result['subject']\n",
    "        adj_matrix = result['adjacency_matrix']\n",
    "        channel_names = result['channel_names']\n",
    "        \n",
    "        print(f\"\\nProcessing channel selection for {subject_id}\")\n",
    "        \n",
    "        selector = ChannelSelector(adj_matrix, channel_names)\n",
    "        \n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            print(f\"  Method: {method}\")\n",
    "            \n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    k_val = result['num_channels']\n",
    "                    selected_channels = channel_names\n",
    "                else:\n",
    "                    k_val = min(k, result['num_channels'])  # Don't exceed available channels\n",
    "                    \n",
    "                    if method == 'ES':\n",
    "                        selected_channels, _ = selector.edge_selection(k_val)\n",
    "                    else:  # AS\n",
    "                        selected_channels, _ = selector.aggregation_selection(k_val)\n",
    "                \n",
    "                print(f\"    k={k_val}: {len(selected_channels)} channels selected\")\n",
    "                \n",
    "                channel_selection_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy_full': result['gated_acc']\n",
    "                })\n",
    "\n",
    "    channel_selection_df = pd.DataFrame(channel_selection_results)\n",
    "    print(f\"\\nChannel selection results: {len(channel_selection_df)} experiments\")\n",
    "    display(channel_selection_df.head(10))\n",
    "else:\n",
    "    channel_selection_df = pd.DataFrame()\n",
    "    print(\"\\nNo results available for channel selection experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from train_utils import retrain_with_selected_channels\n",
    "\n",
    "# Store all retraining results\n",
    "retrain_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    subject_data_cache = {}\n",
    "\n",
    "    for result in all_results:\n",
    "        subject_id = result['subject']\n",
    "        print(f\"Loading data for {subject_id}\")\n",
    "\n",
    "        data, labels, channel_names = load_subject_data(\n",
    "            subject_id,\n",
    "            motor_runs,\n",
    "            EXPERIMENT_CONFIG\n",
    "        )\n",
    "\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        subject_data_cache[subject_id] = {\n",
    "            'data': data,\n",
    "            'labels': labels,\n",
    "            'channel_names': channel_names\n",
    "        }\n",
    "\n",
    "    print(f\"{'='*80}\")\n",
    "    print('RETRAINING WITH SELECTED CHANNELS')\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    for result in tqdm(all_results, desc='Retraining subjects'):\n",
    "        subject_id = result['subject']\n",
    "\n",
    "        if subject_id not in subject_data_cache:\n",
    "            continue\n",
    "\n",
    "        cache = subject_data_cache[subject_id]\n",
    "        data = cache['data']\n",
    "        labels = cache['labels']\n",
    "        channel_names = cache['channel_names']\n",
    "\n",
    "        print(f\"Retraining {subject_id}\")\n",
    "\n",
    "        selector = ChannelSelector(result['adjacency_matrix'], channel_names)\n",
    "\n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    continue\n",
    "\n",
    "                k_val = min(k, result['num_channels'])\n",
    "\n",
    "                if method == 'ES':\n",
    "                    selected_channels, selected_indices = selector.edge_selection(k_val)\n",
    "                else:\n",
    "                    selected_channels, selected_indices = selector.aggregation_selection(k_val)\n",
    "\n",
    "                print(f\"  {method} k={k_val}: Retraining with {len(selected_channels)} channels...\")\n",
    "\n",
    "                retrain_res = retrain_with_selected_channels(\n",
    "                    data, labels,\n",
    "                    selected_channel_indices=selected_indices,\n",
    "                    num_timepoints=result['num_timepoints'],\n",
    "                    num_classes=result['num_classes'],\n",
    "                    device=device,\n",
    "                    n_splits=EXPERIMENT_CONFIG['model']['n_folds'],\n",
    "                    epochs=EXPERIMENT_CONFIG['model']['epochs'],\n",
    "                    lr=EXPERIMENT_CONFIG['model']['learning_rate']\n",
    "                )\n",
    "\n",
    "                acc_drop = result['gated_acc'] - retrain_res['avg_accuracy']\n",
    "\n",
    "                print(f\"    Accuracy: {retrain_res['avg_accuracy']:.4f} +/- {retrain_res['std_accuracy']:.4f}\")\n",
    "                print(f\"    Drop from full: {acc_drop:.4f} ({acc_drop/result['gated_acc']*100:.1f}%)\")\n",
    "\n",
    "                retrain_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_channels_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy': retrain_res['avg_accuracy'],\n",
    "                    'std': retrain_res['std_accuracy'],\n",
    "                    'full_channels_acc': result['gated_acc'],\n",
    "                    'accuracy_drop': acc_drop,\n",
    "                    'accuracy_drop_pct': acc_drop / result['gated_acc'] * 100\n",
    "                })\n",
    "\n",
    "    retrain_df = pd.DataFrame(retrain_results)\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f'Retraining complete: {len(retrain_df)} experiments')\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    retrain_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['retrain_results_file']\n",
    "    retrain_df.to_csv(retrain_path, index=False)\n",
    "    print(f\"Retrain results saved to: {retrain_path}\")\n",
    "else:\n",
    "    retrain_df = pd.DataFrame()\n",
    "    print('No results to retrain. Please run training first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain with Selected Channels\n",
    "\n",
    "Now retrain the model using ONLY the selected channels and compare accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OVERALL RESULTS SUMMARY (Gated Model)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Subjects trained: {len(results_df)}\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"Mean gated accuracy: {results_df['gated_acc'].mean():.4f} +/- {results_df['gated_acc'].std():.4f}\")\n",
    "    print(f\"Best subject: {results_df.loc[results_df['gated_acc'].idxmax(), 'subject']} ({results_df['gated_acc'].max():.4f})\")\n",
    "    print(f\"Worst subject: {results_df.loc[results_df['gated_acc'].idxmin(), 'subject']} ({results_df['gated_acc'].min():.4f})\")\n",
    "\n",
    "    results_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['gated_results_file']\n",
    "    cols_to_save = ['subject', 'num_trials', 'num_channels', 'gated_acc', 'gated_std', 'gate_mean', 'gate_std', 'gate_min', 'gate_max']\n",
    "    results_df[cols_to_save].to_csv(results_path, index=False)\n",
    "    print(f\"Results saved to: {results_path}\")\n",
    "\n",
    "    display(results_df[cols_to_save].head(10))\n",
    "else:\n",
    "    print(\"No subjects were successfully trained. Check the data loading and preprocessing steps.\")\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axes[0, 0].hist(results_df['gated_acc'], bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(results_df['gated_acc'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 0].set_title('Accuracy Distribution (Gated Model)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Accuracy')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0, 1].scatter(results_df['num_trials'], results_df['gated_acc'], alpha=0.6, s=100)\n",
    "    axes[0, 1].set_title('Accuracy vs Number of Trials', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Number of Trials')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    top_10 = results_df.nlargest(min(10, len(results_df)), 'gated_acc')\n",
    "    axes[1, 0].barh(range(len(top_10)), top_10['gated_acc'], color='green', alpha=0.7)\n",
    "    axes[1, 0].set_yticks(range(len(top_10)))\n",
    "    axes[1, 0].set_yticklabels(top_10['subject'])\n",
    "    axes[1, 0].set_title(f'Top {len(top_10)} Subjects by Gated Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Accuracy')\n",
    "    axes[1, 0].invert_yaxis()\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "    sorted_results = results_df.sort_values('gated_acc')\n",
    "    axes[1, 1].plot(range(len(sorted_results)), sorted_results['gated_acc'], marker='o', markersize=4, alpha=0.6)\n",
    "    axes[1, 1].set_title('Subject Ranking (Gated Accuracy)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Rank')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    summary_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['results_summary_figure']\n",
    "    plt.savefig(summary_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Visualizations saved to: {summary_path}\")\n",
    "else:\n",
    "    print('No results to visualize. Please ensure subjects were successfully trained.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Adjacency Matrix (Example Subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(all_results) > 0:\n",
    "    best_idx = results_df['gated_acc'].idxmax()\n",
    "    best_result = all_results[best_idx]\n",
    "\n",
    "    print(f\"Visualizing adjacency matrix for best subject: {best_result['subject']}\")\n",
    "    print(f\"Accuracy: {best_result['gated_acc']:.4f}\")\n",
    "\n",
    "    selector = ChannelSelector(best_result['adjacency_matrix'], best_result['channel_names'])\n",
    "\n",
    "    adj_path = EXPERIMENT_CONFIG['output']['results_dir'] / f\"{EXPERIMENT_CONFIG['output']['adjacency_prefix']}_{best_result['subject']}.png\"\n",
    "    fig = selector.visualize_adjacency(save_path=adj_path)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Adjacency figure saved to: {adj_path}\")\n",
    "\n",
    "    print(\"Top 10 Edges (Edge Selection):\")\n",
    "    selected_channels_es, _ = selector.edge_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_es}\")\n",
    "\n",
    "    print(\"Top 10 Channels (Aggregation Selection):\")\n",
    "    selected_channels_as, _ = selector.aggregation_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_as}\")\n",
    "else:\n",
    "    print('No results available for adjacency visualization.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(results_df) > 0:\n",
    "    results_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['gated_results_file']\n",
    "    results_df[['subject', 'num_trials', 'num_channels', 'gated_acc', 'gated_std', 'gate_mean', 'gate_std', 'gate_min', 'gate_max']].to_csv(results_path, index=False)\n",
    "\n",
    "    if len(channel_selection_df) > 0:\n",
    "        channel_selection_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['channel_selection_results_file']\n",
    "        channel_selection_df.to_csv(channel_selection_path, index=False)\n",
    "    else:\n",
    "        channel_selection_path = None\n",
    "\n",
    "    config_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['config_file']\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(EXPERIMENT_CONFIG, f, indent=2, default=str)\n",
    "\n",
    "    print('All results exported successfully!')\n",
    "    print(f'  - Subject results: {results_path}')\n",
    "    if channel_selection_path:\n",
    "        print(f'  - Channel selection: {channel_selection_path}')\n",
    "    print(f'  - Config: {config_path}')\n",
    "else:\n",
    "    print('No results to export.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b603c",
   "metadata": {},
   "source": [
    "## Baseline Comparison\n",
    "\n",
    "Compare gated trial results with the baseline EEG-ARNN run from `physionet_training.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95423b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['baseline_results_file']\n",
    "comparison_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['comparison_file']\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    if baseline_path.exists():\n",
    "        baseline_df = pd.read_csv(baseline_path)\n",
    "        comparison_df = results_df.merge(\n",
    "            baseline_df[['subject', 'all_channels_acc', 'all_channels_std']],\n",
    "            on='subject',\n",
    "            how='left'\n",
    "        )\n",
    "        comparison_df['accuracy_delta'] = comparison_df['gated_acc'] - comparison_df['all_channels_acc']\n",
    "        comparison_df.rename(columns={\n",
    "            'all_channels_acc': 'baseline_acc',\n",
    "            'all_channels_std': 'baseline_std'\n",
    "        }, inplace=True)\n",
    "\n",
    "        display_columns = ['subject', 'baseline_acc', 'baseline_std', 'gated_acc', 'gated_std', 'accuracy_delta', 'gate_mean', 'gate_std']\n",
    "        display(comparison_df[display_columns])\n",
    "\n",
    "        comparison_df[display_columns].to_csv(comparison_path, index=False)\n",
    "        print(f\"Baseline comparison saved to: {comparison_path}\")\n",
    "    else:\n",
    "        print(f\"Baseline results not found at {baseline_path}. Run BCI_2a_training_baseline.ipynb first.\")\n",
    "else:\n",
    "    print('No gated results available to compare against baseline.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
