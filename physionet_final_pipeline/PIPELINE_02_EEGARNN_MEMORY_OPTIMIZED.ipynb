{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 2: EEG-ARNN - MEMORY OPTIMIZED VERSION\n",
    "\n",
    "**OPTIMIZED FOR KAGGLE GPU:** No model saving, aggressive memory cleanup\n",
    "\n",
    "## Models\n",
    "1. **Baseline-EEG-ARNN** - Pure CNN-GCN architecture\n",
    "2. **Adaptive-Gating-EEG-ARNN** - With data-dependent channel gating\n",
    "\n",
    "## Memory Optimizations\n",
    "- NO model checkpoints saved (only channel importance scores)\n",
    "- Reduced batch size: 32 (from 64)\n",
    "- Aggressive CUDA cache clearing after each fold\n",
    "- Minimal history tracking\n",
    "- Delete models immediately after use\n",
    "\n",
    "## Configuration\n",
    "- **Dataset:** `/kaggle/input/eeg-preprocessed-data/derived`\n",
    "- **Epochs:** 30 (NO early stopping - full training)\n",
    "- **Cross-validation:** 2-fold\n",
    "- **Batch size:** 32 (memory optimized)\n",
    "- **Learning rate:** 0.002\n",
    "\n",
    "## Outputs\n",
    "```\n",
    "results/eegarnn_baseline_results.csv          - Per-fold results\n",
    "results/eegarnn_adaptive_results.csv          - Per-fold results\n",
    "results/eegarnn_initial_summary.csv           - Summary statistics\n",
    "results/channel_selection_results.csv         - All selection methods\n",
    "results/training_histories.pkl                - Training curves\n",
    "plots/*.png                                    - Visualizations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMORY-OPTIMIZED Configuration\n",
    "CONFIG = {\n",
    "    'data_path': '/kaggle/input/eeg-preprocessed-data/derived',\n",
    "    'results_dir': './results',\n",
    "    'plots_dir': './plots',\n",
    "    \n",
    "    'n_folds': 2,\n",
    "    'random_seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Training hyperparameters - MEMORY OPTIMIZED\n",
    "    'batch_size': 64,  # Same as Pipeline 1\n",
    "    'epochs': 30,  # Full training\n",
    "    'learning_rate': 0.002,\n",
    "    'weight_decay': 1e-4,\n",
    "    'scheduler_patience': 3,\n",
    "    'scheduler_factor': 0.5,\n",
    "    'min_lr': 1e-6,\n",
    "    \n",
    "    # Data parameters\n",
    "    'n_channels': 64,\n",
    "    'n_classes': 2,\n",
    "    'sfreq': 128,\n",
    "    'tmin': 0.0,\n",
    "    'tmax': 4.0,\n",
    "    'n_timepoints': 513,\n",
    "    'hidden_dim': 128,\n",
    "    'mi_runs': [7, 8, 11, 12],\n",
    "    \n",
    "    # Gating parameters\n",
    "    'gating': {\n",
    "        'gate_init': 0.9,\n",
    "        'l1_lambda': 1e-3,\n",
    "    },\n",
    "    \n",
    "    # Channel selection k-values\n",
    "    'k_values': [10, 15, 20, 25, 30],\n",
    "    \n",
    "    # Memory optimization flags\n",
    "    'save_models': False,  # DO NOT SAVE MODELS\n",
    "    'aggressive_cleanup': True,\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['results_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['plots_dir'], exist_ok=True)\n",
    "\n",
    "np.random.seed(CONFIG['random_seed'])\n",
    "torch.manual_seed(CONFIG['random_seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['random_seed'])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']} (memory optimized)\")\n",
    "print(f\"Epochs: {CONFIG['epochs']} (NO early stopping)\")\n",
    "print(f\"Save models: {CONFIG['save_models']} (memory saving)\")\n",
    "print(f\"K-values: {CONFIG['k_values']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Memory Cleanup Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_memory():\n",
    "    \"\"\"Aggressive memory cleanup.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def print_memory_usage():\n",
    "    \"\"\"Print current GPU memory usage.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB\")\n",
    "\n",
    "print(\"Memory utilities defined!\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_physionet_data(data_path):\n",
    "    \"\"\"Load preprocessed PhysioNet data - MATCHING PIPELINE 1.\"\"\"\n",
    "    data_root = os.path.abspath(data_path)\n",
    "    if not os.path.isdir(data_root):\n",
    "        raise FileNotFoundError(f\"Data path not found: {data_root}\")\n",
    "\n",
    "    tmin, tmax = CONFIG['tmin'], CONFIG['tmax']\n",
    "    mi_runs = CONFIG['mi_runs']\n",
    "    event_id = {'T1': 1, 'T2': 2}\n",
    "    label_map = {1: 0, 2: 1}\n",
    "\n",
    "    preprocessed_dir = os.path.join(data_root, 'preprocessed')\n",
    "    if os.path.isdir(preprocessed_dir):\n",
    "        data_root = preprocessed_dir\n",
    "        print(f\"Using preprocessed data from: {data_root}\")\n",
    "    else:\n",
    "        print(f\"Using data from: {data_root}\")\n",
    "    \n",
    "    subject_dirs = [d for d in sorted(os.listdir(data_root))\n",
    "                    if os.path.isdir(os.path.join(data_root, d)) and d.upper().startswith('S')]\n",
    "\n",
    "    all_X, all_y, all_subjects = [], [], []\n",
    "    print(f\"Loading data from {len(subject_dirs)} subjects...\")\n",
    "    \n",
    "    for subject_dir in subject_dirs:\n",
    "        subject_num = int(subject_dir[1:]) if len(subject_dir) > 1 else -1\n",
    "        subject_path = os.path.join(data_root, subject_dir)\n",
    "        \n",
    "        for run_id in mi_runs:\n",
    "            run_file = f\"{subject_dir}R{run_id:02d}_preproc_raw.fif\"\n",
    "            run_path = os.path.join(subject_path, run_file)\n",
    "            \n",
    "            if not os.path.exists(run_path):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                raw = mne.io.read_raw_fif(run_path, preload=True, verbose=False)\n",
    "                picks = mne.pick_types(raw.info, eeg=True, meg=False, stim=False, eog=False)\n",
    "                if len(picks) == 0:\n",
    "                    continue\n",
    "                \n",
    "                events, _ = mne.events_from_annotations(raw, event_id=event_id, verbose=False)\n",
    "                if len(events) == 0:\n",
    "                    continue\n",
    "                \n",
    "                epochs = mne.Epochs(\n",
    "                    raw, events, event_id=event_id, \n",
    "                    tmin=tmin, tmax=tmax,\n",
    "                    baseline=None,\n",
    "                    preload=True, \n",
    "                    picks=picks, \n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                data = epochs.get_data()\n",
    "                labels = np.array([label_map.get(epochs.events[i, 2], -1) for i in range(len(epochs))])\n",
    "                valid = labels >= 0\n",
    "                \n",
    "                if np.any(valid):\n",
    "                    all_X.append(data[valid])\n",
    "                    all_y.append(labels[valid])\n",
    "                    all_subjects.append(np.full(np.sum(valid), subject_num))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    if len(all_X) == 0:\n",
    "        raise ValueError(\"No data loaded!\")\n",
    "    \n",
    "    X = np.concatenate(all_X, axis=0)\n",
    "    y = np.concatenate(all_y, axis=0)\n",
    "    subjects = np.concatenate(all_subjects, axis=0)\n",
    "    \n",
    "    print(f\"\\nData loaded: {len(X)} trials from {len(np.unique(subjects))} subjects\")\n",
    "    print(f\"Shape: {X.shape}, Labels: {np.bincount(y)}\")\n",
    "    \n",
    "    return X, y, subjects\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolution Layer\n",
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(torch.randn(num_channels, num_channels) * 0.01)\n",
    "        self.theta = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(hidden_dim)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, C, T = x.shape\n",
    "        A = torch.sigmoid(self.A)\n",
    "        A = 0.5 * (A + A.t())\n",
    "        I = torch.eye(C, device=A.device)\n",
    "        A_hat = A + I\n",
    "        D = torch.diag(torch.pow(A_hat.sum(1).clamp_min(1e-6), -0.5))\n",
    "        A_norm = D @ A_hat @ D\n",
    "        x_perm = x.permute(0, 3, 2, 1).contiguous().view(B * T, C, H)\n",
    "        x_g = A_norm @ x_perm\n",
    "        x_g = self.theta(x_g)\n",
    "        x_g = x_g.view(B, T, C, H).permute(0, 3, 2, 1)\n",
    "        return self.act(self.bn(x_g))\n",
    "\n",
    "    def get_adjacency(self):\n",
    "        with torch.no_grad():\n",
    "            A = torch.sigmoid(self.A)\n",
    "            A = 0.5 * (A + A.t())\n",
    "            return A.cpu().numpy()\n",
    "\n",
    "\n",
    "class TemporalConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=16, pool=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(1, kernel_size),\n",
    "                              padding=(0, kernel_size // 2), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ELU()\n",
    "        self.pool_layer = nn.AvgPool2d(kernel_size=(1, 2)) if pool else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn(self.conv(x)))\n",
    "        if self.pool_layer is not None:\n",
    "            x = self.pool_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BaselineEEGARNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_gate_regularizer = False\n",
    "\n",
    "        self.t1 = TemporalConv(1, hidden_dim, 16, pool=False)\n",
    "        self.g1 = GraphConvLayer(n_channels, hidden_dim)\n",
    "        self.t2 = TemporalConv(hidden_dim, hidden_dim, 16, pool=True)\n",
    "        self.g2 = GraphConvLayer(n_channels, hidden_dim)\n",
    "        self.t3 = TemporalConv(hidden_dim, hidden_dim, 16, pool=True)\n",
    "        self.g3 = GraphConvLayer(n_channels, hidden_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, n_channels, n_timepoints)\n",
    "            feat = self._forward_features(self._prepare_input(dummy))\n",
    "            self.feature_dim = feat.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_dim, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def _prepare_input(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.g1(self.t1(x))\n",
    "        x = self.g2(self.t2(x))\n",
    "        x = self.g3(self.t3(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        prepared = self._prepare_input(x)\n",
    "        features = self._forward_features(prepared)\n",
    "        x = features.view(features.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "    def get_final_adjacency(self):\n",
    "        return self.g3.get_adjacency()\n",
    "\n",
    "    def get_channel_importance_edge(self):\n",
    "        adjacency = self.get_final_adjacency()\n",
    "        return np.sum(np.abs(adjacency), axis=1)\n",
    "\n",
    "\n",
    "class AdaptiveGatingEEGARNN(BaselineEEGARNN):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128, gate_init=0.9):\n",
    "        super().__init__(n_channels, n_classes, n_timepoints, hidden_dim)\n",
    "        self.use_gate_regularizer = True\n",
    "        \n",
    "        self.gate_net = nn.Sequential(\n",
    "            nn.Linear(n_channels * 2, n_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        init_value = float(np.clip(gate_init, 1e-3, 1 - 1e-3))\n",
    "        init_bias = math.log(init_value / (1.0 - init_value))\n",
    "        with torch.no_grad():\n",
    "            self.gate_net[-2].bias.fill_(init_bias)\n",
    "        \n",
    "        self.latest_gate_values = None\n",
    "        self.gate_penalty_tensor = None\n",
    "\n",
    "    def compute_gates(self, x):\n",
    "        x_s = x.squeeze(1)\n",
    "        ch_mean = x_s.mean(dim=2)\n",
    "        ch_std = x_s.std(dim=2)\n",
    "        stats = torch.cat([ch_mean, ch_std], dim=1)\n",
    "        return self.gate_net(stats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        prepared = self._prepare_input(x)\n",
    "        gates = self.compute_gates(prepared)\n",
    "        self.gate_penalty_tensor = gates\n",
    "        self.latest_gate_values = gates.detach()\n",
    "        gated = prepared * gates.view(gates.size(0), 1, gates.size(1), 1)\n",
    "        features = self._forward_features(gated)\n",
    "        x = features.view(features.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "    def get_channel_importance_gate(self):\n",
    "        if self.latest_gate_values is None:\n",
    "            return None\n",
    "        return self.latest_gate_values.mean(dim=0).cpu().numpy()\n",
    "\n",
    "\n",
    "print(\"Models defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comprehensive_metrics(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, average='binary', zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_preds, average='binary', zero_division=0),\n",
    "        'f1_score': f1_score(all_labels, all_preds, average='binary', zero_division=0),\n",
    "        'auc_roc': roc_auc_score(all_labels, all_probs[:, 1]) if len(np.unique(all_labels)) == 2 else 0.0,\n",
    "    }\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    else:\n",
    "        metrics['specificity'] = 0.0\n",
    "        metrics['sensitivity'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, l1_lambda=0.0):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        gate_penalty = getattr(model, 'gate_penalty_tensor', None)\n",
    "        if l1_lambda > 0 and gate_penalty is not None:\n",
    "            loss = loss + l1_lambda * gate_penalty.abs().mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total\n",
    "\n",
    "\n",
    "def train_model_full(model, train_loader, val_loader, config, model_name=''):\n",
    "    device = config['device']\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=config['scheduler_factor'], \n",
    "        patience=config['scheduler_patience'], min_lr=config['min_lr'], verbose=False\n",
    "    )\n",
    "    \n",
    "    l1_lambda = config['gating']['l1_lambda'] if getattr(model, 'use_gate_regularizer', False) else 0.0\n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Minimal history tracking\n",
    "    history = {'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    print(f\"[{model_name}] Training {config['epochs']} epochs\")\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, l1_lambda)\n",
    "        val_loss, val_acc = evaluate_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{config['epochs']} - Val Acc: {val_acc:.4f} | Best: {best_val_acc:.4f}\")\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    return best_state, best_val_acc, history\n",
    "\n",
    "\n",
    "print(\"Training utilities defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Channel Selection Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_importance_aggregation(model, dataloader, device):\n",
    "    model.eval()\n",
    "    channel_stats = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            prepared = model._prepare_input(X_batch)\n",
    "            features = model._forward_features(prepared)\n",
    "            activations = torch.mean(torch.abs(features), dim=(1, 3))\n",
    "            channel_stats.append(activations.cpu())\n",
    "    if not channel_stats:\n",
    "        return np.zeros(model.n_channels)\n",
    "    stacked = torch.cat(channel_stats, dim=0)\n",
    "    return stacked.mean(dim=0).numpy()\n",
    "\n",
    "\n",
    "def compute_gate_importance(model, dataloader, device):\n",
    "    model.eval()\n",
    "    gate_batches = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            _ = model(X_batch)\n",
    "            latest = getattr(model, 'latest_gate_values', None)\n",
    "            if latest is not None:\n",
    "                gate_batches.append(latest.cpu())\n",
    "    if not gate_batches:\n",
    "        return np.ones(model.n_channels) / model.n_channels\n",
    "    stacked = torch.cat(gate_batches, dim=0)\n",
    "    return stacked.mean(dim=0).numpy()\n",
    "\n",
    "\n",
    "def select_top_k_channels(importance_scores, k):\n",
    "    top_k_indices = np.argsort(importance_scores)[-k:]\n",
    "    return sorted(top_k_indices)\n",
    "\n",
    "\n",
    "def apply_channel_selection(X, selected_channels):\n",
    "    return X[:, selected_channels, :]\n",
    "\n",
    "\n",
    "print(\"Channel selection utilities defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X, y, subjects = load_physionet_data(CONFIG['data_path'])\n",
    "cleanup_memory()\n",
    "print_memory_usage()\n",
    "\n",
    "print(\"\\nData ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Initial Models (NO CHECKPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_seed'])\n",
    "\n",
    "models_to_train = [\n",
    "    {'name': 'Baseline-EEG-ARNN', 'class': BaselineEEGARNN},\n",
    "    {'name': 'Adaptive-Gating-EEG-ARNN', 'class': AdaptiveGatingEEGARNN},\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING INITIAL MODELS (NO CHECKPOINTS SAVED)\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store channel importance for each model/fold\n",
    "channel_importance_store = {}\n",
    "\n",
    "all_results = {}\n",
    "all_histories = {}\n",
    "\n",
    "for model_info in models_to_train:\n",
    "    model_name = model_info['name']\n",
    "    model_class = model_info['class']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    fold_results = []\n",
    "    fold_histories = []\n",
    "    channel_importance_store[model_name] = {}\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {fold + 1}/{CONFIG['n_folds']}\")\n",
    "        cleanup_memory()\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        train_dataset = EEGDataset(X_train, y_train)\n",
    "        val_dataset = EEGDataset(X_val, y_val)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "        \n",
    "        if model_class == AdaptiveGatingEEGARNN:\n",
    "            model = model_class(\n",
    "                n_channels=CONFIG['n_channels'], n_classes=CONFIG['n_classes'],\n",
    "                n_timepoints=CONFIG['n_timepoints'], hidden_dim=CONFIG['hidden_dim'],\n",
    "                gate_init=CONFIG['gating']['gate_init']\n",
    "            )\n",
    "        else:\n",
    "            model = model_class(\n",
    "                n_channels=CONFIG['n_channels'], n_classes=CONFIG['n_classes'],\n",
    "                n_timepoints=CONFIG['n_timepoints'], hidden_dim=CONFIG['hidden_dim']\n",
    "            )\n",
    "        \n",
    "        best_state, val_acc, history = train_model_full(\n",
    "            model, train_loader, val_loader, CONFIG, f\"{model_name}-F{fold+1}\"\n",
    "        )\n",
    "        \n",
    "        model.load_state_dict(best_state)\n",
    "        model = model.to(CONFIG['device'])\n",
    "        metrics = calculate_comprehensive_metrics(model, val_loader, CONFIG['device'])\n",
    "        \n",
    "        print(f\"Results: Acc={metrics['accuracy']:.4f}, F1={metrics['f1_score']:.4f}\")\n",
    "        \n",
    "        # Store channel importance for later use (NOT full model)\n",
    "        importance_info = {\n",
    "            'adjacency': model.get_final_adjacency(),\n",
    "            'edge_importance': model.get_channel_importance_edge(),\n",
    "        }\n",
    "        \n",
    "        if hasattr(model, 'get_channel_importance_gate'):\n",
    "            # Compute gate importance\n",
    "            gate_imp = compute_gate_importance(model, train_loader, CONFIG['device'])\n",
    "            importance_info['gate_importance'] = gate_imp\n",
    "        \n",
    "        # Compute aggregation importance\n",
    "        agg_imp = get_channel_importance_aggregation(model, train_loader, CONFIG['device'])\n",
    "        importance_info['aggregation_importance'] = agg_imp\n",
    "        \n",
    "        channel_importance_store[model_name][fold] = importance_info\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'accuracy': metrics['accuracy'],\n",
    "            'precision': metrics['precision'],\n",
    "            'recall': metrics['recall'],\n",
    "            'f1_score': metrics['f1_score'],\n",
    "            'auc_roc': metrics['auc_roc'],\n",
    "            'specificity': metrics['specificity'],\n",
    "            'sensitivity': metrics['sensitivity']\n",
    "        })\n",
    "        fold_histories.append(history)\n",
    "        \n",
    "        # AGGRESSIVE CLEANUP\n",
    "        del model, best_state, train_loader, val_loader, train_dataset, val_dataset\n",
    "        cleanup_memory()\n",
    "    \n",
    "    all_results[model_name] = fold_results\n",
    "    all_histories[model_name] = fold_histories\n",
    "    \n",
    "    df_temp = pd.DataFrame(fold_results)\n",
    "    print(f\"\\n{model_name} Summary:\")\n",
    "    print(f\"  Accuracy: {df_temp['accuracy'].mean():.4f} \u00c2\u00b1 {df_temp['accuracy'].std():.4f}\")\n",
    "    print(f\"  F1-Score: {df_temp['f1_score'].mean():.4f} \u00c2\u00b1 {df_temp['f1_score'].std():.4f}\")\n",
    "    cleanup_memory()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"INITIAL TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Initial Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "for model_name, fold_results in all_results.items():\n",
    "    df = pd.DataFrame(fold_results)\n",
    "    df['model'] = model_name\n",
    "    cols = ['model', 'fold', 'accuracy', 'precision', 'recall', 'f1_score', \n",
    "            'auc_roc', 'specificity', 'sensitivity']\n",
    "    df = df[cols]\n",
    "    filename = model_name.lower().replace('-', '_').replace(' ', '_')\n",
    "    filepath = os.path.join(CONFIG['results_dir'], f'eegarnn_{filename}_results.csv')\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "# Summary\n",
    "summary_data = []\n",
    "for model_name, fold_results in all_results.items():\n",
    "    df_temp = pd.DataFrame(fold_results)\n",
    "    summary = {'model': model_name}\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'specificity', 'sensitivity']:\n",
    "        summary[f'mean_{metric}'] = df_temp[metric].mean()\n",
    "        summary[f'std_{metric}'] = df_temp[metric].std()\n",
    "    summary_data.append(summary)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "filepath = os.path.join(CONFIG['results_dir'], 'eegarnn_initial_summary.csv')\n",
    "summary_df.to_csv(filepath, index=False)\n",
    "print(f\"Saved: {filepath}\")\n",
    "\n",
    "# Histories\n",
    "filepath = os.path.join(CONFIG['results_dir'], 'training_histories.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(all_histories, f)\n",
    "print(f\"Saved: {filepath}\")\n",
    "\n",
    "print(\"\\nInitial results summary:\")\n",
    "print(summary_df[['model', 'mean_accuracy', 'mean_f1_score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Channel Selection Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_experiments = [\n",
    "    {'model': 'Baseline-EEG-ARNN', 'methods': ['edge', 'aggregation']},\n",
    "    {'model': 'Adaptive-Gating-EEG-ARNN', 'methods': ['edge', 'aggregation', 'gate']},\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHANNEL SELECTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"k-values: {CONFIG['k_values']}\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_selection_results = []\n",
    "\n",
    "for exp in cs_experiments:\n",
    "    model_name = exp['model']\n",
    "    methods = exp['methods']\n",
    "    model_class = BaselineEEGARNN if 'Baseline' in model_name else AdaptiveGatingEEGARNN\n",
    "    \n",
    "    print(f\"\\n{model_name}\")\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\n  {method.upper()}:\", end='')\n",
    "        \n",
    "        for k in CONFIG['k_values']:\n",
    "            fold_metrics_list = []\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "                cleanup_memory()\n",
    "                \n",
    "                X_train, X_val = X[train_idx], X[val_idx]\n",
    "                y_train, y_val = y[train_idx], y[val_idx]\n",
    "                \n",
    "                # Get importance scores from stored data\n",
    "                if method == 'edge':\n",
    "                    importance_scores = channel_importance_store[model_name][fold]['edge_importance']\n",
    "                elif method == 'aggregation':\n",
    "                    importance_scores = channel_importance_store[model_name][fold]['aggregation_importance']\n",
    "                else:  # gate\n",
    "                    importance_scores = channel_importance_store[model_name][fold]['gate_importance']\n",
    "                \n",
    "                # Select channels\n",
    "                selected_channels = select_top_k_channels(importance_scores, k)\n",
    "                X_train_selected = apply_channel_selection(X_train, selected_channels)\n",
    "                X_val_selected = apply_channel_selection(X_val, selected_channels)\n",
    "                \n",
    "                # Train new model\n",
    "                if model_class == AdaptiveGatingEEGARNN:\n",
    "                    new_model = model_class(\n",
    "                        n_channels=k, n_classes=CONFIG['n_classes'],\n",
    "                        n_timepoints=CONFIG['n_timepoints'], hidden_dim=CONFIG['hidden_dim'],\n",
    "                        gate_init=CONFIG['gating']['gate_init']\n",
    "                    )\n",
    "                else:\n",
    "                    new_model = model_class(\n",
    "                        n_channels=k, n_classes=CONFIG['n_classes'],\n",
    "                        n_timepoints=CONFIG['n_timepoints'], hidden_dim=CONFIG['hidden_dim']\n",
    "                    )\n",
    "                \n",
    "                train_dataset = EEGDataset(X_train_selected, y_train)\n",
    "                val_dataset = EEGDataset(X_val_selected, y_val)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "                \n",
    "                best_state, val_acc, _ = train_model_full(\n",
    "                    new_model, train_loader, val_loader, CONFIG, f\"{model_name}-{method}-k{k}-F{fold+1}\"\n",
    "                )\n",
    "                \n",
    "                new_model.load_state_dict(best_state)\n",
    "                new_model = new_model.to(CONFIG['device'])\n",
    "                metrics = calculate_comprehensive_metrics(new_model, val_loader, CONFIG['device'])\n",
    "                fold_metrics_list.append(metrics)\n",
    "                \n",
    "                del new_model, best_state, train_loader, val_loader, train_dataset, val_dataset\n",
    "                cleanup_memory()\n",
    "            \n",
    "            # Compute mean metrics\n",
    "            mean_metrics = {}\n",
    "            for metric_name in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'specificity', 'sensitivity']:\n",
    "                values = [m[metric_name] for m in fold_metrics_list]\n",
    "                mean_metrics[f'mean_{metric_name}'] = np.mean(values)\n",
    "                mean_metrics[f'std_{metric_name}'] = np.std(values)\n",
    "            \n",
    "            print(f\" k={k}:{mean_metrics['mean_accuracy']:.3f}\", end='')\n",
    "            \n",
    "            result = {'model': model_name, 'method': method, 'k': k}\n",
    "            result.update(mean_metrics)\n",
    "            channel_selection_results.append(result)\n",
    "        \n",
    "        print()  # newline\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CHANNEL SELECTION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Channel Selection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_df = pd.DataFrame(channel_selection_results)\n",
    "cols = ['model', 'method', 'k'] + [col for col in cs_df.columns if col not in ['model', 'method', 'k']]\n",
    "cs_df = cs_df[cols]\n",
    "\n",
    "filepath = os.path.join(CONFIG['results_dir'], 'channel_selection_results.csv')\n",
    "cs_df.to_csv(filepath, index=False)\n",
    "print(f\"Saved: {filepath}\")\n",
    "\n",
    "print(\"\\nBest results:\")\n",
    "for model_name in ['Baseline-EEG-ARNN', 'Adaptive-Gating-EEG-ARNN']:\n",
    "    model_data = cs_df[cs_df['model'] == model_name]\n",
    "    best_row = model_data.loc[model_data['mean_accuracy'].idxmax()]\n",
    "    print(f\"{model_name}: {best_row['method'].upper()} k={int(best_row['k'])} \"\n",
    "          f\"Acc={best_row['mean_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE 2 COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nResults saved to results/\")\n",
    "print(\"Ready for comparison with Pipeline 1!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}