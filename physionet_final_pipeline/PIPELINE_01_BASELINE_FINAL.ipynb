{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1: Baseline Methods - FINAL VERSION\n",
    "\n",
    "**OPTIMIZED:** 20 epochs, 2-fold CV, Comprehensive metrics\n",
    "\n",
    "## Models\n",
    "1. FBCSP\n",
    "2. CNN-SAE\n",
    "3. EEGNet\n",
    "4. ACS-SE-CNN\n",
    "5. G-CARM\n",
    "\n",
    "## Metrics Calculated\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall (Sensitivity)\n",
    "- F1-Score\n",
    "- AUC-ROC\n",
    "- Specificity\n",
    "- Confusion Matrix\n",
    "\n",
    "## Runtime: ~4-5 hours\n",
    "- Training: ~3 hours (5 models × 2 folds)\n",
    "- Retention: ~1.5 hours (6 k × 2 folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_path': '/kaggle/input/eeg-preprocessed-data/derived',\n",
    "    'models_dir': './models',\n",
    "    'results_dir': './results',\n",
    "    \n",
    "    'n_folds': 2,\n",
    "    'random_seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    'batch_size': 64,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 0.002,\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 5,\n",
    "    'scheduler_patience': 2,\n",
    "    'scheduler_factor': 0.5,\n",
    "    'use_early_stopping': True,\n",
    "    'min_lr': 1e-6,\n",
    "    \n",
    "    # Data parameters\n",
    "    'n_channels': 64,\n",
    "    'n_classes': 2,\n",
    "    'sfreq': 128,\n",
    "    'tmin': 0.0,\n",
    "    'tmax': 4.0,\n",
    "    'n_timepoints': 513,\n",
    "    'mi_runs': [7, 8, 11, 12],\n",
    "    \n",
    "    # FBCSP parameters\n",
    "    'fbcsp_bands': [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 36), (36, 40)],\n",
    "    'fbcsp_n_components': 4,\n",
    "    \n",
    "    # Retention k-values\n",
    "    'retention_k_values': [10, 15, 20, 25, 30, 35],\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['models_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['results_dir'], exist_ok=True)\n",
    "\n",
    "np.random.seed(CONFIG['random_seed'])\n",
    "torch.manual_seed(CONFIG['random_seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['random_seed'])\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"Folds: {CONFIG['n_folds']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']}\")\n",
    "\n",
    "# Estimate runtime\n",
    "n_models = 5\n",
    "total_runs = n_models * CONFIG['n_folds'] + len(CONFIG['retention_k_values']) * CONFIG['n_folds']\n",
    "print(f\"\\nEstimated training runs: {total_runs}\")\n",
    "print(f\"Estimated runtime (~15 min/run): {total_runs * 15 / 60:.1f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metrics Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comprehensive_metrics(model, dataloader, device):\n",
    "    \"\"\"Calculate all metrics for PyTorch models.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # Get predictions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, average='binary', zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_preds, average='binary', zero_division=0),\n",
    "        'f1_score': f1_score(all_labels, all_preds, average='binary', zero_division=0),\n",
    "        'auc_roc': roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.0,\n",
    "    }\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Specificity\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_sklearn_metrics(model, X_val, y_val):\n",
    "    \"\"\"Calculate all metrics for sklearn models.\"\"\"\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_val, y_pred),\n",
    "        'precision': precision_score(y_val, y_pred, average='binary', zero_division=0),\n",
    "        'recall': recall_score(y_val, y_pred, average='binary', zero_division=0),\n",
    "        'f1_score': f1_score(y_val, y_pred, average='binary', zero_division=0),\n",
    "    }\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    # AUC not available for FBCSP without predict_proba\n",
    "    metrics['auc_roc'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "print(\"Metrics calculation functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_physionet_data(data_path):\n",
    "    \"\"\"Load preprocessed PhysioNet data.\"\"\"\n",
    "    data_root = os.path.abspath(data_path)\n",
    "    if not os.path.isdir(data_root):\n",
    "        raise FileNotFoundError(f\"Data path not found: {data_root}\")\n",
    "\n",
    "    tmin = CONFIG['tmin']\n",
    "    tmax = CONFIG['tmax']\n",
    "    mi_runs = CONFIG['mi_runs']\n",
    "    event_id = {'T1': 1, 'T2': 2}\n",
    "    label_map = {1: 0, 2: 1}\n",
    "\n",
    "    preprocessed_dir = os.path.join(data_root, 'preprocessed')\n",
    "    if os.path.isdir(preprocessed_dir):\n",
    "        data_root = preprocessed_dir\n",
    "    \n",
    "    subject_dirs = [d for d in sorted(os.listdir(data_root))\n",
    "                    if os.path.isdir(os.path.join(data_root, d)) and d.upper().startswith('S')]\n",
    "\n",
    "    all_X, all_y, all_subjects = [], [], []\n",
    "    \n",
    "    print(f\"Loading data from {len(subject_dirs)} subjects...\")\n",
    "    \n",
    "    for subject_dir in subject_dirs:\n",
    "        subject_num = int(subject_dir[1:]) if len(subject_dir) > 1 else -1\n",
    "        subject_path = os.path.join(data_root, subject_dir)\n",
    "        \n",
    "        for run_id in mi_runs:\n",
    "            run_file = f\"{subject_dir}R{run_id:02d}_preproc_raw.fif\"\n",
    "            run_path = os.path.join(subject_path, run_file)\n",
    "            \n",
    "            if not os.path.exists(run_path):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                raw = mne.io.read_raw_fif(run_path, preload=True, verbose=False)\n",
    "                picks = mne.pick_types(raw.info, eeg=True, meg=False, stim=False, eog=False)\n",
    "                if len(picks) == 0:\n",
    "                    continue\n",
    "                \n",
    "                events, _ = mne.events_from_annotations(raw, event_id=event_id)\n",
    "                if len(events) == 0:\n",
    "                    continue\n",
    "                \n",
    "                epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                                    baseline=None, preload=True, picks=picks, verbose=False)\n",
    "                \n",
    "                data = epochs.get_data()\n",
    "                labels = np.array([label_map.get(epochs.events[i, 2], -1) for i in range(len(epochs))])\n",
    "                valid = labels >= 0\n",
    "                \n",
    "                if np.any(valid):\n",
    "                    all_X.append(data[valid])\n",
    "                    all_y.append(labels[valid])\n",
    "                    all_subjects.append(np.full(np.sum(valid), subject_num))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    X = np.concatenate(all_X, axis=0)\n",
    "    y = np.concatenate(all_y, axis=0)\n",
    "    subjects = np.concatenate(all_subjects, axis=0)\n",
    "    \n",
    "    print(f\"Loaded {len(X)} trials from {len(np.unique(subjects))} subjects\")\n",
    "    print(f\"Data shape: {X.shape}\")\n",
    "    print(f\"Labels: {np.bincount(y)}\")\n",
    "    \n",
    "    return X, y, subjects\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBCSP\n",
    "class FBCSP:\n",
    "    def __init__(self, freq_bands, n_components=4, sfreq=128):\n",
    "        self.freq_bands = freq_bands\n",
    "        self.n_components = n_components\n",
    "        self.sfreq = sfreq\n",
    "        self.csp_list = []\n",
    "        self.classifier = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        from mne.decoding import CSP\n",
    "        all_features = []\n",
    "        \n",
    "        for low, high in self.freq_bands:\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            csp = CSP(n_components=self.n_components, reg=None, log=True, norm_trace=False)\n",
    "            features = csp.fit_transform(X_filtered, y)\n",
    "            self.csp_list.append(csp)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        self.classifier = LinearDiscriminantAnalysis()\n",
    "        self.classifier.fit(all_features, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        all_features = []\n",
    "        for idx, (low, high) in enumerate(self.freq_bands):\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            features = self.csp_list[idx].transform(X_filtered)\n",
    "            all_features.append(features)\n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        return self.classifier.predict(all_features)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n",
    "    \n",
    "    def _bandpass_filter(self, X, low, high):\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        nyq = self.sfreq / 2\n",
    "        b, a = butter(4, [low / nyq, high / nyq], btype='band')\n",
    "        X_filtered = np.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                X_filtered[i, j, :] = filtfilt(b, a, X[i, j, :])\n",
    "        return X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-SAE\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(n_channels, n_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels // 4, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pooled = torch.mean(x, dim=2)\n",
    "        weights = self.attention(pooled)\n",
    "        return x * weights.unsqueeze(2)\n",
    "\n",
    "\n",
    "class CNNSAE(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        self.spatial_attention = SpatialAttention(n_channels)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.spatial_attention(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEGNet\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, F1=8, D=2, F2=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        self.conv2 = nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1 * D)\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv3 = nn.Conv2d(F1 * D, F2, (1, 16), padding=(0, 8), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc = nn.Linear(flattened_size, n_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.dropout1(self.pool1(F.elu(self.bn2(self.conv2(x)))))\n",
    "        x = self.dropout2(self.pool2(F.elu(self.bn3(self.conv3(x)))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACS-SE-CNN\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, max(1, channels // reduction))\n",
    "        self.fc2 = nn.Linear(max(1, channels // reduction), channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        squeeze = torch.mean(x, dim=2)\n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation))\n",
    "        return x * excitation.unsqueeze(2)\n",
    "\n",
    "\n",
    "class ACSECNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Linear(n_timepoints, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.se1 = SEBlock(n_channels)\n",
    "        self.se2 = SEBlock(128)\n",
    "        self.se3 = SEBlock(256)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        channel_weights = []\n",
    "        for i in range(x.size(1)):\n",
    "            w = self.channel_attention(x[:, i, :])\n",
    "            channel_weights.append(w)\n",
    "        channel_weights = torch.cat(channel_weights, dim=1)\n",
    "        x = x * channel_weights.unsqueeze(2)\n",
    "        x = self.se1(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.se2(x)\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.se3(x)\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G-CARM\n",
    "class CARMBlock(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        A_norm = torch.softmax(self.A, dim=1)\n",
    "        x_reshaped = x.permute(0, 2, 1)\n",
    "        x_graph = torch.matmul(x_reshaped, A_norm.t())\n",
    "        return x_graph.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "class GCARM(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        self.carm1 = CARMBlock(n_channels)\n",
    "        self.carm2 = CARMBlock(n_channels)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.carm1(x)\n",
    "        x = self.carm2(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / max(1, len(dataloader)), correct / max(1, total)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / max(1, len(dataloader)), correct / max(1, total)\n",
    "\n",
    "\n",
    "def train_pytorch_model(model, train_loader, val_loader, config, model_name=''):\n",
    "    device = config['device']\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], \n",
    "                          weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=config['scheduler_factor'], \n",
    "        patience=config['scheduler_patience'], min_lr=config['min_lr'], verbose=False\n",
    "    )\n",
    "    \n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        improved = val_acc > best_val_acc or (val_acc == best_val_acc and val_loss < best_val_loss)\n",
    "        if improved:\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 5 == 0 or improved:\n",
    "            print(f\"[{model_name}] Epoch {epoch+1}/{config['epochs']} - \"\n",
    "                  f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | Best: {best_val_acc:.4f}\")\n",
    "        \n",
    "        if config['use_early_stopping'] and patience_counter >= config['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    return best_state, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading PhysioNet data...\")\n",
    "X, y, subjects = load_physionet_data(CONFIG['data_path'])\n",
    "print(f\"\\nData ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train All Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models_to_train = [\n",
    "    {'name': 'FBCSP', 'type': 'sklearn'},\n",
    "    {'name': 'CNN-SAE', 'type': 'pytorch'},\n",
    "    {'name': 'EEGNet', 'type': 'pytorch'},\n",
    "    {'name': 'ACS-SE-CNN', 'type': 'pytorch'},\n",
    "    {'name': 'G-CARM', 'type': 'pytorch'},\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_seed'])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING BASELINE METHODS\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for model_info in models_to_train:\n",
    "    model_name = model_info['name']\n",
    "    model_type = model_info['type']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}/{CONFIG['n_folds']}\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = FBCSP(freq_bands=CONFIG['fbcsp_bands'],\n",
    "                          n_components=CONFIG['fbcsp_n_components'],\n",
    "                          sfreq=CONFIG['sfreq'])\n",
    "            model.fit(X_train, y_train)\n",
    "            metrics = calculate_sklearn_metrics(model, X_val, y_val)\n",
    "            \n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"baseline_{model_name}_fold{fold+1}.pkl\")\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        else:\n",
    "            train_dataset = EEGDataset(X_train, y_train)\n",
    "            val_dataset = EEGDataset(X_val, y_val)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "            \n",
    "            base_kwargs = {\n",
    "                'n_channels': CONFIG['n_channels'],\n",
    "                'n_classes': CONFIG['n_classes'],\n",
    "                'n_timepoints': CONFIG['n_timepoints'],\n",
    "            }\n",
    "            \n",
    "            if model_name == 'CNN-SAE':\n",
    "                model = CNNSAE(**base_kwargs)\n",
    "            elif model_name == 'EEGNet':\n",
    "                model = EEGNet(**base_kwargs)\n",
    "            elif model_name == 'ACS-SE-CNN':\n",
    "                model = ACSECNN(**base_kwargs)\n",
    "            elif model_name == 'G-CARM':\n",
    "                model = GCARM(**base_kwargs)\n",
    "            \n",
    "            best_state, model = train_pytorch_model(model, train_loader, val_loader, CONFIG, model_name)\n",
    "            \n",
    "            # Calculate comprehensive metrics\n",
    "            metrics = calculate_comprehensive_metrics(model, val_loader, CONFIG['device'])\n",
    "            \n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"baseline_{model_name}_fold{fold+1}.pt\")\n",
    "            torch.save(best_state, model_path)\n",
    "            \n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        # Store results\n",
    "        result = {'fold': fold + 1}\n",
    "        result.update(metrics)\n",
    "        fold_results.append(result)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} Results:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1-Score: {metrics['f1_score']:.4f}\")\n",
    "        print(f\"  AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "        print(f\"  Specificity: {metrics['specificity']:.4f}\")\n",
    "    \n",
    "    # Calculate mean metrics\n",
    "    mean_metrics = {}\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'specificity', 'sensitivity']:\n",
    "        values = [r[metric] for r in fold_results]\n",
    "        mean_metrics[f'mean_{metric}'] = np.mean(values)\n",
    "        mean_metrics[f'std_{metric}'] = np.std(values)\n",
    "    \n",
    "    print(f\"\\n{model_name} Summary:\")\n",
    "    print(f\"Mean Accuracy: {mean_metrics['mean_accuracy']:.4f} +/- {mean_metrics['std_accuracy']:.4f}\")\n",
    "    print(f\"Mean F1-Score: {mean_metrics['mean_f1_score']:.4f} +/- {mean_metrics['std_f1_score']:.4f}\")\n",
    "    print(f\"Mean AUC-ROC: {mean_metrics['mean_auc_roc']:.4f} +/- {mean_metrics['std_auc_roc']:.4f}\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'model': model_name,\n",
    "        **mean_metrics,\n",
    "        'fold_results': fold_results\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL BASELINE MODELS TRAINED!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Retention Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-based channel importance\n",
    "def get_channel_importance_variance(X_train):\n",
    "    \"\"\"Compute channel importance based on temporal variance.\"\"\"\n",
    "    channel_variance = np.var(X_train, axis=(0, 2))\n",
    "    return channel_variance\n",
    "\n",
    "\n",
    "def select_top_k_channels(importance_scores, k):\n",
    "    \"\"\"Select top k channels based on importance scores.\"\"\"\n",
    "    top_k_indices = np.argsort(importance_scores)[-k:]\n",
    "    return sorted(top_k_indices)\n",
    "\n",
    "\n",
    "def apply_channel_selection(X, selected_channels):\n",
    "    \"\"\"Apply channel selection to data.\"\"\"\n",
    "    return X[:, selected_channels, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retention analysis configuration\n",
    "RETENTION_MODEL = 'EEGNet'\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RETENTION ANALYSIS: {RETENTION_MODEL}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "print(f\"k-values: {CONFIG['retention_k_values']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run retention analysis\n",
    "retention_results = []\n",
    "\n",
    "for k in CONFIG['retention_k_values']:\n",
    "    print(f\"\\nTesting with k={k} channels:\")\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Compute channel importance on training data\n",
    "        importance_scores = get_channel_importance_variance(X_train)\n",
    "        selected_channels = select_top_k_channels(importance_scores, k)\n",
    "        \n",
    "        # Apply channel selection\n",
    "        X_train_selected = apply_channel_selection(X_train, selected_channels)\n",
    "        X_val_selected = apply_channel_selection(X_val, selected_channels)\n",
    "        \n",
    "        # Train model with selected channels\n",
    "        train_dataset = EEGDataset(X_train_selected, y_train)\n",
    "        val_dataset = EEGDataset(X_val_selected, y_val)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "        \n",
    "        model = EEGNet(n_channels=k, n_classes=CONFIG['n_classes'], n_timepoints=CONFIG['n_timepoints'])\n",
    "        best_state, model = train_pytorch_model(model, train_loader, val_loader, CONFIG, f\"Retention-k{k}\")\n",
    "        \n",
    "        # Calculate comprehensive metrics\n",
    "        metrics = calculate_comprehensive_metrics(model, val_loader, CONFIG['device'])\n",
    "        \n",
    "        result = {'fold': fold + 1}\n",
    "        result.update(metrics)\n",
    "        fold_results.append(result)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Calculate mean metrics\n",
    "    mean_metrics = {}\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'specificity', 'sensitivity']:\n",
    "        values = [r[metric] for r in fold_results]\n",
    "        mean_metrics[f'mean_{metric}'] = np.mean(values)\n",
    "        mean_metrics[f'std_{metric}'] = np.std(values)\n",
    "    \n",
    "    print(f\"k={k} Results:\")\n",
    "    print(f\"  Accuracy: {mean_metrics['mean_accuracy']:.4f} +/- {mean_metrics['std_accuracy']:.4f}\")\n",
    "    print(f\"  F1-Score: {mean_metrics['mean_f1_score']:.4f} +/- {mean_metrics['std_f1_score']:.4f}\")\n",
    "    print(f\"  AUC-ROC: {mean_metrics['mean_auc_roc']:.4f} +/- {mean_metrics['std_auc_roc']:.4f}\")\n",
    "    \n",
    "    retention_results.append({\n",
    "        'model': RETENTION_MODEL,\n",
    "        'k': k,\n",
    "        **mean_metrics,\n",
    "        'fold_results': fold_results\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare detailed results\n",
    "detailed_results = []\n",
    "for result in all_results:\n",
    "    for fold_result in result['fold_results']:\n",
    "        detailed_results.append({\n",
    "            'model': result['model'],\n",
    "            'fold': fold_result['fold'],\n",
    "            'accuracy': fold_result['accuracy'],\n",
    "            'precision': fold_result['precision'],\n",
    "            'recall': fold_result['recall'],\n",
    "            'f1_score': fold_result['f1_score'],\n",
    "            'auc_roc': fold_result['auc_roc'],\n",
    "            'specificity': fold_result['specificity'],\n",
    "            'sensitivity': fold_result['sensitivity']\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_results)\n",
    "detailed_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_methods_results.csv'), index=False)\n",
    "\n",
    "# Prepare summary\n",
    "summary_data = []\n",
    "for result in all_results:\n",
    "    summary_data.append({\n",
    "        'model': result['model'],\n",
    "        'mean_accuracy': result['mean_accuracy'],\n",
    "        'std_accuracy': result['std_accuracy'],\n",
    "        'mean_precision': result['mean_precision'],\n",
    "        'std_precision': result['std_precision'],\n",
    "        'mean_recall': result['mean_recall'],\n",
    "        'std_recall': result['std_recall'],\n",
    "        'mean_f1_score': result['mean_f1_score'],\n",
    "        'std_f1_score': result['std_f1_score'],\n",
    "        'mean_auc_roc': result['mean_auc_roc'],\n",
    "        'std_auc_roc': result['std_auc_roc'],\n",
    "        'mean_specificity': result['mean_specificity'],\n",
    "        'std_specificity': result['std_specificity'],\n",
    "        'mean_sensitivity': result['mean_sensitivity'],\n",
    "        'std_sensitivity': result['std_sensitivity']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('mean_accuracy', ascending=False).reset_index(drop=True)\n",
    "summary_df['rank'] = range(1, len(summary_df) + 1)\n",
    "summary_df = summary_df[['rank', 'model', 'mean_accuracy', 'std_accuracy', 'mean_precision', 'std_precision',\n",
    "                         'mean_recall', 'std_recall', 'mean_f1_score', 'std_f1_score', 'mean_auc_roc', 'std_auc_roc',\n",
    "                         'mean_specificity', 'std_specificity', 'mean_sensitivity', 'std_sensitivity']]\n",
    "summary_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_methods_summary.csv'), index=False)\n",
    "\n",
    "print(\"\\nResults saved to:\")\n",
    "print(\"  - results/baseline_methods_results.csv\")\n",
    "print(\"  - results/baseline_methods_summary.csv\")\n",
    "\n",
    "print(\"\\nBaseline Methods Summary:\")\n",
    "print(summary_df[['rank', 'model', 'mean_accuracy', 'mean_f1_score', 'mean_auc_roc']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save retention results\n",
    "retention_detailed = []\n",
    "for result in retention_results:\n",
    "    for fold_result in result['fold_results']:\n",
    "        retention_detailed.append({\n",
    "            'model': result['model'],\n",
    "            'k': result['k'],\n",
    "            'fold': fold_result['fold'],\n",
    "            'accuracy': fold_result['accuracy'],\n",
    "            'precision': fold_result['precision'],\n",
    "            'recall': fold_result['recall'],\n",
    "            'f1_score': fold_result['f1_score'],\n",
    "            'auc_roc': fold_result['auc_roc'],\n",
    "            'specificity': fold_result['specificity'],\n",
    "            'sensitivity': fold_result['sensitivity']\n",
    "        })\n",
    "\n",
    "retention_detailed_df = pd.DataFrame(retention_detailed)\n",
    "retention_detailed_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_retention_analysis.csv'), index=False)\n",
    "\n",
    "# Retention summary\n",
    "retention_summary = []\n",
    "for result in retention_results:\n",
    "    retention_summary.append({\n",
    "        'model': result['model'],\n",
    "        'k': result['k'],\n",
    "        'mean_accuracy': result['mean_accuracy'],\n",
    "        'std_accuracy': result['std_accuracy'],\n",
    "        'mean_f1_score': result['mean_f1_score'],\n",
    "        'std_f1_score': result['std_f1_score'],\n",
    "        'mean_auc_roc': result['mean_auc_roc'],\n",
    "        'std_auc_roc': result['std_auc_roc']\n",
    "    })\n",
    "\n",
    "retention_summary_df = pd.DataFrame(retention_summary)\n",
    "\n",
    "print(\"\\nRetention Analysis Results:\")\n",
    "print(retention_summary_df[['k', 'mean_accuracy', 'mean_f1_score', 'mean_auc_roc']].to_string(index=False))\n",
    "\n",
    "print(\"\\nResults saved to: results/baseline_retention_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PIPELINE 1 COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(\"\\nAll comprehensive metrics have been calculated and saved.\")\n",
    "print(\"\\nOutputs:\")\n",
    "print(\"  1. baseline_methods_results.csv - Detailed per-fold results with all metrics\")\n",
    "print(\"  2. baseline_methods_summary.csv - Summary statistics with rankings\")\n",
    "print(\"  3. baseline_retention_analysis.csv - Retention curve data\")\n",
    "print(\"\\nReady for comparison with Pipeline 2!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
