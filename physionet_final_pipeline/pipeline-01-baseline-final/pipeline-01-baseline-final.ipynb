{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13546721,"sourceType":"datasetVersion","datasetId":8603408}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pipeline 1: Baseline Methods - FINAL VERSION\n\n**OPTIMIZED:** 20 epochs, 2-fold CV, Comprehensive metrics\n\n## Models\n1. FBCSP\n2. CNN-SAE\n3. EEGNet\n4. ACS-SE-CNN\n5. G-CARM\n\n## Metrics Calculated\n- Accuracy\n- Precision\n- Recall (Sensitivity)\n- F1-Score\n- AUC-ROC\n- Specificity\n- Confusion Matrix\n\n## Runtime: ~4-5 hours\n- Training: ~3 hours (5 models × 2 folds)\n- Retention: ~1.5 hours (6 k × 2 folds)","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup and Configuration","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport mne\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix\n)\nimport pickle\nfrom copy import deepcopy\nimport warnings\nwarnings.filterwarnings('ignore')\nmne.set_log_level('ERROR')\n\nprint(\"All imports successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:34.575867Z","iopub.execute_input":"2025-11-24T06:12:34.576461Z","iopub.status.idle":"2025-11-24T06:12:40.021969Z","shell.execute_reply.started":"2025-11-24T06:12:34.576436Z","shell.execute_reply":"2025-11-24T06:12:40.021322Z"}},"outputs":[{"name":"stdout","text":"All imports successful!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Configuration\nCONFIG = {\n    'data_path': '/kaggle/input/eeg-preprocessed-data/derived',\n    'models_dir': './models',\n    'results_dir': './results',\n    \n    'n_folds': 2,\n    'random_seed': 42,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    \n    # Training hyperparameters\n    'batch_size': 64,\n    'epochs': 20,\n    'learning_rate': 0.002,\n    'weight_decay': 1e-4,\n    'patience': 5,\n    'scheduler_patience': 2,\n    'scheduler_factor': 0.5,\n    'use_early_stopping': True,\n    'min_lr': 1e-6,\n    \n    # Data parameters\n    'n_channels': 64,\n    'n_classes': 2,\n    'sfreq': 128,\n    'tmin': 0.0,\n    'tmax': 4.0,\n    'n_timepoints': 513,\n    'mi_runs': [7, 8, 11, 12],\n    \n    # FBCSP parameters\n    'fbcsp_bands': [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 36), (36, 40)],\n    'fbcsp_n_components': 4,\n    \n    # Retention k-values\n    'retention_k_values': [10, 15, 20, 25, 30, 35],\n}\n\nos.makedirs(CONFIG['models_dir'], exist_ok=True)\nos.makedirs(CONFIG['results_dir'], exist_ok=True)\n\nnp.random.seed(CONFIG['random_seed'])\ntorch.manual_seed(CONFIG['random_seed'])\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(CONFIG['random_seed'])\n\nprint(f\"Device: {CONFIG['device']}\")\nprint(f\"Epochs: {CONFIG['epochs']}\")\nprint(f\"Folds: {CONFIG['n_folds']}\")\nprint(f\"Learning rate: {CONFIG['learning_rate']}\")\n\n# Estimate runtime\nn_models = 5\ntotal_runs = n_models * CONFIG['n_folds'] + len(CONFIG['retention_k_values']) * CONFIG['n_folds']\nprint(f\"\\nEstimated training runs: {total_runs}\")\nprint(f\"Estimated runtime (~15 min/run): {total_runs * 15 / 60:.1f} hours\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.023398Z","iopub.execute_input":"2025-11-24T06:12:40.023744Z","iopub.status.idle":"2025-11-24T06:12:40.092125Z","shell.execute_reply.started":"2025-11-24T06:12:40.023724Z","shell.execute_reply":"2025-11-24T06:12:40.091509Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nEpochs: 20\nFolds: 2\nLearning rate: 0.002\n\nEstimated training runs: 22\nEstimated runtime (~15 min/run): 5.5 hours\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 2. Metrics Calculation Functions","metadata":{}},{"cell_type":"code","source":"def calculate_comprehensive_metrics(model, dataloader, device):\n    \"\"\"Calculate all metrics for PyTorch models.\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for X_batch, y_batch in dataloader:\n            X_batch = X_batch.to(device)\n            outputs = model(X_batch)\n            \n            # Get predictions\n            probs = torch.softmax(outputs, dim=1)\n            _, predicted = torch.max(outputs, 1)\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(y_batch.numpy())\n            all_probs.extend(probs[:, 1].cpu().numpy())\n    \n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    all_probs = np.array(all_probs)\n    \n    # Calculate metrics\n    metrics = {\n        'accuracy': accuracy_score(all_labels, all_preds),\n        'precision': precision_score(all_labels, all_preds, average='binary', zero_division=0),\n        'recall': recall_score(all_labels, all_preds, average='binary', zero_division=0),\n        'f1_score': f1_score(all_labels, all_preds, average='binary', zero_division=0),\n        'auc_roc': roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.0,\n    }\n    \n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    # Specificity\n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    \n    return metrics\n\n\ndef calculate_sklearn_metrics(model, X_val, y_val):\n    \"\"\"Calculate all metrics for sklearn models.\"\"\"\n    y_pred = model.predict(X_val)\n    \n    metrics = {\n        'accuracy': accuracy_score(y_val, y_pred),\n        'precision': precision_score(y_val, y_pred, average='binary', zero_division=0),\n        'recall': recall_score(y_val, y_pred, average='binary', zero_division=0),\n        'f1_score': f1_score(y_val, y_pred, average='binary', zero_division=0),\n    }\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_val, y_pred)\n    \n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    \n    # AUC not available for FBCSP without predict_proba\n    metrics['auc_roc'] = 0.0\n    \n    return metrics\n\n\nprint(\"Metrics calculation functions loaded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.092926Z","iopub.execute_input":"2025-11-24T06:12:40.093631Z","iopub.status.idle":"2025-11-24T06:12:40.108371Z","shell.execute_reply.started":"2025-11-24T06:12:40.093604Z","shell.execute_reply":"2025-11-24T06:12:40.107815Z"}},"outputs":[{"name":"stdout","text":"Metrics calculation functions loaded!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 3. Data Loading","metadata":{}},{"cell_type":"code","source":"def load_physionet_data(data_path):\n    \"\"\"Load preprocessed PhysioNet data.\"\"\"\n    data_root = os.path.abspath(data_path)\n    if not os.path.isdir(data_root):\n        raise FileNotFoundError(f\"Data path not found: {data_root}\")\n\n    tmin = CONFIG['tmin']\n    tmax = CONFIG['tmax']\n    mi_runs = CONFIG['mi_runs']\n    event_id = {'T1': 1, 'T2': 2}\n    label_map = {1: 0, 2: 1}\n\n    preprocessed_dir = os.path.join(data_root, 'preprocessed')\n    if os.path.isdir(preprocessed_dir):\n        data_root = preprocessed_dir\n    \n    subject_dirs = [d for d in sorted(os.listdir(data_root))\n                    if os.path.isdir(os.path.join(data_root, d)) and d.upper().startswith('S')]\n\n    all_X, all_y, all_subjects = [], [], []\n    \n    print(f\"Loading data from {len(subject_dirs)} subjects...\")\n    \n    for subject_dir in subject_dirs:\n        subject_num = int(subject_dir[1:]) if len(subject_dir) > 1 else -1\n        subject_path = os.path.join(data_root, subject_dir)\n        \n        for run_id in mi_runs:\n            run_file = f\"{subject_dir}R{run_id:02d}_preproc_raw.fif\"\n            run_path = os.path.join(subject_path, run_file)\n            \n            if not os.path.exists(run_path):\n                continue\n            \n            try:\n                raw = mne.io.read_raw_fif(run_path, preload=True, verbose=False)\n                picks = mne.pick_types(raw.info, eeg=True, meg=False, stim=False, eog=False)\n                if len(picks) == 0:\n                    continue\n                \n                events, _ = mne.events_from_annotations(raw, event_id=event_id)\n                if len(events) == 0:\n                    continue\n                \n                epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n                                    baseline=None, preload=True, picks=picks, verbose=False)\n                \n                data = epochs.get_data()\n                labels = np.array([label_map.get(epochs.events[i, 2], -1) for i in range(len(epochs))])\n                valid = labels >= 0\n                \n                if np.any(valid):\n                    all_X.append(data[valid])\n                    all_y.append(labels[valid])\n                    all_subjects.append(np.full(np.sum(valid), subject_num))\n            except Exception as e:\n                continue\n    \n    X = np.concatenate(all_X, axis=0)\n    y = np.concatenate(all_y, axis=0)\n    subjects = np.concatenate(all_subjects, axis=0)\n    \n    print(f\"Loaded {len(X)} trials from {len(np.unique(subjects))} subjects\")\n    print(f\"Data shape: {X.shape}\")\n    print(f\"Labels: {np.bincount(y)}\")\n    \n    return X, y, subjects\n\n\nclass EEGDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.109044Z","iopub.execute_input":"2025-11-24T06:12:40.109310Z","iopub.status.idle":"2025-11-24T06:12:40.127401Z","shell.execute_reply.started":"2025-11-24T06:12:40.109293Z","shell.execute_reply":"2025-11-24T06:12:40.126742Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 4. Model Architectures","metadata":{}},{"cell_type":"code","source":"# FBCSP\nclass FBCSP:\n    def __init__(self, freq_bands, n_components=4, sfreq=128):\n        self.freq_bands = freq_bands\n        self.n_components = n_components\n        self.sfreq = sfreq\n        self.csp_list = []\n        self.classifier = None\n    \n    def fit(self, X, y):\n        from mne.decoding import CSP\n        all_features = []\n        \n        for low, high in self.freq_bands:\n            X_filtered = self._bandpass_filter(X, low, high)\n            csp = CSP(n_components=self.n_components, reg=None, log=True, norm_trace=False)\n            features = csp.fit_transform(X_filtered, y)\n            self.csp_list.append(csp)\n            all_features.append(features)\n        \n        all_features = np.concatenate(all_features, axis=1)\n        self.classifier = LinearDiscriminantAnalysis()\n        self.classifier.fit(all_features, y)\n        return self\n    \n    def predict(self, X):\n        all_features = []\n        for idx, (low, high) in enumerate(self.freq_bands):\n            X_filtered = self._bandpass_filter(X, low, high)\n            features = self.csp_list[idx].transform(X_filtered)\n            all_features.append(features)\n        all_features = np.concatenate(all_features, axis=1)\n        return self.classifier.predict(all_features)\n    \n    def score(self, X, y):\n        return np.mean(self.predict(X) == y)\n    \n    def _bandpass_filter(self, X, low, high):\n        from scipy.signal import butter, filtfilt\n        nyq = self.sfreq / 2\n        b, a = butter(4, [low / nyq, high / nyq], btype='band')\n        X_filtered = np.zeros_like(X)\n        for i in range(X.shape[0]):\n            for j in range(X.shape[1]):\n                X_filtered[i, j, :] = filtfilt(b, a, X[i, j, :])\n        return X_filtered","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.129245Z","iopub.execute_input":"2025-11-24T06:12:40.129442Z","iopub.status.idle":"2025-11-24T06:12:40.147038Z","shell.execute_reply.started":"2025-11-24T06:12:40.129427Z","shell.execute_reply":"2025-11-24T06:12:40.146371Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# CNN-SAE\nclass SpatialAttention(nn.Module):\n    def __init__(self, n_channels):\n        super().__init__()\n        self.attention = nn.Sequential(\n            nn.Linear(n_channels, n_channels // 4),\n            nn.ReLU(),\n            nn.Linear(n_channels // 4, n_channels),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        pooled = torch.mean(x, dim=2)\n        weights = self.attention(pooled)\n        return x * weights.unsqueeze(2)\n\n\nclass CNNSAE(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n        super().__init__()\n        self.spatial_attention = SpatialAttention(n_channels)\n        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm1d(64)\n        self.pool1 = nn.MaxPool1d(2)\n        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.pool2 = nn.MaxPool1d(2)\n        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm1d(256)\n        self.pool3 = nn.MaxPool1d(2)\n        self.dropout = nn.Dropout(0.5)\n        \n        with torch.no_grad():\n            test_input = torch.zeros(1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n        \n        self.fc1 = nn.Linear(flattened_size, 256)\n        self.fc2 = nn.Linear(256, n_classes)\n    \n    def _forward_features(self, x):\n        x = self.spatial_attention(x)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        return x\n    \n    def forward(self, x):\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.147700Z","iopub.execute_input":"2025-11-24T06:12:40.147969Z","iopub.status.idle":"2025-11-24T06:12:40.165815Z","shell.execute_reply.started":"2025-11-24T06:12:40.147946Z","shell.execute_reply":"2025-11-24T06:12:40.165216Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# EEGNet\nclass EEGNet(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, F1=8, D=2, F2=16):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n        self.bn1 = nn.BatchNorm2d(F1)\n        self.conv2 = nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False)\n        self.bn2 = nn.BatchNorm2d(F1 * D)\n        self.pool1 = nn.AvgPool2d((1, 4))\n        self.dropout1 = nn.Dropout(0.5)\n        self.conv3 = nn.Conv2d(F1 * D, F2, (1, 16), padding=(0, 8), bias=False)\n        self.bn3 = nn.BatchNorm2d(F2)\n        self.pool2 = nn.AvgPool2d((1, 8))\n        self.dropout2 = nn.Dropout(0.5)\n        \n        with torch.no_grad():\n            test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n        \n        self.fc = nn.Linear(flattened_size, n_classes)\n\n    def _forward_features(self, x):\n        x = self.bn1(self.conv1(x))\n        x = self.dropout1(self.pool1(F.elu(self.bn2(self.conv2(x)))))\n        x = self.dropout2(self.pool2(F.elu(self.bn3(self.conv3(x)))))\n        return x\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        return self.fc(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.166451Z","iopub.execute_input":"2025-11-24T06:12:40.166697Z","iopub.status.idle":"2025-11-24T06:12:40.185664Z","shell.execute_reply.started":"2025-11-24T06:12:40.166642Z","shell.execute_reply":"2025-11-24T06:12:40.184898Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ACS-SE-CNN\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction=4):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, max(1, channels // reduction))\n        self.fc2 = nn.Linear(max(1, channels // reduction), channels)\n    \n    def forward(self, x):\n        squeeze = torch.mean(x, dim=2)\n        excitation = F.relu(self.fc1(squeeze))\n        excitation = torch.sigmoid(self.fc2(excitation))\n        return x * excitation.unsqueeze(2)\n\n\nclass ACSECNN(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n        super().__init__()\n        self.channel_attention = nn.Sequential(\n            nn.Linear(n_timepoints, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n        self.se1 = SEBlock(n_channels)\n        self.se2 = SEBlock(128)\n        self.se3 = SEBlock(256)\n        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(2)\n        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.pool2 = nn.MaxPool1d(2)\n        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm1d(512)\n        self.pool3 = nn.MaxPool1d(2)\n        self.dropout = nn.Dropout(0.5)\n        \n        with torch.no_grad():\n            test_input = torch.zeros(1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n        \n        self.fc1 = nn.Linear(flattened_size, 256)\n        self.fc2 = nn.Linear(256, n_classes)\n    \n    def _forward_features(self, x):\n        channel_weights = []\n        for i in range(x.size(1)):\n            w = self.channel_attention(x[:, i, :])\n            channel_weights.append(w)\n        channel_weights = torch.cat(channel_weights, dim=1)\n        x = x * channel_weights.unsqueeze(2)\n        x = self.se1(x)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.se2(x)\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.se3(x)\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        return x\n    \n    def forward(self, x):\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.186291Z","iopub.execute_input":"2025-11-24T06:12:40.186552Z","iopub.status.idle":"2025-11-24T06:12:40.206075Z","shell.execute_reply.started":"2025-11-24T06:12:40.186528Z","shell.execute_reply":"2025-11-24T06:12:40.205398Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# G-CARM\nclass CARMBlock(nn.Module):\n    def __init__(self, n_channels):\n        super().__init__()\n        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n    \n    def forward(self, x):\n        A_norm = torch.softmax(self.A, dim=1)\n        x_reshaped = x.permute(0, 2, 1)\n        x_graph = torch.matmul(x_reshaped, A_norm.t())\n        return x_graph.permute(0, 2, 1)\n\n\nclass GCARM(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n        super().__init__()\n        self.carm1 = CARMBlock(n_channels)\n        self.carm2 = CARMBlock(n_channels)\n        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(2)\n        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.pool2 = nn.MaxPool1d(2)\n        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm1d(512)\n        self.pool3 = nn.MaxPool1d(2)\n        self.dropout = nn.Dropout(0.5)\n        \n        with torch.no_grad():\n            test_input = torch.zeros(1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n        \n        self.fc1 = nn.Linear(flattened_size, 256)\n        self.fc2 = nn.Linear(256, n_classes)\n    \n    def _forward_features(self, x):\n        x = self.carm1(x)\n        x = self.carm2(x)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        return x\n    \n    def forward(self, x):\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.206725Z","iopub.execute_input":"2025-11-24T06:12:40.206973Z","iopub.status.idle":"2025-11-24T06:12:40.225301Z","shell.execute_reply.started":"2025-11-24T06:12:40.206950Z","shell.execute_reply":"2025-11-24T06:12:40.224697Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## 5. Training Utilities","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss, correct, total = 0.0, 0, 0\n    \n    for X_batch, y_batch in dataloader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += y_batch.size(0)\n        correct += (predicted == y_batch).sum().item()\n    \n    return total_loss / max(1, len(dataloader)), correct / max(1, total)\n\n\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss, correct, total = 0.0, 0, 0\n    \n    with torch.no_grad():\n        for X_batch, y_batch in dataloader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            \n            total_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += y_batch.size(0)\n            correct += (predicted == y_batch).sum().item()\n    \n    return total_loss / max(1, len(dataloader)), correct / max(1, total)\n\n\ndef train_pytorch_model(model, train_loader, val_loader, config, model_name=''):\n    device = config['device']\n    model = model.to(device)\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], \n                          weight_decay=config['weight_decay'])\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=config['scheduler_factor'], \n        patience=config['scheduler_patience'], min_lr=config['min_lr'], verbose=False\n    )\n    \n    best_state = deepcopy(model.state_dict())\n    best_val_acc = 0.0\n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    for epoch in range(config['epochs']):\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n        scheduler.step(val_loss)\n        \n        improved = val_acc > best_val_acc or (val_acc == best_val_acc and val_loss < best_val_loss)\n        if improved:\n            best_state = deepcopy(model.state_dict())\n            best_val_acc = val_acc\n            best_val_loss = val_loss\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if epoch % 5 == 0 or improved:\n            print(f\"[{model_name}] Epoch {epoch+1}/{config['epochs']} - \"\n                  f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | Best: {best_val_acc:.4f}\")\n        \n        if config['use_early_stopping'] and patience_counter >= config['patience']:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    model.load_state_dict(best_state)\n    return best_state, model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.225990Z","iopub.execute_input":"2025-11-24T06:12:40.226211Z","iopub.status.idle":"2025-11-24T06:12:40.244584Z","shell.execute_reply.started":"2025-11-24T06:12:40.226187Z","shell.execute_reply":"2025-11-24T06:12:40.243918Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 6. Load Data","metadata":{}},{"cell_type":"code","source":"print(\"Loading PhysioNet data...\")\nX, y, subjects = load_physionet_data(CONFIG['data_path'])\nprint(f\"\\nData ready for training!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:40.245162Z","iopub.execute_input":"2025-11-24T06:12:40.245377Z","iopub.status.idle":"2025-11-24T06:12:58.303998Z","shell.execute_reply.started":"2025-11-24T06:12:40.245361Z","shell.execute_reply":"2025-11-24T06:12:58.303143Z"}},"outputs":[{"name":"stdout","text":"Loading PhysioNet data...\nLoading data from 51 subjects...\nLoaded 2966 trials from 51 subjects\nData shape: (2966, 64, 513)\nLabels: [1489 1477]\n\nData ready for training!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## 7. Train All Baseline Models","metadata":{}},{"cell_type":"code","source":"# Define models\nmodels_to_train = [\n    {'name': 'FBCSP', 'type': 'sklearn'},\n    {'name': 'CNN-SAE', 'type': 'pytorch'},\n    {'name': 'EEGNet', 'type': 'pytorch'},\n    {'name': 'ACS-SE-CNN', 'type': 'pytorch'},\n    {'name': 'G-CARM', 'type': 'pytorch'},\n]\n\nall_results = []\nskf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_seed'])\n\nprint(f\"\\n{'='*60}\")\nprint(\"TRAINING BASELINE METHODS\")\nprint(f\"{'='*60}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:58.304906Z","iopub.execute_input":"2025-11-24T06:12:58.305360Z","iopub.status.idle":"2025-11-24T06:12:58.310241Z","shell.execute_reply.started":"2025-11-24T06:12:58.305335Z","shell.execute_reply":"2025-11-24T06:12:58.309703Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING BASELINE METHODS\n============================================================\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Training loop\nfor model_info in models_to_train:\n    model_name = model_info['name']\n    model_type = model_info['type']\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Training {model_name}\")\n    print(f\"{'='*60}\\n\")\n    \n    fold_results = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        print(f\"\\nFold {fold + 1}/{CONFIG['n_folds']}\")\n        \n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n        \n        if model_type == 'sklearn':\n            model = FBCSP(freq_bands=CONFIG['fbcsp_bands'],\n                          n_components=CONFIG['fbcsp_n_components'],\n                          sfreq=CONFIG['sfreq'])\n            model.fit(X_train, y_train)\n            metrics = calculate_sklearn_metrics(model, X_val, y_val)\n            \n            model_path = os.path.join(CONFIG['models_dir'], f\"baseline_{model_name}_fold{fold+1}.pkl\")\n            with open(model_path, 'wb') as f:\n                pickle.dump(model, f)\n        else:\n            train_dataset = EEGDataset(X_train, y_train)\n            val_dataset = EEGDataset(X_val, y_val)\n            train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n            val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n            \n            base_kwargs = {\n                'n_channels': CONFIG['n_channels'],\n                'n_classes': CONFIG['n_classes'],\n                'n_timepoints': CONFIG['n_timepoints'],\n            }\n            \n            if model_name == 'CNN-SAE':\n                model = CNNSAE(**base_kwargs)\n            elif model_name == 'EEGNet':\n                model = EEGNet(**base_kwargs)\n            elif model_name == 'ACS-SE-CNN':\n                model = ACSECNN(**base_kwargs)\n            elif model_name == 'G-CARM':\n                model = GCARM(**base_kwargs)\n            \n            best_state, model = train_pytorch_model(model, train_loader, val_loader, CONFIG, model_name)\n            \n            # Calculate comprehensive metrics\n            metrics = calculate_comprehensive_metrics(model, val_loader, CONFIG['device'])\n            \n            model_path = os.path.join(CONFIG['models_dir'], f\"baseline_{model_name}_fold{fold+1}.pt\")\n            torch.save(best_state, model_path)\n            \n            del model\n            torch.cuda.empty_cache()\n            gc.collect()\n        \n        # Store results\n        result = {'fold': fold + 1}\n        result.update(metrics)\n        fold_results.append(result)\n        \n        print(f\"Fold {fold + 1} Results:\")\n        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n        print(f\"  Precision: {metrics['precision']:.4f}\")\n        print(f\"  Recall: {metrics['recall']:.4f}\")\n        print(f\"  F1-Score: {metrics['f1_score']:.4f}\")\n        print(f\"  AUC-ROC: {metrics['auc_roc']:.4f}\")\n        print(f\"  Specificity: {metrics['specificity']:.4f}\")\n    \n    # Calculate mean metrics\n    mean_metrics = {}\n    for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'specificity', 'sensitivity']:\n        values = [r[metric] for r in fold_results]\n        mean_metrics[f'mean_{metric}'] = np.mean(values)\n        mean_metrics[f'std_{metric}'] = np.std(values)\n    \n    print(f\"\\n{model_name} Summary:\")\n    print(f\"Mean Accuracy: {mean_metrics['mean_accuracy']:.4f} +/- {mean_metrics['std_accuracy']:.4f}\")\n    print(f\"Mean F1-Score: {mean_metrics['mean_f1_score']:.4f} +/- {mean_metrics['std_f1_score']:.4f}\")\n    print(f\"Mean AUC-ROC: {mean_metrics['mean_auc_roc']:.4f} +/- {mean_metrics['std_auc_roc']:.4f}\")\n    \n    all_results.append({\n        'model': model_name,\n        **mean_metrics,\n        'fold_results': fold_results\n    })\n\nprint(f\"\\n{'='*60}\")\nprint(\"ALL BASELINE MODELS TRAINED!\")\nprint(f\"{'='*60}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:12:58.310763Z","iopub.execute_input":"2025-11-24T06:12:58.310970Z","iopub.status.idle":"2025-11-24T06:22:29.434464Z","shell.execute_reply.started":"2025-11-24T06:12:58.310953Z","shell.execute_reply":"2025-11-24T06:22:29.433807Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTraining FBCSP\n============================================================\n\n\nFold 1/2\nFold 1 Results:\n  Accuracy: 0.6042\n  Precision: 0.6089\n  Recall: 0.5718\n  F1-Score: 0.5898\n  AUC-ROC: 0.0000\n  Specificity: 0.6362\n\nFold 2/2\nFold 2 Results:\n  Accuracy: 0.5705\n  Precision: 0.5733\n  Recall: 0.5399\n  F1-Score: 0.5561\n  AUC-ROC: 0.0000\n  Specificity: 0.6008\n\nFBCSP Summary:\nMean Accuracy: 0.5873 +/- 0.0169\nMean F1-Score: 0.5729 +/- 0.0168\nMean AUC-ROC: 0.0000 +/- 0.0000\n\n============================================================\nTraining CNN-SAE\n============================================================\n\n\nFold 1/2\n[CNN-SAE] Epoch 1/20 - Train: 0.6575 | Val: 0.5024 | Best: 0.5024\n[CNN-SAE] Epoch 3/20 - Train: 0.8287 | Val: 0.5024 | Best: 0.5024\n[CNN-SAE] Epoch 6/20 - Train: 0.8692 | Val: 0.5024 | Best: 0.5024\nEarly stopping at epoch 8\nFold 1 Results:\n  Accuracy: 0.5024\n  Precision: 0.0000\n  Recall: 0.0000\n  F1-Score: 0.0000\n  AUC-ROC: 0.8999\n  Specificity: 1.0000\n\nFold 2/2\n[CNN-SAE] Epoch 1/20 - Train: 0.6473 | Val: 0.5017 | Best: 0.5017\n[CNN-SAE] Epoch 2/20 - Train: 0.8018 | Val: 0.5017 | Best: 0.5017\n[CNN-SAE] Epoch 6/20 - Train: 0.8746 | Val: 0.4983 | Best: 0.5017\nEarly stopping at epoch 7\nFold 2 Results:\n  Accuracy: 0.5017\n  Precision: 0.0000\n  Recall: 0.0000\n  F1-Score: 0.0000\n  AUC-ROC: 0.8938\n  Specificity: 1.0000\n\nCNN-SAE Summary:\nMean Accuracy: 0.5020 +/- 0.0003\nMean F1-Score: 0.0000 +/- 0.0000\nMean AUC-ROC: 0.8968 +/- 0.0031\n\n============================================================\nTraining EEGNet\n============================================================\n\n\nFold 1/2\n[EEGNet] Epoch 1/20 - Train: 0.7330 | Val: 0.4976 | Best: 0.4976\n[EEGNet] Epoch 2/20 - Train: 0.7916 | Val: 0.4976 | Best: 0.4976\n[EEGNet] Epoch 3/20 - Train: 0.7991 | Val: 0.7067 | Best: 0.7067\n[EEGNet] Epoch 4/20 - Train: 0.8146 | Val: 0.8071 | Best: 0.8071\n[EEGNet] Epoch 5/20 - Train: 0.8307 | Val: 0.8260 | Best: 0.8260\n[EEGNet] Epoch 6/20 - Train: 0.8281 | Val: 0.8328 | Best: 0.8328\n[EEGNet] Epoch 11/20 - Train: 0.8503 | Val: 0.8321 | Best: 0.8328\nEarly stopping at epoch 11\nFold 1 Results:\n  Accuracy: 0.8328\n  Precision: 0.8275\n  Recall: 0.8388\n  F1-Score: 0.8331\n  AUC-ROC: 0.9149\n  Specificity: 0.8268\n\nFold 2/2\n[EEGNet] Epoch 1/20 - Train: 0.6709 | Val: 0.4983 | Best: 0.4983\n[EEGNet] Epoch 2/20 - Train: 0.8112 | Val: 0.7566 | Best: 0.7566\n[EEGNet] Epoch 4/20 - Train: 0.8415 | Val: 0.8078 | Best: 0.8078\n[EEGNet] Epoch 5/20 - Train: 0.8483 | Val: 0.8125 | Best: 0.8125\n[EEGNet] Epoch 6/20 - Train: 0.8382 | Val: 0.8200 | Best: 0.8200\n[EEGNet] Epoch 11/20 - Train: 0.8732 | Val: 0.8159 | Best: 0.8200\nEarly stopping at epoch 11\nFold 2 Results:\n  Accuracy: 0.8200\n  Precision: 0.7857\n  Recall: 0.8782\n  F1-Score: 0.8294\n  AUC-ROC: 0.9053\n  Specificity: 0.7621\n\nEEGNet Summary:\nMean Accuracy: 0.8264 +/- 0.0064\nMean F1-Score: 0.8313 +/- 0.0019\nMean AUC-ROC: 0.9101 +/- 0.0048\n\n============================================================\nTraining ACS-SE-CNN\n============================================================\n\n\nFold 1/2\n[ACS-SE-CNN] Epoch 1/20 - Train: 0.5307 | Val: 0.4976 | Best: 0.4976\n[ACS-SE-CNN] Epoch 2/20 - Train: 0.7053 | Val: 0.5024 | Best: 0.5024\n[ACS-SE-CNN] Epoch 6/20 - Train: 0.8341 | Val: 0.5024 | Best: 0.5024\nEarly stopping at epoch 7\nFold 1 Results:\n  Accuracy: 0.5024\n  Precision: 0.0000\n  Recall: 0.0000\n  F1-Score: 0.0000\n  AUC-ROC: 0.8921\n  Specificity: 1.0000\n\nFold 2/2\n[ACS-SE-CNN] Epoch 1/20 - Train: 0.5280 | Val: 0.5017 | Best: 0.5017\n[ACS-SE-CNN] Epoch 6/20 - Train: 0.8442 | Val: 0.5017 | Best: 0.5017\nEarly stopping at epoch 6\nFold 2 Results:\n  Accuracy: 0.5017\n  Precision: 0.0000\n  Recall: 0.0000\n  F1-Score: 0.0000\n  AUC-ROC: 0.7281\n  Specificity: 1.0000\n\nACS-SE-CNN Summary:\nMean Accuracy: 0.5020 +/- 0.0003\nMean F1-Score: 0.0000 +/- 0.0000\nMean AUC-ROC: 0.8101 +/- 0.0820\n\n============================================================\nTraining G-CARM\n============================================================\n\n\nFold 1/2\n[G-CARM] Epoch 1/20 - Train: 0.5078 | Val: 0.5024 | Best: 0.5024\n[G-CARM] Epoch 6/20 - Train: 0.5017 | Val: 0.5024 | Best: 0.5024\nEarly stopping at epoch 6\nFold 1 Results:\n  Accuracy: 0.5024\n  Precision: 0.0000\n  Recall: 0.0000\n  F1-Score: 0.0000\n  AUC-ROC: 0.5094\n  Specificity: 1.0000\n\nFold 2/2\n[G-CARM] Epoch 1/20 - Train: 0.5172 | Val: 0.4983 | Best: 0.4983\n[G-CARM] Epoch 2/20 - Train: 0.4788 | Val: 0.5017 | Best: 0.5017\n[G-CARM] Epoch 6/20 - Train: 0.5017 | Val: 0.5017 | Best: 0.5017\nEarly stopping at epoch 7\nFold 2 Results:\n  Accuracy: 0.5017\n  Precision: 0.0000\n  Recall: 0.0000\n  F1-Score: 0.0000\n  AUC-ROC: 0.5127\n  Specificity: 1.0000\n\nG-CARM Summary:\nMean Accuracy: 0.5020 +/- 0.0003\nMean F1-Score: 0.0000 +/- 0.0000\nMean AUC-ROC: 0.5110 +/- 0.0016\n\n============================================================\nALL BASELINE MODELS TRAINED!\n============================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## 8. Retention Analysis","metadata":{}},{"cell_type":"code","source":"# Variance-based channel importance\ndef get_channel_importance_variance(X_train):\n    \"\"\"Compute channel importance based on temporal variance.\"\"\"\n    channel_variance = np.var(X_train, axis=(0, 2))\n    return channel_variance\n\n\ndef select_top_k_channels(importance_scores, k):\n    \"\"\"Select top k channels based on importance scores.\"\"\"\n    top_k_indices = np.argsort(importance_scores)[-k:]\n    return sorted(top_k_indices)\n\n\ndef apply_channel_selection(X, selected_channels):\n    \"\"\"Apply channel selection to data.\"\"\"\n    return X[:, selected_channels, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:22:29.436449Z","iopub.execute_input":"2025-11-24T06:22:29.436747Z","iopub.status.idle":"2025-11-24T06:22:29.441504Z","shell.execute_reply.started":"2025-11-24T06:22:29.436731Z","shell.execute_reply":"2025-11-24T06:22:29.440883Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Retention analysis configuration\nRETENTION_MODEL = 'EEGNet'\n\nprint(f\"\\n{'='*60}\")\nprint(f\"RETENTION ANALYSIS: {RETENTION_MODEL}\")\nprint(f\"{'='*60}\\n\")\nprint(f\"k-values: {CONFIG['retention_k_values']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:22:29.442256Z","iopub.execute_input":"2025-11-24T06:22:29.442502Z","iopub.status.idle":"2025-11-24T06:22:29.463793Z","shell.execute_reply.started":"2025-11-24T06:22:29.442483Z","shell.execute_reply":"2025-11-24T06:22:29.463211Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nRETENTION ANALYSIS: EEGNet\n============================================================\n\nk-values: [10, 15, 20, 25, 30, 35]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Run retention analysis\nretention_results = []\n\nfor k in CONFIG['retention_k_values']:\n    print(f\"\\nTesting with k={k} channels:\")\n    fold_results = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n        \n        # Compute channel importance on training data\n        importance_scores = get_channel_importance_variance(X_train)\n        selected_channels = select_top_k_channels(importance_scores, k)\n        \n        # Apply channel selection\n        X_train_selected = apply_channel_selection(X_train, selected_channels)\n        X_val_selected = apply_channel_selection(X_val, selected_channels)\n        \n        # Train model with selected channels\n        train_dataset = EEGDataset(X_train_selected, y_train)\n        val_dataset = EEGDataset(X_val_selected, y_val)\n        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n        \n        model = EEGNet(n_channels=k, n_classes=CONFIG['n_classes'], n_timepoints=CONFIG['n_timepoints'])\n        best_state, model = train_pytorch_model(model, train_loader, val_loader, CONFIG, f\"Retention-k{k}\")\n        \n        # Calculate comprehensive metrics\n        metrics = calculate_comprehensive_metrics(model, val_loader, CONFIG['device'])\n        \n        result = {'fold': fold + 1}\n        result.update(metrics)\n        fold_results.append(result)\n        \n        del model\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    # Calculate mean metrics\n    mean_metrics = {}\n    for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'specificity', 'sensitivity']:\n        values = [r[metric] for r in fold_results]\n        mean_metrics[f'mean_{metric}'] = np.mean(values)\n        mean_metrics[f'std_{metric}'] = np.std(values)\n    \n    print(f\"k={k} Results:\")\n    print(f\"  Accuracy: {mean_metrics['mean_accuracy']:.4f} +/- {mean_metrics['std_accuracy']:.4f}\")\n    print(f\"  F1-Score: {mean_metrics['mean_f1_score']:.4f} +/- {mean_metrics['std_f1_score']:.4f}\")\n    print(f\"  AUC-ROC: {mean_metrics['mean_auc_roc']:.4f} +/- {mean_metrics['std_auc_roc']:.4f}\")\n    \n    retention_results.append({\n        'model': RETENTION_MODEL,\n        'k': k,\n        **mean_metrics,\n        'fold_results': fold_results\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:22:29.464559Z","iopub.execute_input":"2025-11-24T06:22:29.465218Z","iopub.status.idle":"2025-11-24T06:23:41.054386Z","shell.execute_reply.started":"2025-11-24T06:22:29.465196Z","shell.execute_reply":"2025-11-24T06:23:41.053695Z"}},"outputs":[{"name":"stdout","text":"\nTesting with k=10 channels:\n[Retention-k10] Epoch 1/20 - Train: 0.7256 | Val: 0.4976 | Best: 0.4976\n[Retention-k10] Epoch 3/20 - Train: 0.7701 | Val: 0.6102 | Best: 0.6102\n[Retention-k10] Epoch 4/20 - Train: 0.7876 | Val: 0.7869 | Best: 0.7869\n[Retention-k10] Epoch 5/20 - Train: 0.7734 | Val: 0.8051 | Best: 0.8051\n[Retention-k10] Epoch 6/20 - Train: 0.7788 | Val: 0.7930 | Best: 0.8051\nEarly stopping at epoch 10\n[Retention-k10] Epoch 1/20 - Train: 0.6905 | Val: 0.5017 | Best: 0.5017\n[Retention-k10] Epoch 2/20 - Train: 0.7896 | Val: 0.5981 | Best: 0.5981\n[Retention-k10] Epoch 3/20 - Train: 0.7977 | Val: 0.7525 | Best: 0.7525\n[Retention-k10] Epoch 4/20 - Train: 0.7984 | Val: 0.7808 | Best: 0.7808\n[Retention-k10] Epoch 5/20 - Train: 0.8105 | Val: 0.7862 | Best: 0.7862\n[Retention-k10] Epoch 6/20 - Train: 0.8031 | Val: 0.7795 | Best: 0.7862\n[Retention-k10] Epoch 7/20 - Train: 0.8071 | Val: 0.7950 | Best: 0.7950\n[Retention-k10] Epoch 11/20 - Train: 0.8247 | Val: 0.7923 | Best: 0.7950\nEarly stopping at epoch 12\nk=10 Results:\n  Accuracy: 0.8001 +/- 0.0051\n  F1-Score: 0.7984 +/- 0.0054\n  AUC-ROC: 0.8843 +/- 0.0060\n\nTesting with k=15 channels:\n[Retention-k15] Epoch 1/20 - Train: 0.7067 | Val: 0.4976 | Best: 0.4976\n[Retention-k15] Epoch 2/20 - Train: 0.7721 | Val: 0.4976 | Best: 0.4976\n[Retention-k15] Epoch 3/20 - Train: 0.7862 | Val: 0.7222 | Best: 0.7222\n[Retention-k15] Epoch 4/20 - Train: 0.7964 | Val: 0.7674 | Best: 0.7674\n[Retention-k15] Epoch 5/20 - Train: 0.7943 | Val: 0.8105 | Best: 0.8105\n[Retention-k15] Epoch 6/20 - Train: 0.8038 | Val: 0.8085 | Best: 0.8105\n[Retention-k15] Epoch 8/20 - Train: 0.8132 | Val: 0.8146 | Best: 0.8146\n[Retention-k15] Epoch 11/20 - Train: 0.8159 | Val: 0.8085 | Best: 0.8146\nEarly stopping at epoch 13\n[Retention-k15] Epoch 1/20 - Train: 0.7154 | Val: 0.5017 | Best: 0.5017\n[Retention-k15] Epoch 2/20 - Train: 0.7829 | Val: 0.5017 | Best: 0.5017\n[Retention-k15] Epoch 3/20 - Train: 0.7991 | Val: 0.5550 | Best: 0.5550\n[Retention-k15] Epoch 4/20 - Train: 0.8031 | Val: 0.7680 | Best: 0.7680\n[Retention-k15] Epoch 5/20 - Train: 0.8011 | Val: 0.7862 | Best: 0.7862\n[Retention-k15] Epoch 6/20 - Train: 0.8193 | Val: 0.7943 | Best: 0.7943\n[Retention-k15] Epoch 11/20 - Train: 0.8206 | Val: 0.7943 | Best: 0.7943\nEarly stopping at epoch 11\nk=15 Results:\n  Accuracy: 0.8045 +/- 0.0101\n  F1-Score: 0.8033 +/- 0.0054\n  AUC-ROC: 0.8943 +/- 0.0096\n\nTesting with k=20 channels:\n[Retention-k20] Epoch 1/20 - Train: 0.7141 | Val: 0.5024 | Best: 0.5024\n[Retention-k20] Epoch 2/20 - Train: 0.7782 | Val: 0.5024 | Best: 0.5024\n[Retention-k20] Epoch 3/20 - Train: 0.7937 | Val: 0.7970 | Best: 0.7970\n[Retention-k20] Epoch 5/20 - Train: 0.8031 | Val: 0.8098 | Best: 0.8098\n[Retention-k20] Epoch 6/20 - Train: 0.8018 | Val: 0.8105 | Best: 0.8105\n[Retention-k20] Epoch 10/20 - Train: 0.8193 | Val: 0.8119 | Best: 0.8119\n[Retention-k20] Epoch 11/20 - Train: 0.8227 | Val: 0.8078 | Best: 0.8119\nEarly stopping at epoch 15\n[Retention-k20] Epoch 1/20 - Train: 0.7195 | Val: 0.5017 | Best: 0.5017\n[Retention-k20] Epoch 2/20 - Train: 0.8078 | Val: 0.5017 | Best: 0.5017\n[Retention-k20] Epoch 3/20 - Train: 0.8200 | Val: 0.5914 | Best: 0.5914\n[Retention-k20] Epoch 4/20 - Train: 0.8233 | Val: 0.7950 | Best: 0.7950\n[Retention-k20] Epoch 5/20 - Train: 0.8213 | Val: 0.8024 | Best: 0.8024\n[Retention-k20] Epoch 6/20 - Train: 0.8159 | Val: 0.8004 | Best: 0.8024\n[Retention-k20] Epoch 10/20 - Train: 0.8334 | Val: 0.8085 | Best: 0.8085\n[Retention-k20] Epoch 11/20 - Train: 0.8436 | Val: 0.8011 | Best: 0.8085\nEarly stopping at epoch 15\nk=20 Results:\n  Accuracy: 0.8102 +/- 0.0017\n  F1-Score: 0.8109 +/- 0.0008\n  AUC-ROC: 0.8959 +/- 0.0069\n\nTesting with k=25 channels:\n[Retention-k25] Epoch 1/20 - Train: 0.7100 | Val: 0.4976 | Best: 0.4976\n[Retention-k25] Epoch 2/20 - Train: 0.7856 | Val: 0.4976 | Best: 0.4976\n[Retention-k25] Epoch 3/20 - Train: 0.7984 | Val: 0.7734 | Best: 0.7734\n[Retention-k25] Epoch 4/20 - Train: 0.8098 | Val: 0.7970 | Best: 0.7970\n[Retention-k25] Epoch 5/20 - Train: 0.8132 | Val: 0.8227 | Best: 0.8227\n[Retention-k25] Epoch 6/20 - Train: 0.8078 | Val: 0.8105 | Best: 0.8227\n[Retention-k25] Epoch 7/20 - Train: 0.8105 | Val: 0.8301 | Best: 0.8301\n[Retention-k25] Epoch 11/20 - Train: 0.8206 | Val: 0.8193 | Best: 0.8301\nEarly stopping at epoch 12\n[Retention-k25] Epoch 1/20 - Train: 0.7283 | Val: 0.5017 | Best: 0.5017\n[Retention-k25] Epoch 2/20 - Train: 0.8092 | Val: 0.5078 | Best: 0.5078\n[Retention-k25] Epoch 3/20 - Train: 0.8119 | Val: 0.5341 | Best: 0.5341\n[Retention-k25] Epoch 4/20 - Train: 0.8038 | Val: 0.6339 | Best: 0.6339\n[Retention-k25] Epoch 5/20 - Train: 0.8247 | Val: 0.7316 | Best: 0.7316\n[Retention-k25] Epoch 6/20 - Train: 0.8200 | Val: 0.7916 | Best: 0.7916\n[Retention-k25] Epoch 7/20 - Train: 0.8355 | Val: 0.7977 | Best: 0.7977\n[Retention-k25] Epoch 9/20 - Train: 0.8328 | Val: 0.8011 | Best: 0.8011\n[Retention-k25] Epoch 11/20 - Train: 0.8375 | Val: 0.7444 | Best: 0.8011\n[Retention-k25] Epoch 13/20 - Train: 0.8328 | Val: 0.8078 | Best: 0.8078\n[Retention-k25] Epoch 16/20 - Train: 0.8422 | Val: 0.8071 | Best: 0.8078\n[Retention-k25] Epoch 17/20 - Train: 0.8463 | Val: 0.8078 | Best: 0.8078\n[Retention-k25] Epoch 19/20 - Train: 0.8597 | Val: 0.8098 | Best: 0.8098\nk=25 Results:\n  Accuracy: 0.8200 +/- 0.0101\n  F1-Score: 0.8195 +/- 0.0105\n  AUC-ROC: 0.8987 +/- 0.0061\n\nTesting with k=30 channels:\n[Retention-k30] Epoch 1/20 - Train: 0.7323 | Val: 0.6143 | Best: 0.6143\n[Retention-k30] Epoch 3/20 - Train: 0.7835 | Val: 0.7532 | Best: 0.7532\n[Retention-k30] Epoch 4/20 - Train: 0.8038 | Val: 0.8146 | Best: 0.8146\n[Retention-k30] Epoch 6/20 - Train: 0.8112 | Val: 0.7916 | Best: 0.8146\n[Retention-k30] Epoch 8/20 - Train: 0.8159 | Val: 0.8200 | Best: 0.8200\n[Retention-k30] Epoch 11/20 - Train: 0.8314 | Val: 0.7802 | Best: 0.8200\nEarly stopping at epoch 13\n[Retention-k30] Epoch 1/20 - Train: 0.7269 | Val: 0.5017 | Best: 0.5017\n[Retention-k30] Epoch 3/20 - Train: 0.8092 | Val: 0.7957 | Best: 0.7957\n[Retention-k30] Epoch 4/20 - Train: 0.8206 | Val: 0.8018 | Best: 0.8018\n[Retention-k30] Epoch 5/20 - Train: 0.8301 | Val: 0.8085 | Best: 0.8085\n[Retention-k30] Epoch 6/20 - Train: 0.8321 | Val: 0.8038 | Best: 0.8085\nEarly stopping at epoch 10\nk=30 Results:\n  Accuracy: 0.8142 +/- 0.0057\n  F1-Score: 0.8167 +/- 0.0112\n  AUC-ROC: 0.8969 +/- 0.0081\n\nTesting with k=35 channels:\n[Retention-k35] Epoch 1/20 - Train: 0.7107 | Val: 0.4976 | Best: 0.4976\n[Retention-k35] Epoch 2/20 - Train: 0.7943 | Val: 0.4976 | Best: 0.4976\n[Retention-k35] Epoch 3/20 - Train: 0.7970 | Val: 0.8334 | Best: 0.8334\n[Retention-k35] Epoch 6/20 - Train: 0.8119 | Val: 0.8227 | Best: 0.8334\nEarly stopping at epoch 8\n[Retention-k35] Epoch 1/20 - Train: 0.7154 | Val: 0.5017 | Best: 0.5017\n[Retention-k35] Epoch 2/20 - Train: 0.7997 | Val: 0.5017 | Best: 0.5017\n[Retention-k35] Epoch 4/20 - Train: 0.8274 | Val: 0.7188 | Best: 0.7188\n[Retention-k35] Epoch 5/20 - Train: 0.8247 | Val: 0.7991 | Best: 0.7991\n[Retention-k35] Epoch 6/20 - Train: 0.8254 | Val: 0.8139 | Best: 0.8139\n[Retention-k35] Epoch 11/20 - Train: 0.8456 | Val: 0.8146 | Best: 0.8146\n[Retention-k35] Epoch 16/20 - Train: 0.8550 | Val: 0.8058 | Best: 0.8146\nEarly stopping at epoch 16\nk=35 Results:\n  Accuracy: 0.8240 +/- 0.0094\n  F1-Score: 0.8258 +/- 0.0081\n  AUC-ROC: 0.9030 +/- 0.0048\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## 9. Save All Results","metadata":{}},{"cell_type":"code","source":"# Prepare detailed results\ndetailed_results = []\nfor result in all_results:\n    for fold_result in result['fold_results']:\n        detailed_results.append({\n            'model': result['model'],\n            'fold': fold_result['fold'],\n            'accuracy': fold_result['accuracy'],\n            'precision': fold_result['precision'],\n            'recall': fold_result['recall'],\n            'f1_score': fold_result['f1_score'],\n            'auc_roc': fold_result['auc_roc'],\n            'specificity': fold_result['specificity'],\n            'sensitivity': fold_result['sensitivity']\n        })\n\ndetailed_df = pd.DataFrame(detailed_results)\ndetailed_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_methods_results.csv'), index=False)\n\n# Prepare summary\nsummary_data = []\nfor result in all_results:\n    summary_data.append({\n        'model': result['model'],\n        'mean_accuracy': result['mean_accuracy'],\n        'std_accuracy': result['std_accuracy'],\n        'mean_precision': result['mean_precision'],\n        'std_precision': result['std_precision'],\n        'mean_recall': result['mean_recall'],\n        'std_recall': result['std_recall'],\n        'mean_f1_score': result['mean_f1_score'],\n        'std_f1_score': result['std_f1_score'],\n        'mean_auc_roc': result['mean_auc_roc'],\n        'std_auc_roc': result['std_auc_roc'],\n        'mean_specificity': result['mean_specificity'],\n        'std_specificity': result['std_specificity'],\n        'mean_sensitivity': result['mean_sensitivity'],\n        'std_sensitivity': result['std_sensitivity']\n    })\n\nsummary_df = pd.DataFrame(summary_data)\nsummary_df = summary_df.sort_values('mean_accuracy', ascending=False).reset_index(drop=True)\nsummary_df['rank'] = range(1, len(summary_df) + 1)\nsummary_df = summary_df[['rank', 'model', 'mean_accuracy', 'std_accuracy', 'mean_precision', 'std_precision',\n                         'mean_recall', 'std_recall', 'mean_f1_score', 'std_f1_score', 'mean_auc_roc', 'std_auc_roc',\n                         'mean_specificity', 'std_specificity', 'mean_sensitivity', 'std_sensitivity']]\nsummary_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_methods_summary.csv'), index=False)\n\nprint(\"\\nResults saved to:\")\nprint(\"  - results/baseline_methods_results.csv\")\nprint(\"  - results/baseline_methods_summary.csv\")\n\nprint(\"\\nBaseline Methods Summary:\")\nprint(summary_df[['rank', 'model', 'mean_accuracy', 'mean_f1_score', 'mean_auc_roc']].to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:23:41.055641Z","iopub.execute_input":"2025-11-24T06:23:41.055871Z","iopub.status.idle":"2025-11-24T06:23:41.089325Z","shell.execute_reply.started":"2025-11-24T06:23:41.055854Z","shell.execute_reply":"2025-11-24T06:23:41.088785Z"}},"outputs":[{"name":"stdout","text":"\nResults saved to:\n  - results/baseline_methods_results.csv\n  - results/baseline_methods_summary.csv\n\nBaseline Methods Summary:\n rank      model  mean_accuracy  mean_f1_score  mean_auc_roc\n    1     EEGNet       0.826365       0.831251      0.910054\n    2      FBCSP       0.587323       0.572947      0.000000\n    3    CNN-SAE       0.502023       0.000000      0.896810\n    4 ACS-SE-CNN       0.502023       0.000000      0.810095\n    5     G-CARM       0.502023       0.000000      0.511041\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Save retention results\nretention_detailed = []\nfor result in retention_results:\n    for fold_result in result['fold_results']:\n        retention_detailed.append({\n            'model': result['model'],\n            'k': result['k'],\n            'fold': fold_result['fold'],\n            'accuracy': fold_result['accuracy'],\n            'precision': fold_result['precision'],\n            'recall': fold_result['recall'],\n            'f1_score': fold_result['f1_score'],\n            'auc_roc': fold_result['auc_roc'],\n            'specificity': fold_result['specificity'],\n            'sensitivity': fold_result['sensitivity']\n        })\n\nretention_detailed_df = pd.DataFrame(retention_detailed)\nretention_detailed_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_retention_analysis.csv'), index=False)\n\n# Retention summary\nretention_summary = []\nfor result in retention_results:\n    retention_summary.append({\n        'model': result['model'],\n        'k': result['k'],\n        'mean_accuracy': result['mean_accuracy'],\n        'std_accuracy': result['std_accuracy'],\n        'mean_f1_score': result['mean_f1_score'],\n        'std_f1_score': result['std_f1_score'],\n        'mean_auc_roc': result['mean_auc_roc'],\n        'std_auc_roc': result['std_auc_roc']\n    })\n\nretention_summary_df = pd.DataFrame(retention_summary)\n\nprint(\"\\nRetention Analysis Results:\")\nprint(retention_summary_df[['k', 'mean_accuracy', 'mean_f1_score', 'mean_auc_roc']].to_string(index=False))\n\nprint(\"\\nResults saved to: results/baseline_retention_analysis.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:23:41.090052Z","iopub.execute_input":"2025-11-24T06:23:41.090681Z","iopub.status.idle":"2025-11-24T06:23:41.100780Z","shell.execute_reply.started":"2025-11-24T06:23:41.090663Z","shell.execute_reply":"2025-11-24T06:23:41.100066Z"}},"outputs":[{"name":"stdout","text":"\nRetention Analysis Results:\n k  mean_accuracy  mean_f1_score  mean_auc_roc\n10       0.800067       0.798359      0.884251\n15       0.804450       0.803254      0.894295\n20       0.810182       0.810873      0.895934\n25       0.819960       0.819451      0.898742\n30       0.814228       0.816666      0.896916\n35       0.824005       0.825827      0.903013\n\nResults saved to: results/baseline_retention_analysis.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## 10. Final Summary","metadata":{}},{"cell_type":"code","source":"print(f\"\\n{'='*60}\")\nprint(\"PIPELINE 1 COMPLETE!\")\nprint(f\"{'='*60}\")\n\nprint(\"\\nAll comprehensive metrics have been calculated and saved.\")\nprint(\"\\nOutputs:\")\nprint(\"  1. baseline_methods_results.csv - Detailed per-fold results with all metrics\")\nprint(\"  2. baseline_methods_summary.csv - Summary statistics with rankings\")\nprint(\"  3. baseline_retention_analysis.csv - Retention curve data\")\nprint(\"\\nReady for comparison with Pipeline 2!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:23:41.101581Z","iopub.execute_input":"2025-11-24T06:23:41.101897Z","iopub.status.idle":"2025-11-24T06:23:41.115593Z","shell.execute_reply.started":"2025-11-24T06:23:41.101875Z","shell.execute_reply":"2025-11-24T06:23:41.114952Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nPIPELINE 1 COMPLETE!\n============================================================\n\nAll comprehensive metrics have been calculated and saved.\n\nOutputs:\n  1. baseline_methods_results.csv - Detailed per-fold results with all metrics\n  2. baseline_methods_summary.csv - Summary statistics with rankings\n  3. baseline_retention_analysis.csv - Retention curve data\n\nReady for comparison with Pipeline 2!\n","output_type":"stream"}],"execution_count":19}]}