{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2967738,"sourceType":"datasetVersion","datasetId":1819423}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PhysioNet Motor Imagery - Legacy Baseline Methods\n\n## Comprehensive Evaluation of 5 Baseline Methods\n\nThis notebook trains and evaluates:\n1. **FBCSP** - Filter Bank Common Spatial Patterns with LDA\n2. **CNN-SAE** - CNN with Spatial Attention\n3. **EEGNet** - Compact convolutional network\n4. **ACS-SE-CNN** - Attention + Squeeze-Excitation CNN\n5. **G-CARM** - Graph-based CARM\n\n## Configuration:\n- **30 epochs**, **0.0015 LR** (for PyTorch models)\n- **10 subjects**, **3-fold CV**\n- **9 filter banks**, **4 CSP components** (for FBCSP)\n\n## Metrics:\n- Accuracy, Precision, Recall, F1-Score, AUC-ROC, Specificity\n\n## Output:\n- `legacy_fbcsp_results.csv`\n- `legacy_cnn_sae_results.csv`\n- `legacy_eegnet_results.csv`\n- `legacy_acs_se_cnn_results.csv`\n- `legacy_g_carm_results.csv`","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup and Imports","metadata":{}},{"cell_type":"code","source":"import json\nimport random\nimport warnings\nfrom pathlib import Path\nfrom copy import deepcopy\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, confusion_matrix\n)\nfrom scipy.signal import butter, filtfilt\nimport gc\n\nimport mne\nfrom mne.decoding import CSP\n\nwarnings.filterwarnings('ignore')\nsns.set_context('notebook', font_scale=1.0)\nmne.set_log_level('WARNING')\n\ndef set_seed(s=42):\n    random.seed(s)\n    np.random.seed(s)\n    torch.manual_seed(s)\n    torch.cuda.manual_seed_all(s)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Device: {device}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:21.741097Z","iopub.execute_input":"2025-11-25T03:27:21.741391Z","iopub.status.idle":"2025-11-25T03:27:21.808654Z","shell.execute_reply.started":"2025-11-25T03:27:21.741368Z","shell.execute_reply":"2025-11-25T03:27:21.808026Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 2. Configuration","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nif os.path.exists('/kaggle/input'):\n    print(\"Running on Kaggle\")\n    kaggle_input = Path('/kaggle/input')\n    datasets = [d for d in kaggle_input.iterdir() if d.is_dir()]\n    print(f\"Available datasets: {[d.name for d in datasets]}\")\n\n    DATA_DIR = None\n    possible_names = ['physioneteegmi', 'eeg-motor-movementimagery-dataset']\n    for ds_name in possible_names:\n        test_path = kaggle_input / ds_name\n        if test_path.exists():\n            DATA_DIR = test_path\n            print(f\"Found dataset: {DATA_DIR}\")\n            break\n\n    if DATA_DIR is None and datasets:\n        DATA_DIR = datasets[0]\n        print(f\"Using first available dataset: {DATA_DIR}\")\nelse:\n    print(\"Running locally\")\n    DATA_DIR = Path('data/physionet/files')\n\nCONFIG = {\n    'data': {\n        'raw_data_dir': DATA_DIR,\n        'selected_classes': [1, 2],\n        'tmin': -1.0,\n        'tmax': 5.0,\n        'baseline': (-0.5, 0)\n    },\n    'preprocessing': {\n        'l_freq': 0.5,\n        'h_freq': 40.0,\n        'notch_freq': 50.0,\n        'target_sfreq': 128.0,\n        'apply_car': True\n    },\n    'model': {\n        'epochs': 30,\n        'learning_rate': 0.0015,\n        'batch_size': 64,\n        'n_folds': 3,\n        'patience': 10\n    },\n    'fbcsp': {\n        'freq_bands': [\n            (4, 8), (8, 12), (12, 16), (16, 20), (20, 24),\n            (24, 28), (28, 32), (32, 36), (36, 40)\n        ],\n        'n_components': 4\n    },\n    'output': {\n        'results_dir': Path('results'),\n    },\n    'max_subjects': 10,\n    'min_runs_per_subject': 8\n}\n\nCONFIG['output']['results_dir'].mkdir(exist_ok=True, parents=True)\n\nprint(f\"\\nConfiguration loaded!\")\nprint(f\"Training: {CONFIG['max_subjects']} subjects, {CONFIG['model']['n_folds']}-fold CV, {CONFIG['model']['epochs']} epochs\")\nprint(f\"FBCSP: {len(CONFIG['fbcsp']['freq_bands'])} filter banks, {CONFIG['fbcsp']['n_components']} components\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:21.809762Z","iopub.execute_input":"2025-11-25T03:27:21.809987Z","iopub.status.idle":"2025-11-25T03:27:21.820879Z","shell.execute_reply.started":"2025-11-25T03:27:21.809970Z","shell.execute_reply":"2025-11-25T03:27:21.820245Z"}},"outputs":[{"name":"stdout","text":"Running on Kaggle\nAvailable datasets: ['physioneteegmi']\nFound dataset: /kaggle/input/physioneteegmi\n\nConfiguration loaded!\nTraining: 10 subjects, 3-fold CV, 30 epochs\nFBCSP: 9 filter banks, 4 components\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 3. Data Cleaning - Remove Faulty Subjects","metadata":{}},{"cell_type":"code","source":"KNOWN_BAD_SUBJECTS = [\n    'S088', 'S089', 'S092', 'S100', 'S104', 'S106', 'S107', 'S108', 'S109'\n]\n\nHIGH_ISSUE_SUBJECTS = [\n    'S003', 'S004', 'S009', 'S010', 'S012', 'S013', 'S017', 'S018', 'S019',\n    'S021', 'S022', 'S023', 'S024', 'S025', 'S026', 'S027', 'S028', 'S029'\n]\n\nEXCLUDED_SUBJECTS = set(KNOWN_BAD_SUBJECTS + HIGH_ISSUE_SUBJECTS)\n\nprint(f\"Total excluded subjects: {len(EXCLUDED_SUBJECTS)}\")\nprint(f\"Excluded subjects: {sorted(EXCLUDED_SUBJECTS)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:21.821503Z","iopub.execute_input":"2025-11-25T03:27:21.821733Z","iopub.status.idle":"2025-11-25T03:27:21.834517Z","shell.execute_reply.started":"2025-11-25T03:27:21.821709Z","shell.execute_reply":"2025-11-25T03:27:21.833971Z"}},"outputs":[{"name":"stdout","text":"Total excluded subjects: 27\nExcluded subjects: ['S003', 'S004', 'S009', 'S010', 'S012', 'S013', 'S017', 'S018', 'S019', 'S021', 'S022', 'S023', 'S024', 'S025', 'S026', 'S027', 'S028', 'S029', 'S088', 'S089', 'S092', 'S100', 'S104', 'S106', 'S107', 'S108', 'S109']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 4. Data Loading and Preprocessing Functions","metadata":{}},{"cell_type":"code","source":"def preprocess_raw(raw, config):\n    cleaned_names = {name: name.rstrip('.') for name in raw.ch_names}\n    raw.rename_channels(cleaned_names)\n    raw.pick_types(eeg=True)\n    raw.set_montage('standard_1020', on_missing='ignore', match_case=False)\n    \n    nyquist = raw.info['sfreq'] / 2.0\n    if config['preprocessing']['notch_freq'] < nyquist:\n        raw.notch_filter(freqs=config['preprocessing']['notch_freq'], verbose=False)\n    \n    raw.filter(\n        l_freq=config['preprocessing']['l_freq'],\n        h_freq=config['preprocessing']['h_freq'],\n        method='fir',\n        fir_design='firwin',\n        verbose=False\n    )\n    \n    if config['preprocessing']['apply_car']:\n        raw.set_eeg_reference('average', projection=False, verbose=False)\n    \n    raw.resample(config['preprocessing']['target_sfreq'], npad='auto', verbose=False)\n    return raw\n\n\ndef load_and_preprocess_edf(edf_path, config):\n    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n    raw = preprocess_raw(raw, config)\n    \n    events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n    \n    if len(events) == 0:\n        return None, None, raw.ch_names\n    \n    epochs = mne.Epochs(\n        raw,\n        events,\n        event_id=event_ids,\n        tmin=config['data']['tmin'],\n        tmax=config['data']['tmax'],\n        baseline=tuple(config['data']['baseline']),\n        preload=True,\n        verbose='ERROR'\n    )\n    \n    return epochs.get_data(), epochs.events[:, 2], raw.ch_names\n\n\ndef filter_classes(x, y, selected_classes):\n    mask = np.isin(y, selected_classes)\n    y, x = y[mask], x[mask]\n    label_map = {old: new for new, old in enumerate(sorted(selected_classes))}\n    y = np.array([label_map[int(label)] for label in y], dtype=np.int64)\n    return x, y\n\n\ndef normalize(x):\n    mu = x.mean(axis=(0, 2), keepdims=True)\n    sd = x.std(axis=(0, 2), keepdims=True) + 1e-8\n    return (x - mu) / sd\n\n\ndef load_subject_data(data_dir, subject_id, run_ids, config):\n    subject_dir = data_dir / subject_id\n    if not subject_dir.exists():\n        return None, None, None\n    \n    all_x, all_y = [], []\n    channel_names = None\n    \n    for run_id in run_ids:\n        edf_path = subject_dir / f'{subject_id}{run_id}.edf'\n        if not edf_path.exists():\n            continue\n        \n        try:\n            x, y, ch_names = load_and_preprocess_edf(edf_path, config)\n            if x is None or len(y) == 0:\n                continue\n            \n            x, y = filter_classes(x, y, config['data']['selected_classes'])\n            if len(y) == 0:\n                continue\n            \n            channel_names = channel_names or ch_names\n            all_x.append(x)\n            all_y.append(y)\n        except Exception as e:\n            print(f\"  Warning: Failed to load {edf_path.name}: {e}\")\n            continue\n    \n    if len(all_x) == 0:\n        return None, None, channel_names\n    \n    return np.concatenate(all_x, 0), np.concatenate(all_y, 0), channel_names\n\n\ndef get_available_subjects(data_dir, min_runs=8, excluded=None):\n    if not data_dir.exists():\n        raise ValueError(f\"Data directory not found: {data_dir}\")\n    \n    excluded = excluded or set()\n    subjects = []\n    \n    for subject_dir in sorted(data_dir.iterdir()):\n        if not subject_dir.is_dir() or not subject_dir.name.startswith('S'):\n            continue\n        \n        if subject_dir.name in excluded:\n            continue\n        \n        edf_files = list(subject_dir.glob('*.edf'))\n        if len(edf_files) >= min_runs:\n            subjects.append(subject_dir.name)\n    \n    return subjects\n\n\nprint(\"\\nScanning for subjects...\")\ndata_dir = CONFIG['data']['raw_data_dir']\nprint(f\"Looking for data in: {data_dir}\")\n\nall_subjects = get_available_subjects(\n    data_dir, \n    min_runs=CONFIG['min_runs_per_subject'],\n    excluded=EXCLUDED_SUBJECTS\n)\nsubjects = all_subjects[:CONFIG['max_subjects']]\n\nprint(f\"Found {len(all_subjects)} clean subjects with >= {CONFIG['min_runs_per_subject']} runs\")\nprint(f\"Will process {len(subjects)} subjects: {subjects}\")\n\nMOTOR_IMAGERY_RUNS = ['R07', 'R08', 'R09', 'R10', 'R11', 'R12', 'R13', 'R14']\nMOTOR_EXECUTION_RUNS = ['R03', 'R04', 'R05', 'R06']\nALL_TASK_RUNS = MOTOR_IMAGERY_RUNS + MOTOR_EXECUTION_RUNS\nprint(f\"Using runs: {ALL_TASK_RUNS}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:21.835710Z","iopub.execute_input":"2025-11-25T03:27:21.835935Z","iopub.status.idle":"2025-11-25T03:27:22.798584Z","shell.execute_reply.started":"2025-11-25T03:27:21.835920Z","shell.execute_reply":"2025-11-25T03:27:22.797923Z"}},"outputs":[{"name":"stdout","text":"\nScanning for subjects...\nLooking for data in: /kaggle/input/physioneteegmi\nFound 82 clean subjects with >= 8 runs\nWill process 10 subjects: ['S001', 'S002', 'S005', 'S006', 'S007', 'S008', 'S011', 'S014', 'S015', 'S016']\nUsing runs: ['R07', 'R08', 'R09', 'R10', 'R11', 'R12', 'R13', 'R14', 'R03', 'R04', 'R05', 'R06']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 5. PyTorch Dataset","metadata":{}},{"cell_type":"code","source":"class EEGDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = torch.FloatTensor(x).unsqueeze(1)\n        self.y = torch.LongTensor(y)\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, i):\n        return self.x[i], self.y[i]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.799297Z","iopub.execute_input":"2025-11-25T03:27:22.799549Z","iopub.status.idle":"2025-11-25T03:27:22.803805Z","shell.execute_reply.started":"2025-11-25T03:27:22.799530Z","shell.execute_reply":"2025-11-25T03:27:22.803075Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 6. Comprehensive Metrics Functions","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef calculate_comprehensive_metrics(model, dataloader, device):\n    model.eval()\n    all_preds, all_labels, all_probs = [], [], []\n\n    for X_batch, y_batch in dataloader:\n        X_batch = X_batch.to(device)\n        outputs = model(X_batch)\n        probs = torch.softmax(outputs, dim=1)\n        _, predicted = torch.max(outputs, 1)\n\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(y_batch.numpy())\n        all_probs.extend(probs[:, 1].cpu().numpy())\n\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    all_probs = np.array(all_probs)\n\n    metrics = {\n        'accuracy': accuracy_score(all_labels, all_preds),\n        'precision': precision_score(all_labels, all_preds, average='binary', zero_division=0),\n        'recall': recall_score(all_labels, all_preds, average='binary', zero_division=0),\n        'f1_score': f1_score(all_labels, all_preds, average='binary', zero_division=0),\n        'auc_roc': roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.0,\n    }\n\n    cm = confusion_matrix(all_labels, all_preds)\n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    else:\n        metrics['specificity'] = 0.0\n        metrics['sensitivity'] = metrics['recall']\n\n    return metrics\n\n\ndef calculate_sklearn_metrics(y_true, y_pred):\n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average='binary', zero_division=0),\n        'recall': recall_score(y_true, y_pred, average='binary', zero_division=0),\n        'f1_score': f1_score(y_true, y_pred, average='binary', zero_division=0),\n        'auc_roc': 0.0,\n    }\n\n    cm = confusion_matrix(y_true, y_pred)\n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    else:\n        metrics['specificity'] = 0.0\n        metrics['sensitivity'] = metrics['recall']\n\n    return metrics\n\n\nprint(\"Comprehensive metrics functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.805553Z","iopub.execute_input":"2025-11-25T03:27:22.805760Z","iopub.status.idle":"2025-11-25T03:27:22.823541Z","shell.execute_reply.started":"2025-11-25T03:27:22.805745Z","shell.execute_reply":"2025-11-25T03:27:22.822801Z"}},"outputs":[{"name":"stdout","text":"Comprehensive metrics functions defined!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 7. Model Architectures","metadata":{}},{"cell_type":"markdown","source":"### 7.1 FBCSP","metadata":{}},{"cell_type":"code","source":"class FBCSP:\n    def __init__(self, freq_bands, n_components=4, sfreq=128.0):\n        self.freq_bands = freq_bands\n        self.n_components = n_components\n        self.sfreq = sfreq\n        self.csps = []\n        self.lda = LinearDiscriminantAnalysis()\n    \n    def _bandpass_filter(self, data, low_freq, high_freq):\n        nyquist = self.sfreq / 2.0\n        low = low_freq / nyquist\n        high = high_freq / nyquist\n        b, a = butter(5, [low, high], btype='band')\n        return filtfilt(b, a, data, axis=-1)\n    \n    def fit(self, X, y):\n        self.csps = []\n        all_features = []\n        \n        for low_freq, high_freq in self.freq_bands:\n            X_filtered = self._bandpass_filter(X.copy(), low_freq, high_freq)\n            \n            csp = CSP(n_components=self.n_components, reg='ledoit_wolf', log=True, norm_trace=False)\n            csp.fit(X_filtered, y)\n            self.csps.append(csp)\n            \n            features = csp.transform(X_filtered)\n            all_features.append(features)\n        \n        all_features = np.concatenate(all_features, axis=1)\n        self.lda.fit(all_features, y)\n        return self\n    \n    def predict(self, X):\n        all_features = []\n        \n        for idx, (low_freq, high_freq) in enumerate(self.freq_bands):\n            X_filtered = self._bandpass_filter(X.copy(), low_freq, high_freq)\n            features = self.csps[idx].transform(X_filtered)\n            all_features.append(features)\n        \n        all_features = np.concatenate(all_features, axis=1)\n        return self.lda.predict(all_features)\n\nprint(\"FBCSP defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.824184Z","iopub.execute_input":"2025-11-25T03:27:22.824369Z","iopub.status.idle":"2025-11-25T03:27:22.840810Z","shell.execute_reply.started":"2025-11-25T03:27:22.824353Z","shell.execute_reply":"2025-11-25T03:27:22.840124Z"}},"outputs":[{"name":"stdout","text":"FBCSP defined!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    for x, y in dataloader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        logits = model(x)\n        loss = criterion(logits, y)\n\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        all_preds += torch.argmax(logits, 1).cpu().tolist()\n        all_labels += y.cpu().tolist()\n    \n    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n\n\n@torch.no_grad()\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    for x, y in dataloader:\n        x, y = x.to(device), y.to(device)\n        logits = model(x)\n        loss = criterion(logits, y)\n        \n        total_loss += loss.item()\n        all_preds += torch.argmax(logits, 1).cpu().tolist()\n        all_labels += y.cpu().tolist()\n    \n    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n\n\ndef train_model(model, train_loader, val_loader, device, epochs, lr, patience, verbose=True):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=3, verbose=False\n    )\n    \n    best_acc = 0.0\n    best_state = None\n    no_improve = 0\n    \n    epoch_iterator = tqdm(range(epochs), desc='    Epochs', leave=False) if verbose else range(epochs)\n    \n    for epoch in epoch_iterator:\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n        \n        scheduler.step(val_loss)\n        \n        if verbose:\n            epoch_iterator.set_postfix({\n                'train_loss': f'{train_loss:.4f}',\n                'train_acc': f'{train_acc:.4f}',\n                'val_loss': f'{val_loss:.4f}',\n                'val_acc': f'{val_acc:.4f}',\n                'best': f'{best_acc:.4f}'\n            })\n        \n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_state = deepcopy(model.state_dict())\n            no_improve = 0\n        else:\n            no_improve += 1\n        \n        if no_improve >= patience:\n            if verbose:\n                print(f'      Early stopping at epoch {epoch+1}/{epochs}')\n            break\n    \n    if best_state is None:\n        best_state = deepcopy(model.state_dict())\n    \n    model.load_state_dict(best_state)\n    return best_state, best_acc\n\n\nprint(\"Training functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.841606Z","iopub.execute_input":"2025-11-25T03:27:22.841865Z","iopub.status.idle":"2025-11-25T03:27:22.858816Z","shell.execute_reply.started":"2025-11-25T03:27:22.841844Z","shell.execute_reply":"2025-11-25T03:27:22.858161Z"}},"outputs":[{"name":"stdout","text":"Training functions defined!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### 7.2 CNN-SAE","metadata":{}},{"cell_type":"code","source":"class SpatialAttention(nn.Module):\n    def __init__(self, n_channels):\n        super().__init__()\n        self.attention = nn.Sequential(\n            nn.Linear(n_channels, n_channels // 4),\n            nn.ReLU(),\n            nn.Linear(n_channels // 4, n_channels),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        pooled = torch.mean(x, dim=2)\n        weights = self.attention(pooled)\n        return x * weights.unsqueeze(2)\n\n\nclass CNNSAE(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769):\n        super().__init__()\n        self.spatial_attention = SpatialAttention(n_channels)\n        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm1d(64)\n        self.pool1 = nn.MaxPool1d(2)\n        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.pool2 = nn.MaxPool1d(2)\n        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm1d(256)\n        self.pool3 = nn.MaxPool1d(2)\n        self.dropout = nn.Dropout(0.5)\n\n        with torch.no_grad():\n            test_input = torch.zeros(1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n\n        self.fc1 = nn.Linear(flattened_size, 256)\n        self.fc2 = nn.Linear(256, n_classes)\n\n    def _forward_features(self, x):\n        x = self.spatial_attention(x)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        return x\n\n    def forward(self, x):\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)\n\nprint(\"CNN-SAE defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.859461Z","iopub.execute_input":"2025-11-25T03:27:22.859718Z","iopub.status.idle":"2025-11-25T03:27:22.879380Z","shell.execute_reply.started":"2025-11-25T03:27:22.859698Z","shell.execute_reply":"2025-11-25T03:27:22.878846Z"}},"outputs":[{"name":"stdout","text":"CNN-SAE defined!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 7.3 EEGNet","metadata":{}},{"cell_type":"code","source":"class EEGNet(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769, F1=8, D=2, F2=16):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n        self.bn1 = nn.BatchNorm2d(F1)\n        self.conv2 = nn.Conv2d(F1, F1*D, (n_channels, 1), groups=F1, bias=False)\n        self.bn2 = nn.BatchNorm2d(F1*D)\n        self.pool1 = nn.AvgPool2d((1, 4))\n        self.dropout1 = nn.Dropout(0.5)\n        self.conv3 = nn.Conv2d(F1*D, F2, (1, 16), padding=(0, 8), bias=False)\n        self.bn3 = nn.BatchNorm2d(F2)\n        self.pool2 = nn.AvgPool2d((1, 8))\n        self.dropout2 = nn.Dropout(0.5)\n\n        with torch.no_grad():\n            test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n\n        self.fc = nn.Linear(flattened_size, n_classes)\n\n    def _forward_features(self, x):\n        x = self.bn1(self.conv1(x))\n        x = self.dropout1(self.pool1(F.elu(self.bn2(self.conv2(x)))))\n        x = self.dropout2(self.pool2(F.elu(self.bn3(self.conv3(x)))))\n        return x\n\n    def forward(self, x):\n        if x.dim() == 3:\n            x = x.unsqueeze(1)\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n\nprint(\"EEGNet defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.880032Z","iopub.execute_input":"2025-11-25T03:27:22.880218Z","iopub.status.idle":"2025-11-25T03:27:22.892904Z","shell.execute_reply.started":"2025-11-25T03:27:22.880205Z","shell.execute_reply":"2025-11-25T03:27:22.892354Z"}},"outputs":[{"name":"stdout","text":"EEGNet defined!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### 7.4 ACS-SE-CNN","metadata":{}},{"cell_type":"code","source":"class SEBlock(nn.Module):\n    def __init__(self, channels, reduction=4):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, max(1, channels // reduction))\n        self.fc2 = nn.Linear(max(1, channels // reduction), channels)\n\n    def forward(self, x):\n        squeeze = torch.mean(x, dim=2)\n        excitation = F.relu(self.fc1(squeeze))\n        excitation = torch.sigmoid(self.fc2(excitation))\n        return x * excitation.unsqueeze(2)\n\n\nclass ACSECNN(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769):\n        super().__init__()\n        self.channel_attention = nn.Sequential(\n            nn.Linear(n_timepoints, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n        self.se1 = SEBlock(n_channels)\n        self.se2 = SEBlock(128)\n        self.se3 = SEBlock(256)\n        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(2)\n        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.pool2 = nn.MaxPool1d(2)\n        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm1d(512)\n        self.pool3 = nn.MaxPool1d(2)\n        self.dropout = nn.Dropout(0.5)\n\n        with torch.no_grad():\n            test_input = torch.zeros(1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n\n        self.fc1 = nn.Linear(flattened_size, 256)\n        self.fc2 = nn.Linear(256, n_classes)\n\n    def _forward_features(self, x):\n        channel_weights = []\n        for i in range(x.size(1)):\n            w = self.channel_attention(x[:, i, :])\n            channel_weights.append(w)\n        channel_weights = torch.cat(channel_weights, dim=1)\n        x = x * channel_weights.unsqueeze(2)\n        x = self.se1(x)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.se2(x)\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.se3(x)\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        return x\n\n    def forward(self, x):\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)\n\nprint(\"ACS-SE-CNN defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.894913Z","iopub.execute_input":"2025-11-25T03:27:22.895358Z","iopub.status.idle":"2025-11-25T03:27:22.910400Z","shell.execute_reply.started":"2025-11-25T03:27:22.895342Z","shell.execute_reply":"2025-11-25T03:27:22.909688Z"}},"outputs":[{"name":"stdout","text":"ACS-SE-CNN defined!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### 7.5 G-CARM","metadata":{}},{"cell_type":"code","source":"class CARMBlock(nn.Module):\n    def __init__(self, n_channels):\n        super().__init__()\n        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n\n    def forward(self, x):\n        A_norm = torch.softmax(self.A, dim=1)\n        x_reshaped = x.permute(0, 2, 1)\n        x_graph = torch.matmul(x_reshaped, A_norm.t())\n        return x_graph.permute(0, 2, 1)\n\n\nclass GCARM(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769):\n        super().__init__()\n        self.carm1 = CARMBlock(n_channels)\n        self.carm2 = CARMBlock(n_channels)\n        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(2)\n        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.pool2 = nn.MaxPool1d(2)\n        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm1d(512)\n        self.pool3 = nn.MaxPool1d(2)\n        self.dropout = nn.Dropout(0.5)\n\n        with torch.no_grad():\n            test_input = torch.zeros(1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n\n        self.fc1 = nn.Linear(flattened_size, 256)\n        self.fc2 = nn.Linear(256, n_classes)\n\n    def _forward_features(self, x):\n        x = self.carm1(x)\n        x = self.carm2(x)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        return x\n\n    def forward(self, x):\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)\n\nprint(\"G-CARM defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.911193Z","iopub.execute_input":"2025-11-25T03:27:22.911424Z","iopub.status.idle":"2025-11-25T03:27:22.928879Z","shell.execute_reply.started":"2025-11-25T03:27:22.911410Z","shell.execute_reply":"2025-11-25T03:27:22.928290Z"}},"outputs":[{"name":"stdout","text":"G-CARM defined!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## 8. Training Functions","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    for x, y in dataloader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        logits = model(x)\n        loss = criterion(logits, y)\n\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        all_preds += torch.argmax(logits, 1).cpu().tolist()\n        all_labels += y.cpu().tolist()\n    \n    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n\n\n@torch.no_grad()\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    for x, y in dataloader:\n        x, y = x.to(device), y.to(device)\n        logits = model(x)\n        loss = criterion(logits, y)\n        \n        total_loss += loss.item()\n        all_preds += torch.argmax(logits, 1).cpu().tolist()\n        all_labels += y.cpu().tolist()\n    \n    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n\n\ndef train_model(model, train_loader, val_loader, device, epochs, lr, patience):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=3, verbose=False\n    )\n    \n    best_acc = 0.0\n    best_state = None\n    no_improve = 0\n    \n    for epoch in range(epochs):\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n        \n        scheduler.step(val_loss)\n        \n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_state = deepcopy(model.state_dict())\n            no_improve = 0\n        else:\n            no_improve += 1\n        \n        if no_improve >= patience:\n            break\n    \n    if best_state is None:\n        best_state = deepcopy(model.state_dict())\n    \n    model.load_state_dict(best_state)\n    return best_state, best_acc\n\n\nprint(\"Training functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.929521Z","iopub.execute_input":"2025-11-25T03:27:22.929733Z","iopub.status.idle":"2025-11-25T03:27:22.946272Z","shell.execute_reply.started":"2025-11-25T03:27:22.929719Z","shell.execute_reply":"2025-11-25T03:27:22.945692Z"}},"outputs":[{"name":"stdout","text":"Training functions defined!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## 9. Main Training Loop","metadata":{}},{"cell_type":"code","source":"all_results = {\n    'fbcsp': [],\n    'cnn_sae': [],\n    'eegnet': [],\n    'acs_se_cnn': [],\n    'g_carm': []\n}\n\nprint(\"\\nStarting training for legacy methods...\\n\")\n\nfor subject_id in tqdm(subjects, desc='Training subjects'):\n    print(f\"\\nProcessing {subject_id}...\")\n    \n    X, Y, channel_names = load_subject_data(\n        data_dir,\n        subject_id,\n        ALL_TASK_RUNS,\n        CONFIG\n    )\n    \n    if X is None or len(Y) == 0:\n        print(f\"  Skipped: No data available\")\n        continue\n    \n    C, T = X.shape[1], X.shape[2]\n    K = len(set(CONFIG['data']['selected_classes']))\n    \n    print(f\"  Data shape: {X.shape}\")\n    print(f\"  Label distribution: {np.bincount(Y)}\")\n    \n    for model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n        print(f\"\\n  Training {model_name.upper()}...\")\n        \n        skf = StratifiedKFold(n_splits=CONFIG['model']['n_folds'], shuffle=True, random_state=42)\n        fold_results = []\n        \n        for fold, (train_idx, val_idx) in enumerate(skf.split(X, Y)):\n            X_train, X_val = X[train_idx], X[val_idx]\n            Y_train, Y_val = Y[train_idx], Y[val_idx]\n            \n            if model_name == 'fbcsp':\n                model = FBCSP(\n                    freq_bands=CONFIG['fbcsp']['freq_bands'],\n                    n_components=CONFIG['fbcsp']['n_components'],\n                    sfreq=CONFIG['preprocessing']['target_sfreq']\n                )\n                model.fit(X_train, Y_train)\n                y_pred = model.predict(X_val)\n                metrics = calculate_sklearn_metrics(Y_val, y_pred)\n                fold_results.append(metrics)\n            else:\n                X_train_norm = normalize(X_train)\n                X_val_norm = normalize(X_val)\n                \n                train_loader = DataLoader(\n                    EEGDataset(X_train_norm, Y_train),\n                    batch_size=CONFIG['model']['batch_size'],\n                    shuffle=True,\n                    num_workers=0\n                )\n                val_loader = DataLoader(\n                    EEGDataset(X_val_norm, Y_val),\n                    batch_size=CONFIG['model']['batch_size'],\n                    shuffle=False,\n                    num_workers=0\n                )\n                \n                if model_name == 'cnn_sae':\n                    model = CNNSAE(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n                elif model_name == 'eegnet':\n                    model = EEGNet(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n                elif model_name == 'acs_se_cnn':\n                    model = ACSECNN(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n                elif model_name == 'g_carm':\n                    model = GCARM(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n                \n                best_state, best_acc = train_model(\n                    model, train_loader, val_loader, device,\n                    CONFIG['model']['epochs'],\n                    CONFIG['model']['learning_rate'],\n                    CONFIG['model']['patience']\n                )\n                model.load_state_dict(best_state)\n                \n                metrics = calculate_comprehensive_metrics(model, val_loader, device)\n                fold_results.append(metrics)\n                \n                del model\n                torch.cuda.empty_cache()\n                gc.collect()\n        \n        avg_metrics = {}\n        for key in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc', 'specificity']:\n            values = [f[key] for f in fold_results]\n            avg_metrics[f'avg_{key}'] = float(np.mean(values))\n            avg_metrics[f'std_{key}'] = float(np.std(values))\n        \n        result = {\n            'subject': subject_id,\n            'num_trials': X.shape[0],\n            'num_channels': C,\n            **avg_metrics\n        }\n        \n        all_results[model_name].append(result)\n        \n        print(f\"    Accuracy: {avg_metrics['avg_accuracy']:.4f} ± {avg_metrics['std_accuracy']:.4f}\")\n        print(f\"    F1-Score: {avg_metrics['avg_f1_score']:.4f} ± {avg_metrics['std_f1_score']:.4f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Training Complete!\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:27:22.946909Z","iopub.execute_input":"2025-11-25T03:27:22.947142Z","iopub.status.idle":"2025-11-25T03:42:07.956091Z","shell.execute_reply.started":"2025-11-25T03:27:22.947120Z","shell.execute_reply":"2025-11-25T03:42:07.955290Z"}},"outputs":[{"name":"stdout","text":"\nStarting training for legacy methods...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training subjects:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c655014f0a2946f5beb81093f63d707e"}},"metadata":{}},{"name":"stdout","text":"\nProcessing S001...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.6151 ± 0.0148\n    F1-Score: 0.3294 ± 0.0486\n\n  Training CNN_SAE...\n    Accuracy: 0.9286 ± 0.0097\n    F1-Score: 0.8888 ± 0.0151\n\n  Training EEGNET...\n    Accuracy: 0.9563 ± 0.0148\n    F1-Score: 0.9324 ± 0.0249\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.8770 ± 0.0202\n    F1-Score: 0.8099 ± 0.0310\n\n  Training G_CARM...\n    Accuracy: 0.8254 ± 0.0056\n    F1-Score: 0.7021 ± 0.0154\n\nProcessing S002...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.6786 ± 0.0097\n    F1-Score: 0.4209 ± 0.0454\n\n  Training CNN_SAE...\n    Accuracy: 0.7817 ± 0.0056\n    F1-Score: 0.6237 ± 0.0308\n\n  Training EEGNET...\n    Accuracy: 0.7857 ± 0.0257\n    F1-Score: 0.6709 ± 0.0377\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.7222 ± 0.0438\n    F1-Score: 0.3476 ± 0.2501\n\n  Training G_CARM...\n    Accuracy: 0.6746 ± 0.0224\n    F1-Score: 0.2997 ± 0.1419\n\nProcessing S005...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.6190 ± 0.0097\n    F1-Score: 0.2938 ± 0.0107\n\n  Training CNN_SAE...\n    Accuracy: 0.8135 ± 0.0112\n    F1-Score: 0.6831 ± 0.0144\n\n  Training EEGNET...\n    Accuracy: 0.8889 ± 0.0056\n    F1-Score: 0.8172 ± 0.0188\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.8373 ± 0.0297\n    F1-Score: 0.7094 ± 0.0804\n\n  Training G_CARM...\n    Accuracy: 0.7857 ± 0.0350\n    F1-Score: 0.5872 ± 0.0784\n\nProcessing S006...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.5159 ± 0.0341\n    F1-Score: 0.1787 ± 0.1058\n\n  Training CNN_SAE...\n    Accuracy: 0.7817 ± 0.0112\n    F1-Score: 0.6206 ± 0.0063\n\n  Training EEGNET...\n    Accuracy: 0.9246 ± 0.0245\n    F1-Score: 0.8850 ± 0.0370\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.7381 ± 0.0097\n    F1-Score: 0.5627 ± 0.0525\n\n  Training G_CARM...\n    Accuracy: 0.7460 ± 0.0112\n    F1-Score: 0.4734 ± 0.0857\n\nProcessing S007...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.7262 ± 0.0292\n    F1-Score: 0.5114 ± 0.0382\n\n  Training CNN_SAE...\n    Accuracy: 0.8968 ± 0.0405\n    F1-Score: 0.8317 ± 0.0678\n\n  Training EEGNET...\n    Accuracy: 0.9524 ± 0.0194\n    F1-Score: 0.9250 ± 0.0303\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.8929 ± 0.0257\n    F1-Score: 0.8255 ± 0.0428\n\n  Training G_CARM...\n    Accuracy: 0.8730 ± 0.0405\n    F1-Score: 0.7876 ± 0.0754\n\nProcessing S008...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.6071 ± 0.0424\n    F1-Score: 0.3159 ± 0.0814\n\n  Training CNN_SAE...\n    Accuracy: 0.9206 ± 0.0393\n    F1-Score: 0.8756 ± 0.0632\n\n  Training EEGNET...\n    Accuracy: 0.9603 ± 0.0112\n    F1-Score: 0.9396 ± 0.0175\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.8929 ± 0.0505\n    F1-Score: 0.8168 ± 0.0933\n\n  Training G_CARM...\n    Accuracy: 0.8651 ± 0.0224\n    F1-Score: 0.7783 ± 0.0371\n\nProcessing S011...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.5079 ± 0.0202\n    F1-Score: 0.1599 ± 0.0520\n\n  Training CNN_SAE...\n    Accuracy: 0.8730 ± 0.0368\n    F1-Score: 0.8072 ± 0.0639\n\n  Training EEGNET...\n    Accuracy: 0.8889 ± 0.0056\n    F1-Score: 0.8292 ± 0.0054\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.8452 ± 0.0337\n    F1-Score: 0.7403 ± 0.0621\n\n  Training G_CARM...\n    Accuracy: 0.7063 ± 0.0281\n    F1-Score: 0.3471 ± 0.2456\n\nProcessing S014...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.6746 ± 0.0662\n    F1-Score: 0.3775 ± 0.1682\n\n  Training CNN_SAE...\n    Accuracy: 0.8651 ± 0.0245\n    F1-Score: 0.7912 ± 0.0307\n\n  Training EEGNET...\n    Accuracy: 0.8651 ± 0.0202\n    F1-Score: 0.7758 ± 0.0366\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.8095 ± 0.0292\n    F1-Score: 0.6682 ± 0.0931\n\n  Training G_CARM...\n    Accuracy: 0.6786 ± 0.0097\n    F1-Score: 0.0674 ± 0.0544\n\nProcessing S015...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.7460 ± 0.0459\n    F1-Score: 0.5773 ± 0.1106\n\n  Training CNN_SAE...\n    Accuracy: 0.8571 ± 0.0350\n    F1-Score: 0.7564 ± 0.0595\n\n  Training EEGNET...\n    Accuracy: 0.8968 ± 0.0438\n    F1-Score: 0.8293 ± 0.0769\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.8373 ± 0.0202\n    F1-Score: 0.7573 ± 0.0309\n\n  Training G_CARM...\n    Accuracy: 0.8571 ± 0.0168\n    F1-Score: 0.7766 ± 0.0297\n\nProcessing S016...\n  Data shape: (252, 64, 769)\n  Label distribution: [168  84]\n\n  Training FBCSP...\n    Accuracy: 0.6270 ± 0.0148\n    F1-Score: 0.4035 ± 0.0688\n\n  Training CNN_SAE...\n    Accuracy: 0.7500 ± 0.0257\n    F1-Score: 0.4732 ± 0.1494\n\n  Training EEGNET...\n    Accuracy: 0.8056 ± 0.0368\n    F1-Score: 0.6603 ± 0.0835\n\n  Training ACS_SE_CNN...\n    Accuracy: 0.7302 ± 0.0148\n    F1-Score: 0.4238 ± 0.0171\n\n  Training G_CARM...\n    Accuracy: 0.7778 ± 0.0297\n    F1-Score: 0.5917 ± 0.0844\n\n================================================================================\nTraining Complete!\n================================================================================\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 10. Save Results","metadata":{}},{"cell_type":"code","source":"results_dir = CONFIG['output']['results_dir']\n\nfor model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n    if len(all_results[model_name]) > 0:\n        df = pd.DataFrame(all_results[model_name])\n        df.to_csv(results_dir / f'legacy_{model_name}_results.csv', index=False)\n        print(f\"Saved: legacy_{model_name}_results.csv\")\n\nprint(f\"\\nAll results saved to {results_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:42:07.957046Z","iopub.execute_input":"2025-11-25T03:42:07.957478Z","iopub.status.idle":"2025-11-25T03:42:07.976693Z","shell.execute_reply.started":"2025-11-25T03:42:07.957456Z","shell.execute_reply":"2025-11-25T03:42:07.976132Z"}},"outputs":[{"name":"stdout","text":"Saved: legacy_fbcsp_results.csv\nSaved: legacy_cnn_sae_results.csv\nSaved: legacy_eegnet_results.csv\nSaved: legacy_acs_se_cnn_results.csv\nSaved: legacy_g_carm_results.csv\n\nAll results saved to results\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 11. Results Summary","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"RESULTS SUMMARY\")\nprint(\"=\"*80 + \"\\n\")\n\nfor model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n    if len(all_results[model_name]) > 0:\n        accs = [r['avg_accuracy'] for r in all_results[model_name]]\n        f1s = [r['avg_f1_score'] for r in all_results[model_name]]\n        aucs = [r['avg_auc_roc'] for r in all_results[model_name]]\n        \n        print(f\"{model_name.upper()} Results:\")\n        print(f\"  Subjects: {len(all_results[model_name])}\")\n        print(f\"  Mean accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n        print(f\"  Mean F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n        print(f\"  Mean AUC-ROC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n        print()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DONE!\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:42:07.977415Z","iopub.execute_input":"2025-11-25T03:42:07.977701Z","iopub.status.idle":"2025-11-25T03:42:07.985964Z","shell.execute_reply.started":"2025-11-25T03:42:07.977681Z","shell.execute_reply":"2025-11-25T03:42:07.985230Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nRESULTS SUMMARY\n================================================================================\n\nFBCSP Results:\n  Subjects: 10\n  Mean accuracy: 0.6317 ± 0.0747\n  Mean F1-Score: 0.3568 ± 0.1249\n  Mean AUC-ROC: 0.0000 ± 0.0000\n\nCNN_SAE Results:\n  Subjects: 10\n  Mean accuracy: 0.8468 ± 0.0589\n  Mean F1-Score: 0.7352 ± 0.1258\n  Mean AUC-ROC: 0.8568 ± 0.0857\n\nEEGNET Results:\n  Subjects: 10\n  Mean accuracy: 0.8925 ± 0.0575\n  Mean F1-Score: 0.8265 ± 0.0957\n  Mean AUC-ROC: 0.9255 ± 0.0609\n\nACS_SE_CNN Results:\n  Subjects: 10\n  Mean accuracy: 0.8183 ± 0.0629\n  Mean F1-Score: 0.6662 ± 0.1598\n  Mean AUC-ROC: 0.8231 ± 0.0972\n\nG_CARM Results:\n  Subjects: 10\n  Mean accuracy: 0.7790 ± 0.0720\n  Mean F1-Score: 0.5411 ± 0.2298\n  Mean AUC-ROC: 0.7759 ± 0.0993\n\n\n================================================================================\nDONE!\n================================================================================\n","output_type":"stream"}],"execution_count":16}]}