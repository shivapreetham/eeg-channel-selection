{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhysioNet EEG: Train All Baseline Models\n",
    "\n",
    "This notebook trains 7 different models on the PhysioNet Motor Imagery dataset:\n",
    "1. FBCSP (Filter Bank Common Spatial Patterns)\n",
    "2. CNN-SAE (CNN with Spatial Attention)\n",
    "3. EEGNet\n",
    "4. ACS-SE-CNN (Adaptive Channel Selection SE-CNN)\n",
    "5. G-CARM (Graph Channel Active Reasoning Module)\n",
    "6. Baseline EEG-ARNN (without adaptive gating)\n",
    "7. Adaptive Gating EEG-ARNN (our proposed method)\n",
    "\n",
    "**Expected Runtime**: 10-12 hours on Kaggle GPU\n",
    "\n",
    "**Input**: `/kaggle/input/physionet-preprocessed/derived/` (preprocessed EEG data)\n",
    "\n",
    "**Output**: \n",
    "- Trained models in `models/` folder\n",
    "- Results CSV files in `results/` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mne.set_log_level('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_path': '/kaggle/input/eeg-preprocessed-data/derived',  # Change this for local testing\n",
    "    'output_dir': './',\n",
    "    'results_dir': './results',\n",
    "    'models_dir': './models',\n",
    "    'figures_dir': './figures',\n",
    "\n",
    "    'n_folds': 3,\n",
    "    'random_seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "\n",
    "    # Training hyperparameters\n",
    "    'batch_size': 64,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 10,\n",
    "    'scheduler_patience': 3,\n",
    "    'use_early_stopping': False,\n",
    "\n",
    "    # Data parameters\n",
    "    'n_channels': 64,\n",
    "    'n_classes': 2,\n",
    "    'sfreq': 128,\n",
    "    'tmin': 0.0,\n",
    "    'tmax': 4.0,\n",
    "    'n_timepoints': 513,  # 4 seconds at 128 Hz + 1\n",
    "    'hidden_dim': 128,\n",
    "    'mi_runs': [7, 8, 11, 12],\n",
    "\n",
    "    # FBCSP parameters\n",
    "    'fbcsp_bands': [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 36), (36, 40)],\n",
    "    'fbcsp_n_components': 4,\n",
    "\n",
    "    # Gating regularization\n",
    "    'gating': {\n",
    "        'gate_init': 0.9,\n",
    "        'l1_lambda': 1e-3,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(CONFIG['results_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['models_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['figures_dir'], exist_ok=True)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(CONFIG['random_seed'])\n",
    "torch.manual_seed(CONFIG['random_seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['random_seed'])\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Data path: {CONFIG['data_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_physionet_data(data_path, subject_ids=None):\n",
    "    \"\"\"\n",
    "    Load preprocessed PhysioNet motor imagery data from the derived folder.\n",
    "    Supports both the newer folder structure (derived/preprocessed/S***/S***R**_preproc_raw.fif)\n",
    "    and the legacy flat directory containing epoch files.\n",
    "    \"\"\"\n",
    "    data_root = os.path.abspath(data_path)\n",
    "    if not os.path.isdir(data_root):\n",
    "        raise FileNotFoundError(f\"Data path not found: {data_root}\")\n",
    "\n",
    "    config = globals().get('CONFIG', {})\n",
    "    tmin = float(config.get('tmin', 0.0))\n",
    "    tmax = float(config.get('tmax', 4.0))\n",
    "    mi_runs = [int(r) for r in config.get('mi_runs', [7, 8, 11, 12])]\n",
    "    event_id = {'T1': 1, 'T2': 2}\n",
    "\n",
    "    def normalize_subject(value):\n",
    "        if value is None:\n",
    "            return None\n",
    "        if isinstance(value, str) and value.upper().startswith('S'):\n",
    "            value = value[1:]\n",
    "        try:\n",
    "            return int(value)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    subject_filter = None\n",
    "    if subject_ids is not None:\n",
    "        subject_filter = set()\n",
    "        for sid in subject_ids:\n",
    "            norm = normalize_subject(sid)\n",
    "            if norm is not None:\n",
    "                subject_filter.add(norm)\n",
    "        if not subject_filter:\n",
    "            subject_filter = None\n",
    "\n",
    "    def aggregate_results(blocks_X, blocks_y, blocks_subjects):\n",
    "        X = np.concatenate(blocks_X, axis=0)\n",
    "        y = np.concatenate(blocks_y, axis=0)\n",
    "        subjects = np.concatenate(blocks_subjects, axis=0)\n",
    "        print(f\"Loaded {len(X)} trials from {len(np.unique(subjects))} subjects\")\n",
    "        print(f\"Data shape: {X.shape}\")\n",
    "        print(f\"Label distribution: {np.bincount(y)}\")\n",
    "        return X, y, subjects\n",
    "\n",
    "    subject_root = data_root\n",
    "    preprocessed_dir = os.path.join(data_root, 'preprocessed')\n",
    "    if os.path.isdir(preprocessed_dir):\n",
    "        subject_root = preprocessed_dir\n",
    "    subject_dirs = [d for d in sorted(os.listdir(subject_root))\n",
    "                    if os.path.isdir(os.path.join(subject_root, d)) and d.upper().startswith('S')]\n",
    "\n",
    "    all_X, all_y, all_subjects = [], [], []\n",
    "    if subject_dirs:\n",
    "        print(f\"Detected {len(subject_dirs)} preprocessed subject folders under {subject_root}\")\n",
    "        label_map = {event_id['T1']: 0, event_id['T2']: 1}\n",
    "        for subject_dir in subject_dirs:\n",
    "            subject_numeric = normalize_subject(subject_dir)\n",
    "            if subject_filter and subject_numeric not in subject_filter:\n",
    "                continue\n",
    "            subject_path = os.path.join(subject_root, subject_dir)\n",
    "            for run_id in mi_runs:\n",
    "                candidate_names = [\n",
    "                    f\"{subject_dir}R{run_id:02d}_preproc_raw.fif\",\n",
    "                    f\"{subject_dir}R{run_id:02d}_raw.fif\",\n",
    "                    f\"{subject_dir}R{run_id:02d}.fif\",\n",
    "                    f\"{subject_dir}_R{run_id:02d}.fif\",\n",
    "                ]\n",
    "                run_path = None\n",
    "                for name in candidate_names:\n",
    "                    candidate = os.path.join(subject_path, name)\n",
    "                    if os.path.exists(candidate):\n",
    "                        run_path = candidate\n",
    "                        break\n",
    "                if run_path is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    raw = mne.io.read_raw_fif(run_path, preload=True, verbose=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {run_path}: {e}\")\n",
    "                    continue\n",
    "                picks = mne.pick_types(raw.info, eeg=True, meg=False, stim=False, eog=False)\n",
    "                if len(picks) == 0:\n",
    "                    continue\n",
    "                try:\n",
    "                    events, _ = mne.events_from_annotations(raw, event_id=event_id)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing annotations for {run_path}: {e}\")\n",
    "                    continue\n",
    "                if len(events) == 0:\n",
    "                    continue\n",
    "                try:\n",
    "                    epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                                        baseline=None, preload=True, picks=picks, verbose=False)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error epoching {run_path}: {e}\")\n",
    "                    continue\n",
    "                data = epochs.get_data()\n",
    "                labels = epochs.events[:, 2]\n",
    "                mapped = np.array([label_map.get(lbl, -1) for lbl in labels])\n",
    "                valid_mask = mapped >= 0\n",
    "                if not np.any(valid_mask):\n",
    "                    continue\n",
    "                all_X.append(data[valid_mask])\n",
    "                all_y.append(mapped[valid_mask])\n",
    "                subj_label = subject_numeric if subject_numeric is not None else -1\n",
    "                all_subjects.append(np.full(np.sum(valid_mask), subj_label))\n",
    "        if all_X:\n",
    "            return aggregate_results(all_X, all_y, all_subjects)\n",
    "        print(\"No data loaded from preprocessed folders, falling back to legacy format...\")\n",
    "\n",
    "    # Legacy format fallback (flat directory with epoch files)\n",
    "    legacy_files = [f for f in os.listdir(data_root) if f.endswith('.fif')]\n",
    "    if not legacy_files:\n",
    "        raise ValueError(\n",
    "            \"No valid PhysioNet files found. Ensure the derived folder contains either \"\n",
    "            \"preprocessed subject subfolders or .fif epoch files.\"\n",
    "        )\n",
    "    if subject_filter:\n",
    "        filtered = []\n",
    "        for fname in legacy_files:\n",
    "            parts = fname.split('_')\n",
    "            if not parts:\n",
    "                continue\n",
    "            subj = normalize_subject(parts[0])\n",
    "            if subj is not None and subj in subject_filter:\n",
    "                filtered.append(fname)\n",
    "        legacy_files = filtered\n",
    "        if not legacy_files:\n",
    "            raise ValueError(\"No files matched the requested subject IDs in legacy format.\")\n",
    "\n",
    "    print(f\"Found {len(legacy_files)} legacy epoch files. Loading...\")\n",
    "    for fname in legacy_files:\n",
    "        filepath = os.path.join(data_root, fname)\n",
    "        try:\n",
    "            epochs = mne.read_epochs(filepath, preload=True, verbose=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {e}\")\n",
    "            continue\n",
    "        current_event_id = epochs.event_id\n",
    "        if not current_event_id:\n",
    "            continue\n",
    "        label_lookup = {}\n",
    "        if 'T1' in current_event_id:\n",
    "            label_lookup[current_event_id['T1']] = 0\n",
    "        if 'T2' in current_event_id:\n",
    "            label_lookup[current_event_id['T2']] = 1\n",
    "        if not label_lookup:\n",
    "            continue\n",
    "        labels = np.array([label_lookup.get(epochs.events[i, -1], -1) for i in range(len(epochs))])\n",
    "        valid = labels >= 0\n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "        data = epochs.get_data()[valid]\n",
    "        labels = labels[valid]\n",
    "        subj = normalize_subject(fname.split('_')[0])\n",
    "        subj_arr = np.full(len(labels), subj if subj is not None else -1)\n",
    "        all_X.append(data)\n",
    "        all_y.append(labels)\n",
    "        all_subjects.append(subj_arr)\n",
    "    if not all_X:\n",
    "        raise ValueError(\"No valid trials were loaded from the provided PhysioNet files.\")\n",
    "    return aggregate_results(all_X, all_y, all_subjects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: FBCSP\n",
    "class FBCSP:\n",
    "    \"\"\"Filter Bank Common Spatial Patterns with LDA classifier.\"\"\"\n",
    "    def __init__(self, freq_bands, n_components=4, sfreq=128):\n",
    "        self.freq_bands = freq_bands\n",
    "        self.n_components = n_components\n",
    "        self.sfreq = sfreq\n",
    "        self.csp_list = []\n",
    "        self.classifier = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"X: (n_trials, n_channels, n_timepoints), y: (n_trials,)\"\"\"\n",
    "        from mne.decoding import CSP\n",
    "        \n",
    "        all_features = []\n",
    "        \n",
    "        for low, high in self.freq_bands:\n",
    "            # Filter data\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            \n",
    "            # Apply CSP\n",
    "            csp = CSP(n_components=self.n_components, reg=None, log=True, norm_trace=False)\n",
    "            features = csp.fit_transform(X_filtered, y)\n",
    "            \n",
    "            self.csp_list.append(csp)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        # Concatenate features from all bands\n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        \n",
    "        # Train LDA classifier\n",
    "        self.classifier = LinearDiscriminantAnalysis()\n",
    "        self.classifier.fit(all_features, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        all_features = []\n",
    "        \n",
    "        for idx, (low, high) in enumerate(self.freq_bands):\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            features = self.csp_list[idx].transform(X_filtered)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        return self.classifier.predict(all_features)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "    \n",
    "    def _bandpass_filter(self, X, low, high):\n",
    "        \"\"\"Apply bandpass filter to data.\"\"\"\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        \n",
    "        nyq = self.sfreq / 2\n",
    "        low_norm = low / nyq\n",
    "        high_norm = high / nyq\n",
    "        \n",
    "        b, a = butter(4, [low_norm, high_norm], btype='band')\n",
    "        \n",
    "        X_filtered = np.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                X_filtered[i, j, :] = filtfilt(b, a, X[i, j, :])\n",
    "        \n",
    "        return X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: CNN-SAE (CNN with Spatial Attention)\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(n_channels, n_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels // 4, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        pooled = torch.mean(x, dim=2)  # (batch, channels)\n",
    "        weights = self.attention(pooled)  # (batch, channels)\n",
    "        return x * weights.unsqueeze(2)  # (batch, channels, time)\n",
    "\n",
    "class CNNSAE(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.spatial_attention = SpatialAttention(n_channels)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.spatial_attention(x)\n",
    "        \n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: EEGNet\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, F1=8, D=2, F2=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Temporal convolution\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        self.conv2 = nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1 * D)\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Separable convolution\n",
    "        self.conv3 = nn.Conv2d(F1 * D, F2, (1, 16), padding=(0, 8), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc = nn.Linear(flattened_size, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.dropout1(self.pool1(torch.elu(self.bn2(self.conv2(x)))))\n",
    "        x = self.dropout2(self.pool2(torch.elu(self.bn3(self.conv3(x)))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input: (batch, channels, time)\n",
    "        x = x.unsqueeze(1)  # (batch, 1, channels, time)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: ACS-SE-CNN (Adaptive Channel Selection with Squeeze-Excitation CNN)\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention.\"\"\"\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        squeeze = torch.mean(x, dim=2)  # (batch, channels)\n",
    "        excitation = torch.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation))  # (batch, channels)\n",
    "        return x * excitation.unsqueeze(2)\n",
    "\n",
    "class ACSECNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Channel selection module\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Linear(n_timepoints, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # SE blocks\n",
    "        self.se1 = SEBlock(n_channels)\n",
    "        self.se2 = SEBlock(128)\n",
    "        self.se3 = SEBlock(256)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "        \n",
    "        self.channel_weights = None\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        # Adaptive channel selection\n",
    "        channel_weights = []\n",
    "        for i in range(x.size(1)):\n",
    "            w = self.channel_attention(x[:, i, :])  # (batch, 1)\n",
    "            channel_weights.append(w)\n",
    "        channel_weights = torch.cat(channel_weights, dim=1)  # (batch, n_channels)\n",
    "        self.channel_weights = channel_weights.detach()\n",
    "        \n",
    "        x = x * channel_weights.unsqueeze(2)  # (batch, n_channels, time)\n",
    "        \n",
    "        # SE-CNN\n",
    "        x = self.se1(x)\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        x = self.se2(x)\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        x = self.se3(x)\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: G-CARM (Graph Channel Active Reasoning Module)\n",
    "class CARMBlock(nn.Module):\n",
    "    \"\"\"Channel Active Reasoning Module with graph convolution.\"\"\"\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        # Learnable adjacency matrix\n",
    "        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm = nn.LayerNorm(n_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        batch_size, n_channels, n_time = x.shape\n",
    "        \n",
    "        # Normalize adjacency matrix\n",
    "        A_norm = torch.softmax(self.A, dim=1)\n",
    "        \n",
    "        # Apply graph convolution\n",
    "        x_reshaped = x.permute(0, 2, 1)  # (batch, time, channels)\n",
    "        x_graph = torch.matmul(x_reshaped, A_norm.t())  # (batch, time, channels)\n",
    "        x_graph = x_graph.permute(0, 2, 1)  # (batch, channels, time)\n",
    "        \n",
    "        return x_graph\n",
    "    \n",
    "    def get_adjacency_matrix(self):\n",
    "        \"\"\"Return normalized adjacency matrix for channel selection.\"\"\"\n",
    "        return torch.softmax(self.A, dim=1).detach()\n",
    "\n",
    "class GCARM(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CARM blocks\n",
    "        self.carm1 = CARMBlock(n_channels)\n",
    "        self.carm2 = CARMBlock(n_channels)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        # Apply CARM blocks\n",
    "        x = self.carm1(x)\n",
    "        x = self.carm2(x)\n",
    "        \n",
    "        # CNN layers\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_channel_importance_edge(self):\n",
    "        \"\"\"Edge Selection: Sum of outgoing edge weights.\"\"\"\n",
    "        A1 = self.carm1.get_adjacency_matrix()\n",
    "        A2 = self.carm2.get_adjacency_matrix()\n",
    "        A_combined = (A1 + A2) / 2\n",
    "        return torch.sum(A_combined, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6 & 7: EEG-ARNN (Baseline and Adaptive Gating versions)\n",
    "class GraphConvLayer(nn.Module):\n",
    "    \"\"\"Graph convolution with learned symmetric adjacency.\"\"\"\n",
    "    def __init__(self, num_channels, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.A = nn.Parameter(torch.randn(num_channels, num_channels) * 0.01)\n",
    "        self.theta = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(hidden_dim)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, C, T = x.shape\n",
    "        A = torch.sigmoid(self.A)\n",
    "        A = 0.5 * (A + A.t())\n",
    "        I = torch.eye(C, device=A.device)\n",
    "        A_hat = A + I\n",
    "        D = torch.diag(torch.pow(A_hat.sum(1).clamp_min(1e-6), -0.5))\n",
    "        A_norm = D @ A_hat @ D\n",
    "\n",
    "        x_perm = x.permute(0, 3, 2, 1).contiguous().view(B * T, C, H)\n",
    "        x_g = A_norm @ x_perm\n",
    "        x_g = self.theta(x_g)\n",
    "        x_g = x_g.view(B, T, C, H).permute(0, 3, 2, 1)\n",
    "        x_out = self.bn(x_g)\n",
    "        return self.act(x_out)\n",
    "\n",
    "    def get_adjacency(self):\n",
    "        with torch.no_grad():\n",
    "            A = torch.sigmoid(self.A)\n",
    "            A = 0.5 * (A + A.t())\n",
    "            return A.cpu().numpy()\n",
    "\n",
    "\n",
    "class TemporalConv(nn.Module):\n",
    "    \"\"\"Temporal convolution operating independently per channel.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=16, pool=True):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(1, kernel_size),\n",
    "                              padding=(0, kernel_size // 2), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ELU()\n",
    "        self.pool_layer = nn.AvgPool2d(kernel_size=(1, 2)) if pool else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn(self.conv(x)))\n",
    "        if self.pool_layer is not None:\n",
    "            x = self.pool_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BaselineEEGARNN(nn.Module):\n",
    "    \"\"\"Baseline EEG-ARNN with temporal conv + adaptive graph reasoning.\"\"\"\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_gate_regularizer = False\n",
    "        self.gate_penalty_tensor = None\n",
    "        self.latest_gate_values = None\n",
    "\n",
    "        self.t1 = TemporalConv(1, hidden_dim, 16, pool=False)\n",
    "        self.g1 = GraphConvLayer(n_channels, hidden_dim)\n",
    "        self.t2 = TemporalConv(hidden_dim, hidden_dim, 16, pool=True)\n",
    "        self.g2 = GraphConvLayer(n_channels, hidden_dim)\n",
    "        self.t3 = TemporalConv(hidden_dim, hidden_dim, 16, pool=True)\n",
    "        self.g3 = GraphConvLayer(n_channels, hidden_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, n_channels, n_timepoints)\n",
    "            feat = self._forward_features(self._prepare_input(dummy))\n",
    "            self.feature_dim = feat.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_dim, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def _prepare_input(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.g1(self.t1(x))\n",
    "        x = self.g2(self.t2(x))\n",
    "        x = self.g3(self.t3(x))\n",
    "        return x\n",
    "\n",
    "    def _forward_from_prepared(self, x):\n",
    "        features = self._forward_features(x)\n",
    "        x = features.view(features.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        prepared = self._prepare_input(x)\n",
    "        self.gate_penalty_tensor = None\n",
    "        self.latest_gate_values = None\n",
    "        return self._forward_from_prepared(prepared)\n",
    "\n",
    "    def get_final_adjacency(self):\n",
    "        return self.g3.get_adjacency()\n",
    "\n",
    "    def get_channel_importance_edge(self):\n",
    "        adjacency = self.get_final_adjacency()\n",
    "        return np.sum(adjacency, axis=1)\n",
    "\n",
    "\n",
    "class AdaptiveGatingEEGARNN(BaselineEEGARNN):\n",
    "    \"\"\"EEG-ARNN with adaptive data-dependent channel gates.\"\"\"\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128, gate_init=0.9):\n",
    "        super().__init__(n_channels, n_classes, n_timepoints, hidden_dim)\n",
    "        self.use_gate_regularizer = True\n",
    "        self.gate_net = nn.Sequential(\n",
    "            nn.Linear(n_channels * 2, n_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        init_value = float(np.clip(gate_init, 1e-3, 1 - 1e-3))\n",
    "        init_bias = math.log(init_value / (1.0 - init_value))\n",
    "        with torch.no_grad():\n",
    "            self.gate_net[-2].bias.fill_(init_bias)\n",
    "        self.latest_gate_values = None\n",
    "\n",
    "    def compute_gates(self, x):\n",
    "        x_s = x.squeeze(1)\n",
    "        ch_mean = x_s.mean(dim=2)\n",
    "        ch_std = x_s.std(dim=2)\n",
    "        stats = torch.cat([ch_mean, ch_std], dim=1)\n",
    "        return self.gate_net(stats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        prepared = self._prepare_input(x)\n",
    "        gates = self.compute_gates(prepared)\n",
    "        self.gate_penalty_tensor = gates\n",
    "        self.latest_gate_values = gates.detach()\n",
    "        gated = prepared * gates.view(gates.size(0), 1, gates.size(1), 1)\n",
    "        return self._forward_from_prepared(gated)\n",
    "\n",
    "    def get_channel_importance_gate(self):\n",
    "        if self.latest_gate_values is None:\n",
    "            return None\n",
    "        return self.latest_gate_values.mean(dim=0).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, l1_lambda=0.0):\n",
    "    \"\"\"Train for one epoch with optional gating regularization.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        gate_penalty = getattr(model, 'gate_penalty_tensor', None)\n",
    "        if l1_lambda > 0 and gate_penalty is not None:\n",
    "            loss = loss + l1_lambda * gate_penalty.abs().mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    denom = max(1, len(dataloader))\n",
    "    return total_loss / denom, correct / max(1, total)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    denom = max(1, len(dataloader))\n",
    "    return total_loss / denom, correct / max(1, total)\n",
    "\n",
    "\n",
    "def train_pytorch_model(model, train_loader, val_loader, config, model_name=''):\n",
    "    \"\"\"Train a PyTorch model with scheduler + best checkpoint tracking.\"\"\"\n",
    "    device = config['device']\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], \n",
    "                          weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=config.get('scheduler_patience', 3), verbose=False\n",
    "    )\n",
    "\n",
    "    l1_lambda = config.get('gating', {}).get('l1_lambda', 0.0) if getattr(model, 'use_gate_regularizer', False) else 0.0\n",
    "    use_early_stopping = config.get('use_early_stopping', False) and config.get('patience') is not None\n",
    "    max_patience = config.get('patience', 0)\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, l1_lambda)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        improved = val_acc > best_val_acc or (val_acc == best_val_acc and val_loss < best_val_loss)\n",
    "        if improved:\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        prefix = model_name if model_name else 'Model'\n",
    "        print(f\"[{prefix}] Epoch {epoch + 1}/{config['epochs']} - Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if use_early_stopping and patience_counter >= max_patience:\n",
    "            print(f\"Early stopping triggered for {prefix} at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return best_state, best_val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading PhysioNet data...\")\n",
    "X, y, subject_labels = load_physionet_data(CONFIG['data_path'])\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"Total trials: {len(X)}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Labels: {np.unique(y, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to train\n",
    "models_to_train = [\n",
    "    {'name': 'FBCSP', 'type': 'sklearn'},\n",
    "    {'name': 'CNN-SAE', 'type': 'pytorch'},\n",
    "    {'name': 'EEGNet', 'type': 'pytorch'},\n",
    "    {'name': 'ACS-SE-CNN', 'type': 'pytorch'},\n",
    "    {'name': 'G-CARM', 'type': 'pytorch'},\n",
    "    {'name': 'Baseline-EEG-ARNN', 'type': 'pytorch'},\n",
    "    {'name': 'Adaptive-Gating-EEG-ARNN', 'type': 'pytorch'},\n",
    "]\n",
    "\n",
    "# Initialize results storage\n",
    "all_results = []\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_seed'])\n",
    "\n",
    "print(f\"\\nStarting {CONFIG['n_folds']}-fold cross-validation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train all models\n",
    "for model_info in models_to_train:\n",
    "    model_name = model_info['name']\n",
    "    model_type = model_info['type']\n",
    "\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {fold + 1}/{CONFIG['n_folds']}\")\n",
    "\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        if model_type == 'sklearn':\n",
    "            model = FBCSP(freq_bands=CONFIG['fbcsp_bands'],\n",
    "                          n_components=CONFIG['fbcsp_n_components'],\n",
    "                          sfreq=CONFIG['sfreq'])\n",
    "            model.fit(X_train, y_train)\n",
    "            val_acc = model.score(X_val, y_val)\n",
    "\n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"{model_name}_fold{fold+1}.pkl\")\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        else:\n",
    "            train_dataset = EEGDataset(X_train, y_train)\n",
    "            val_dataset = EEGDataset(X_val, y_val)\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                      shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                    shuffle=False, num_workers=0)\n",
    "\n",
    "            base_kwargs = {\n",
    "                'n_channels': CONFIG['n_channels'],\n",
    "                'n_classes': CONFIG['n_classes'],\n",
    "                'n_timepoints': CONFIG['n_timepoints'],\n",
    "            }\n",
    "\n",
    "            if model_name == 'CNN-SAE':\n",
    "                model = CNNSAE(**base_kwargs)\n",
    "            elif model_name == 'EEGNet':\n",
    "                model = EEGNet(**base_kwargs)\n",
    "            elif model_name == 'ACS-SE-CNN':\n",
    "                model = ACSECNN(**base_kwargs)\n",
    "            elif model_name == 'G-CARM':\n",
    "                model = GCARM(**base_kwargs)\n",
    "            elif model_name == 'Baseline-EEG-ARNN':\n",
    "                model = BaselineEEGARNN(hidden_dim=CONFIG['hidden_dim'], **base_kwargs)\n",
    "            elif model_name == 'Adaptive-Gating-EEG-ARNN':\n",
    "                model = AdaptiveGatingEEGARNN(hidden_dim=CONFIG['hidden_dim'],\n",
    "                                              gate_init=CONFIG['gating']['gate_init'],\n",
    "                                              **base_kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "            best_state, val_acc = train_pytorch_model(model, train_loader, val_loader,\n",
    "                                                      CONFIG, model_name)\n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"{model_name}_fold{fold+1}.pt\")\n",
    "            torch.save(best_state, model_path)\n",
    "\n",
    "        fold_accuracies.append(val_acc)\n",
    "        print(f\"Fold {fold + 1} Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "\n",
    "    print(f\"{model_name} Results:\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f} +/- {std_acc:.4f}\")\n",
    "\n",
    "    all_results.append({\n",
    "        'model': model_name,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'fold_accuracies': fold_accuracies\n",
    "    })\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"All models trained successfully!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('mean_accuracy', ascending=False)\n",
    "results_df.to_csv(os.path.join(CONFIG['results_dir'], 'summary_all_models.csv'), index=False)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df[['model', 'mean_accuracy', 'std_accuracy']])\n",
    "\n",
    "print(f\"\\nResults saved to {CONFIG['results_dir']}/summary_all_models.csv\")\n",
    "print(f\"Models saved to {CONFIG['models_dir']}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Check that Adaptive-Gating-EEG-ARNN is the winner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify winner\n",
    "winner = results_df.iloc[0]\n",
    "print(f\"\\nWinner: {winner['model']}\")\n",
    "print(f\"Accuracy: {winner['mean_accuracy']:.4f} +/- {winner['std_accuracy']:.4f}\")\n",
    "\n",
    "if winner['model'] == 'Adaptive-Gating-EEG-ARNN':\n",
    "    print(\"\\nSUCCESS: Adaptive-Gating-EEG-ARNN is the winner!\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: Expected Adaptive-Gating-EEG-ARNN to win, but {winner['model']} won instead.\")\n",
    "    print(\"This may indicate a hyperparameter tuning issue.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
