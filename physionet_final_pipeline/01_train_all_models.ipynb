{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhysioNet EEG: Train All Baseline Models\n",
    "\n",
    "This notebook trains 7 different models on the PhysioNet Motor Imagery dataset:\n",
    "1. FBCSP (Filter Bank Common Spatial Patterns)\n",
    "2. CNN-SAE (CNN with Spatial Attention)\n",
    "3. EEGNet\n",
    "4. ACS-SE-CNN (Adaptive Channel Selection SE-CNN)\n",
    "5. G-CARM (Graph Channel Active Reasoning Module)\n",
    "6. Baseline EEG-ARNN (without adaptive gating)\n",
    "7. Adaptive Gating EEG-ARNN (our proposed method)\n",
    "\n",
    "**Expected Runtime**: 10-12 hours on Kaggle GPU\n",
    "\n",
    "**Input**: `/kaggle/input/physionet-preprocessed/derived/` (preprocessed EEG data)\n",
    "\n",
    "**Output**: \n",
    "- Trained models in `models/` folder\n",
    "- Results CSV files in `results/` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mne.set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_path': '/kaggle/input/eeg-preprocessed-data/derived',  # Change this for local testing\n",
    "    'output_dir': './',\n",
    "    'results_dir': './results',\n",
    "    'models_dir': './models',\n",
    "    'figures_dir': './figures',\n",
    "    \n",
    "    'n_folds': 3,\n",
    "    'random_seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    'batch_size': 64,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 10,\n",
    "    \n",
    "    # Data parameters\n",
    "    'n_channels': 64,\n",
    "    'n_classes': 2,\n",
    "    'sfreq': 128,\n",
    "    'tmin': 0.0,\n",
    "    'tmax': 4.0,\n",
    "    'n_timepoints': 513,  # 4 seconds at 128 Hz + 1\n",
    "    \n",
    "    # FBCSP parameters\n",
    "    'fbcsp_bands': [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 36), (36, 40)],\n",
    "    'fbcsp_n_components': 4,\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(CONFIG['results_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['models_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['figures_dir'], exist_ok=True)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(CONFIG['random_seed'])\n",
    "torch.manual_seed(CONFIG['random_seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['random_seed'])\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Data path: {CONFIG['data_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_physionet_data(data_path, subject_ids=None):\n",
    "    \"\"\"\n",
    "    Load preprocessed PhysioNet data from derived folder.\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array (n_trials, n_channels, n_timepoints)\n",
    "        y: numpy array (n_trials,) with labels 0=T1 (left fist), 1=T2 (right fist)\n",
    "        subject_labels: numpy array (n_trials,) with subject IDs\n",
    "    \"\"\"\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_subjects = []\n",
    "    \n",
    "    # Get list of subjects\n",
    "    if subject_ids is None:\n",
    "        files = [f for f in os.listdir(data_path) if f.endswith('.fif')]\n",
    "        subject_ids = sorted(list(set([int(f.split('_')[0][1:]) for f in files])))\n",
    "    \n",
    "    print(f\"Loading data from {len(subject_ids)} subjects...\")\n",
    "    \n",
    "    for subject_id in tqdm(subject_ids):\n",
    "        # Load runs for this subject (runs 3, 4, 7, 8, 11, 12)\n",
    "        subject_runs = []\n",
    "        for run_id in [3, 4, 7, 8, 11, 12]:\n",
    "            filename = f\"S{subject_id:03d}_R{run_id:02d}.fif\"\n",
    "            filepath = os.path.join(data_path, filename)\n",
    "            \n",
    "            if not os.path.exists(filepath):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                epochs = mne.read_epochs(filepath, preload=True, verbose=False)\n",
    "                subject_runs.append(epochs)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(subject_runs) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Concatenate all runs for this subject\n",
    "        epochs = mne.concatenate_epochs(subject_runs)\n",
    "        \n",
    "        # Extract data\n",
    "        X = epochs.get_data()  # (n_trials, n_channels, n_timepoints)\n",
    "        \n",
    "        # Extract labels - CRITICAL FIX\n",
    "        # MNE uses internal event codes that must be mapped to our 0/1 labels\n",
    "        event_ids = epochs.event_id\n",
    "        valid_event_ids = {'T1': 1, 'T2': 2}  # MNE annotation codes\n",
    "        \n",
    "        # Create mapping from MNE event codes to our labels (T1=0, T2=1)\n",
    "        event_name_to_label = {}\n",
    "        if 'T1' in event_ids:\n",
    "            event_name_to_label['T1'] = 0\n",
    "        if 'T2' in event_ids:\n",
    "            event_name_to_label['T2'] = 1\n",
    "        \n",
    "        # Map MNE event codes to our labels\n",
    "        event_code_to_label = {}\n",
    "        for name, label in event_name_to_label.items():\n",
    "            if name in valid_event_ids:\n",
    "                mne_code = valid_event_ids[name]\n",
    "                event_code_to_label[mne_code] = label\n",
    "        \n",
    "        # Get labels for each trial\n",
    "        y = np.array([event_code_to_label.get(epochs.events[i, -1], -1) \n",
    "                     for i in range(len(epochs))])\n",
    "        \n",
    "        # Filter out any trials with unknown labels\n",
    "        valid_mask = y != -1\n",
    "        X = X[valid_mask]\n",
    "        y = y[valid_mask]\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            continue\n",
    "        \n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_subjects.append(np.full(len(y), subject_id))\n",
    "    \n",
    "    # Concatenate all subjects\n",
    "    X = np.concatenate(all_X, axis=0)\n",
    "    y = np.concatenate(all_y, axis=0)\n",
    "    subject_labels = np.concatenate(all_subjects, axis=0)\n",
    "    \n",
    "    print(f\"Loaded {len(X)} trials from {len(np.unique(subject_labels))} subjects\")\n",
    "    print(f\"Data shape: {X.shape}\")\n",
    "    print(f\"Label distribution: {np.bincount(y)}\")\n",
    "    \n",
    "    return X, y, subject_labels\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    \"\"\"PyTorch dataset for EEG data.\"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: FBCSP\n",
    "class FBCSP:\n",
    "    \"\"\"Filter Bank Common Spatial Patterns with LDA classifier.\"\"\"\n",
    "    def __init__(self, freq_bands, n_components=4, sfreq=128):\n",
    "        self.freq_bands = freq_bands\n",
    "        self.n_components = n_components\n",
    "        self.sfreq = sfreq\n",
    "        self.csp_list = []\n",
    "        self.classifier = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"X: (n_trials, n_channels, n_timepoints), y: (n_trials,)\"\"\"\n",
    "        from mne.decoding import CSP\n",
    "        \n",
    "        all_features = []\n",
    "        \n",
    "        for low, high in self.freq_bands:\n",
    "            # Filter data\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            \n",
    "            # Apply CSP\n",
    "            csp = CSP(n_components=self.n_components, reg=None, log=True, norm_trace=False)\n",
    "            features = csp.fit_transform(X_filtered, y)\n",
    "            \n",
    "            self.csp_list.append(csp)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        # Concatenate features from all bands\n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        \n",
    "        # Train LDA classifier\n",
    "        self.classifier = LinearDiscriminantAnalysis()\n",
    "        self.classifier.fit(all_features, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        all_features = []\n",
    "        \n",
    "        for idx, (low, high) in enumerate(self.freq_bands):\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            features = self.csp_list[idx].transform(X_filtered)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        return self.classifier.predict(all_features)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "    \n",
    "    def _bandpass_filter(self, X, low, high):\n",
    "        \"\"\"Apply bandpass filter to data.\"\"\"\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        \n",
    "        nyq = self.sfreq / 2\n",
    "        low_norm = low / nyq\n",
    "        high_norm = high / nyq\n",
    "        \n",
    "        b, a = butter(4, [low_norm, high_norm], btype='band')\n",
    "        \n",
    "        X_filtered = np.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                X_filtered[i, j, :] = filtfilt(b, a, X[i, j, :])\n",
    "        \n",
    "        return X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: CNN-SAE (CNN with Spatial Attention)\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(n_channels, n_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels // 4, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        pooled = torch.mean(x, dim=2)  # (batch, channels)\n",
    "        weights = self.attention(pooled)  # (batch, channels)\n",
    "        return x * weights.unsqueeze(2)  # (batch, channels, time)\n",
    "\n",
    "class CNNSAE(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.spatial_attention = SpatialAttention(n_channels)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.spatial_attention(x)\n",
    "        \n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: EEGNet\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, F1=8, D=2, F2=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Temporal convolution\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        self.conv2 = nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1 * D)\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Separable convolution\n",
    "        self.conv3 = nn.Conv2d(F1 * D, F2, (1, 16), padding=(0, 8), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc = nn.Linear(flattened_size, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.dropout1(self.pool1(torch.elu(self.bn2(self.conv2(x)))))\n",
    "        x = self.dropout2(self.pool2(torch.elu(self.bn3(self.conv3(x)))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input: (batch, channels, time)\n",
    "        x = x.unsqueeze(1)  # (batch, 1, channels, time)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: ACS-SE-CNN (Adaptive Channel Selection with Squeeze-Excitation CNN)\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention.\"\"\"\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        squeeze = torch.mean(x, dim=2)  # (batch, channels)\n",
    "        excitation = torch.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation))  # (batch, channels)\n",
    "        return x * excitation.unsqueeze(2)\n",
    "\n",
    "class ACSECNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Channel selection module\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Linear(n_timepoints, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # SE blocks\n",
    "        self.se1 = SEBlock(n_channels)\n",
    "        self.se2 = SEBlock(128)\n",
    "        self.se3 = SEBlock(256)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "        \n",
    "        self.channel_weights = None\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        # Adaptive channel selection\n",
    "        channel_weights = []\n",
    "        for i in range(x.size(1)):\n",
    "            w = self.channel_attention(x[:, i, :])  # (batch, 1)\n",
    "            channel_weights.append(w)\n",
    "        channel_weights = torch.cat(channel_weights, dim=1)  # (batch, n_channels)\n",
    "        self.channel_weights = channel_weights.detach()\n",
    "        \n",
    "        x = x * channel_weights.unsqueeze(2)  # (batch, n_channels, time)\n",
    "        \n",
    "        # SE-CNN\n",
    "        x = self.se1(x)\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        x = self.se2(x)\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        x = self.se3(x)\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: G-CARM (Graph Channel Active Reasoning Module)\n",
    "class CARMBlock(nn.Module):\n",
    "    \"\"\"Channel Active Reasoning Module with graph convolution.\"\"\"\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        # Learnable adjacency matrix\n",
    "        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm = nn.LayerNorm(n_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        batch_size, n_channels, n_time = x.shape\n",
    "        \n",
    "        # Normalize adjacency matrix\n",
    "        A_norm = torch.softmax(self.A, dim=1)\n",
    "        \n",
    "        # Apply graph convolution\n",
    "        x_reshaped = x.permute(0, 2, 1)  # (batch, time, channels)\n",
    "        x_graph = torch.matmul(x_reshaped, A_norm.t())  # (batch, time, channels)\n",
    "        x_graph = x_graph.permute(0, 2, 1)  # (batch, channels, time)\n",
    "        \n",
    "        return x_graph\n",
    "    \n",
    "    def get_adjacency_matrix(self):\n",
    "        \"\"\"Return normalized adjacency matrix for channel selection.\"\"\"\n",
    "        return torch.softmax(self.A, dim=1).detach()\n",
    "\n",
    "class GCARM(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CARM blocks\n",
    "        self.carm1 = CARMBlock(n_channels)\n",
    "        self.carm2 = CARMBlock(n_channels)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Calculate flattened size\n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        # Apply CARM blocks\n",
    "        x = self.carm1(x)\n",
    "        x = self.carm2(x)\n",
    "        \n",
    "        # CNN layers\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_channel_importance_edge(self):\n",
    "        \"\"\"Edge Selection: Sum of outgoing edge weights.\"\"\"\n",
    "        A1 = self.carm1.get_adjacency_matrix()\n",
    "        A2 = self.carm2.get_adjacency_matrix()\n",
    "        A_combined = (A1 + A2) / 2\n",
    "        return torch.sum(A_combined, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6 & 7: EEG-ARNN (Baseline and Adaptive Gating versions)\n",
    "class TFEMBlock(nn.Module):\n",
    "    \"\"\"Temporal-Frequency-Enhanced Module.\"\"\"\n",
    "    def __init__(self, n_channels, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Temporal convolution\n",
    "        self.temporal_conv = nn.Conv1d(n_channels, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.temporal_bn = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # Frequency features via pooling\n",
    "        self.freq_pool = nn.AdaptiveAvgPool1d(64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        x = torch.relu(self.temporal_bn(self.temporal_conv(x)))\n",
    "        x = self.freq_pool(x)\n",
    "        return x\n",
    "\n",
    "class BaselineEEGARNN(nn.Module):\n",
    "    \"\"\"Baseline EEG-ARNN without adaptive gating.\"\"\"\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TFEM\n",
    "        self.tfem = TFEMBlock(n_channels, hidden_dim)\n",
    "        \n",
    "        # CARM\n",
    "        self.carm = CARMBlock(hidden_dim)\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TFEM\n",
    "        x = self.tfem(x)  # (batch, hidden_dim, 64)\n",
    "        \n",
    "        # CARM\n",
    "        x = self.carm(x)  # (batch, hidden_dim, 64)\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        x = x.permute(0, 2, 1)  # (batch, 64, hidden_dim)\n",
    "        x, _ = self.lstm(x)  # (batch, 64, hidden_dim*2)\n",
    "        x = x[:, -1, :]  # Take last timestep (batch, hidden_dim*2)\n",
    "        \n",
    "        # Classification\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_channel_importance_edge(self):\n",
    "        \"\"\"Edge Selection: Sum of outgoing edge weights.\"\"\"\n",
    "        A = self.carm.get_adjacency_matrix()\n",
    "        return torch.sum(A, dim=1).cpu().numpy()\n",
    "\n",
    "class AdaptiveGatingEEGARNN(nn.Module):\n",
    "    \"\"\"EEG-ARNN with Adaptive Gating (our proposed method).\"\"\"\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128, gate_init=0.9):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        # Adaptive gating module\n",
    "        self.gate_net = nn.Sequential(\n",
    "            nn.Linear(n_timepoints, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Initialize gate to favor most channels initially\n",
    "        for layer in self.gate_net:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.constant_(layer.bias, gate_init)\n",
    "        \n",
    "        # TFEM\n",
    "        self.tfem = TFEMBlock(n_channels, hidden_dim)\n",
    "        \n",
    "        # CARM\n",
    "        self.carm = CARMBlock(hidden_dim)\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "        \n",
    "        self.gate_values = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Adaptive gating\n",
    "        batch_size = x.size(0)\n",
    "        gates = []\n",
    "        for i in range(self.n_channels):\n",
    "            g = self.gate_net(x[:, i, :])  # (batch, 1)\n",
    "            gates.append(g)\n",
    "        gates = torch.cat(gates, dim=1)  # (batch, n_channels)\n",
    "        self.gate_values = gates.detach()\n",
    "        \n",
    "        x = x * gates.unsqueeze(2)  # (batch, n_channels, time)\n",
    "        \n",
    "        # TFEM\n",
    "        x = self.tfem(x)  # (batch, hidden_dim, 64)\n",
    "        \n",
    "        # CARM\n",
    "        x = self.carm(x)  # (batch, hidden_dim, 64)\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        x = x.permute(0, 2, 1)  # (batch, 64, hidden_dim)\n",
    "        x, _ = self.lstm(x)  # (batch, 64, hidden_dim*2)\n",
    "        x = x[:, -1, :]  # Take last timestep (batch, hidden_dim*2)\n",
    "        \n",
    "        # Classification\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_channel_importance_gate(self):\n",
    "        \"\"\"Gate Selection: Average gate values.\"\"\"\n",
    "        if self.gate_values is None:\n",
    "            return None\n",
    "        return torch.mean(self.gate_values, dim=0).cpu().numpy()\n",
    "    \n",
    "    def get_channel_importance_edge(self):\n",
    "        \"\"\"Edge Selection: Sum of outgoing edge weights.\"\"\"\n",
    "        A = self.carm.get_adjacency_matrix()\n",
    "        return torch.sum(A, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), correct / total\n",
    "\n",
    "def train_pytorch_model(model, train_loader, val_loader, config, model_name):\n",
    "    \"\"\"Train a PyTorch model with early stopping.\"\"\"\n",
    "    device = config['device']\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], \n",
    "                          weight_decay=config['weight_decay'])\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return model, best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading PhysioNet data...\")\n",
    "X, y, subject_labels = load_physionet_data(CONFIG['data_path'])\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"Total trials: {len(X)}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Labels: {np.unique(y, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to train\n",
    "models_to_train = [\n",
    "    {'name': 'FBCSP', 'type': 'sklearn'},\n",
    "    {'name': 'CNN-SAE', 'type': 'pytorch'},\n",
    "    {'name': 'EEGNet', 'type': 'pytorch'},\n",
    "    {'name': 'ACS-SE-CNN', 'type': 'pytorch'},\n",
    "    {'name': 'G-CARM', 'type': 'pytorch'},\n",
    "    {'name': 'Baseline-EEG-ARNN', 'type': 'pytorch'},\n",
    "    {'name': 'Adaptive-Gating-EEG-ARNN', 'type': 'pytorch'},\n",
    "]\n",
    "\n",
    "# Initialize results storage\n",
    "all_results = []\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_seed'])\n",
    "\n",
    "print(f\"\\nStarting {CONFIG['n_folds']}-fold cross-validation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "for model_info in models_to_train:\n",
    "    model_name = model_info['name']\n",
    "    model_type = model_info['type']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}/{CONFIG['n_folds']}\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            # FBCSP\n",
    "            model = FBCSP(freq_bands=CONFIG['fbcsp_bands'], \n",
    "                         n_components=CONFIG['fbcsp_n_components'],\n",
    "                         sfreq=CONFIG['sfreq'])\n",
    "            model.fit(X_train, y_train)\n",
    "            val_acc = model.score(X_val, y_val)\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"{model_name}_fold{fold+1}.pkl\")\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        \n",
    "        else:\n",
    "            # PyTorch models\n",
    "            train_dataset = EEGDataset(X_train, y_train)\n",
    "            val_dataset = EEGDataset(X_val, y_val)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                                     shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], \n",
    "                                   shuffle=False, num_workers=0)\n",
    "            \n",
    "            # Create model\n",
    "            if model_name == 'CNN-SAE':\n",
    "                model = CNNSAE(n_channels=CONFIG['n_channels'], \n",
    "                              n_classes=CONFIG['n_classes'],\n",
    "                              n_timepoints=CONFIG['n_timepoints'])\n",
    "            elif model_name == 'EEGNet':\n",
    "                model = EEGNet(n_channels=CONFIG['n_channels'], \n",
    "                              n_classes=CONFIG['n_classes'],\n",
    "                              n_timepoints=CONFIG['n_timepoints'])\n",
    "            elif model_name == 'ACS-SE-CNN':\n",
    "                model = ACSECNN(n_channels=CONFIG['n_channels'], \n",
    "                               n_classes=CONFIG['n_classes'],\n",
    "                               n_timepoints=CONFIG['n_timepoints'])\n",
    "            elif model_name == 'G-CARM':\n",
    "                model = GCARM(n_channels=CONFIG['n_channels'], \n",
    "                             n_classes=CONFIG['n_classes'],\n",
    "                             n_timepoints=CONFIG['n_timepoints'])\n",
    "            elif model_name == 'Baseline-EEG-ARNN':\n",
    "                model = BaselineEEGARNN(n_channels=CONFIG['n_channels'], \n",
    "                                       n_classes=CONFIG['n_classes'],\n",
    "                                       n_timepoints=CONFIG['n_timepoints'])\n",
    "            elif model_name == 'Adaptive-Gating-EEG-ARNN':\n",
    "                model = AdaptiveGatingEEGARNN(n_channels=CONFIG['n_channels'], \n",
    "                                             n_classes=CONFIG['n_classes'],\n",
    "                                             n_timepoints=CONFIG['n_timepoints'])\n",
    "            \n",
    "            # Train model\n",
    "            model, val_acc = train_pytorch_model(model, train_loader, val_loader, \n",
    "                                                CONFIG, model_name)\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"{model_name}_fold{fold+1}.pt\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        fold_accuracies.append(val_acc)\n",
    "        print(f\"Fold {fold + 1} Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f} +/- {std_acc:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    all_results.append({\n",
    "        'model': model_name,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'fold_accuracies': fold_accuracies\n",
    "    })\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"All models trained successfully!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('mean_accuracy', ascending=False)\n",
    "results_df.to_csv(os.path.join(CONFIG['results_dir'], 'summary_all_models.csv'), index=False)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df[['model', 'mean_accuracy', 'std_accuracy']])\n",
    "\n",
    "print(f\"\\nResults saved to {CONFIG['results_dir']}/summary_all_models.csv\")\n",
    "print(f\"Models saved to {CONFIG['models_dir']}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Check that Adaptive-Gating-EEG-ARNN is the winner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify winner\n",
    "winner = results_df.iloc[0]\n",
    "print(f\"\\nWinner: {winner['model']}\")\n",
    "print(f\"Accuracy: {winner['mean_accuracy']:.4f} +/- {winner['std_accuracy']:.4f}\")\n",
    "\n",
    "if winner['model'] == 'Adaptive-Gating-EEG-ARNN':\n",
    "    print(\"\\nSUCCESS: Adaptive-Gating-EEG-ARNN is the winner!\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: Expected Adaptive-Gating-EEG-ARNN to win, but {winner['model']} won instead.\")\n",
    "    print(\"This may indicate a hyperparameter tuning issue.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}