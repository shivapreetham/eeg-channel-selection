{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PhysioNet EEG: Complete Pipeline - Training, Channel Selection & Results Generation\n\nThis unified notebook contains the complete experimental pipeline:\n1. Train all 7 baseline models with improved hyperparameters\n2. Evaluate channel selection methods (Edge, Aggregation, Gate)\n3. Generate all paper-ready results, tables, and figures\n\n**Improved Hyperparameters for Faster Convergence:**\n- Epochs: 25 (with early stopping patience=5)\n- Learning rate: 0.002 (2x original)\n- Adaptive LR scheduling with ReduceLROnPlateau\n- Early stopping enabled for faster training\n\n**Expected Runtime**: ~18-20 hours on Kaggle GPU\n\n**Estimated Breakdown:**\n- Initial training (7 models × 3 folds × ~15 min): ~5 hours\n- Channel selection (2 models × 3 methods × 5 k-values × 3 folds × ~15 min): ~11 hours\n- Retention (6 k-values × 3 folds × ~15 min): ~4.5 hours\n\n**Input**: `/kaggle/input/eeg-preprocessed-data/derived/`\n\n**Output**:\n- `models/` - Trained model checkpoints\n- `results/` - CSV files with all results\n- `figures/` - Publication-ready figures"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration with improved hyperparameters\nCONFIG = {\n    'data_path': '/kaggle/input/eeg-preprocessed-data/derived',\n    'output_dir': './',\n    'results_dir': './results',\n    'models_dir': './models',\n    'figures_dir': './figures',\n\n    'n_folds': 3,\n    'random_seed': 42,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n\n    # IMPROVED Training hyperparameters for faster convergence\n    'batch_size': 64,\n    'epochs': 25,  # Balanced: faster than 50, better convergence than 20\n    'learning_rate': 0.002,  # 2x original for faster convergence\n    'weight_decay': 1e-4,\n    'patience': 5,  # Early stopping patience\n    'scheduler_patience': 2,  # LR reduction patience\n    'scheduler_factor': 0.5,\n    'use_early_stopping': True,  # Enabled\n    'min_lr': 1e-6,\n\n    # Data parameters\n    'n_channels': 64,\n    'n_classes': 2,\n    'sfreq': 128,\n    'tmin': 0.0,\n    'tmax': 4.0,\n    'n_timepoints': 513,\n    'hidden_dim': 128,\n    'mi_runs': [7, 8, 11, 12],\n\n    # FBCSP parameters\n    'fbcsp_bands': [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 36), (36, 40)],\n    'fbcsp_n_components': 4,\n\n    # Gating regularization\n    'gating': {\n        'gate_init': 0.9,\n        'l1_lambda': 1e-3,\n    },\n    \n    # Channel selection k values (REDUCED FOR FASTER RUNTIME)\n    'k_values': [10, 20, 30, 40, 50],  # 5 values instead of more\n    'retention_k_values': [10, 15, 20, 25, 30, 35],  # 6 values for retention curve\n}\n\n# Create output directories\nos.makedirs(CONFIG['results_dir'], exist_ok=True)\nos.makedirs(CONFIG['models_dir'], exist_ok=True)\nos.makedirs(CONFIG['figures_dir'], exist_ok=True)\n\n# Set random seeds\nnp.random.seed(CONFIG['random_seed'])\ntorch.manual_seed(CONFIG['random_seed'])\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(CONFIG['random_seed'])\n    torch.backends.cudnn.deterministic = True\n\nprint(f\"Device: {CONFIG['device']}\")\nprint(f\"Data path: {CONFIG['data_path']}\")\nprint(f\"Epochs: {CONFIG['epochs']}\")\nprint(f\"Learning rate: {CONFIG['learning_rate']}\")\nprint(f\"Early stopping: {CONFIG['use_early_stopping']} (patience={CONFIG['patience']})\")\nprint(f\"\\nChannel selection k-values: {CONFIG['k_values']}\")\nprint(f\"Retention analysis k-values: {CONFIG['retention_k_values']}\")\n\n# Calculate estimated runtime\nbaseline_runs = 7 * 3  # 7 models × 3 folds\ncs_runs = 2 * 3 * len(CONFIG['k_values']) * 3  # 2 models × 3 methods × 5 k-values × 3 folds\nretention_runs = len(CONFIG['retention_k_values']) * 3  # 6 k-values × 3 folds\ntotal_runs = baseline_runs + cs_runs + retention_runs\n\nprint(f\"\\nEstimated training runs:\")\nprint(f\"  - Baseline models: {baseline_runs}\")\nprint(f\"  - Channel selection: {cs_runs}\")\nprint(f\"  - Retention analysis: {retention_runs}\")\nprint(f\"  - TOTAL: {total_runs} training runs\")\nprint(f\"\\nEstimated runtime (15 min/run): ~{total_runs * 15 / 60:.1f} hours\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_physionet_data(data_path, subject_ids=None):\n",
    "    \"\"\"\n",
    "    Load preprocessed PhysioNet motor imagery data.\n",
    "    Supports both preprocessed folder structure and legacy flat directory.\n",
    "    \"\"\"\n",
    "    data_root = os.path.abspath(data_path)\n",
    "    if not os.path.isdir(data_root):\n",
    "        raise FileNotFoundError(f\"Data path not found: {data_root}\")\n",
    "\n",
    "    config = globals().get('CONFIG', {})\n",
    "    tmin = float(config.get('tmin', 0.0))\n",
    "    tmax = float(config.get('tmax', 4.0))\n",
    "    mi_runs = [int(r) for r in config.get('mi_runs', [7, 8, 11, 12])]\n",
    "    event_id = {'T1': 1, 'T2': 2}\n",
    "\n",
    "    def normalize_subject(value):\n",
    "        if value is None:\n",
    "            return None\n",
    "        if isinstance(value, str) and value.upper().startswith('S'):\n",
    "            value = value[1:]\n",
    "        try:\n",
    "            return int(value)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    subject_filter = None\n",
    "    if subject_ids is not None:\n",
    "        subject_filter = set()\n",
    "        for sid in subject_ids:\n",
    "            norm = normalize_subject(sid)\n",
    "            if norm is not None:\n",
    "                subject_filter.add(norm)\n",
    "        if not subject_filter:\n",
    "            subject_filter = None\n",
    "\n",
    "    def aggregate_results(blocks_X, blocks_y, blocks_subjects):\n",
    "        X = np.concatenate(blocks_X, axis=0)\n",
    "        y = np.concatenate(blocks_y, axis=0)\n",
    "        subjects = np.concatenate(blocks_subjects, axis=0)\n",
    "        print(f\"Loaded {len(X)} trials from {len(np.unique(subjects))} subjects\")\n",
    "        print(f\"Data shape: {X.shape}\")\n",
    "        print(f\"Label distribution: {np.bincount(y)}\")\n",
    "        return X, y, subjects\n",
    "\n",
    "    subject_root = data_root\n",
    "    preprocessed_dir = os.path.join(data_root, 'preprocessed')\n",
    "    if os.path.isdir(preprocessed_dir):\n",
    "        subject_root = preprocessed_dir\n",
    "    \n",
    "    subject_dirs = [d for d in sorted(os.listdir(subject_root))\n",
    "                    if os.path.isdir(os.path.join(subject_root, d)) and d.upper().startswith('S')]\n",
    "\n",
    "    all_X, all_y, all_subjects = [], [], []\n",
    "    \n",
    "    if subject_dirs:\n",
    "        print(f\"Detected {len(subject_dirs)} preprocessed subject folders\")\n",
    "        label_map = {event_id['T1']: 0, event_id['T2']: 1}\n",
    "        \n",
    "        for subject_dir in subject_dirs:\n",
    "            subject_numeric = normalize_subject(subject_dir)\n",
    "            if subject_filter and subject_numeric not in subject_filter:\n",
    "                continue\n",
    "            \n",
    "            subject_path = os.path.join(subject_root, subject_dir)\n",
    "            \n",
    "            for run_id in mi_runs:\n",
    "                candidate_names = [\n",
    "                    f\"{subject_dir}R{run_id:02d}_preproc_raw.fif\",\n",
    "                    f\"{subject_dir}R{run_id:02d}_raw.fif\",\n",
    "                    f\"{subject_dir}R{run_id:02d}.fif\",\n",
    "                    f\"{subject_dir}_R{run_id:02d}.fif\",\n",
    "                ]\n",
    "                \n",
    "                run_path = None\n",
    "                for name in candidate_names:\n",
    "                    candidate = os.path.join(subject_path, name)\n",
    "                    if os.path.exists(candidate):\n",
    "                        run_path = candidate\n",
    "                        break\n",
    "                \n",
    "                if run_path is None:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    raw = mne.io.read_raw_fif(run_path, preload=True, verbose=False)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                \n",
    "                picks = mne.pick_types(raw.info, eeg=True, meg=False, stim=False, eog=False)\n",
    "                if len(picks) == 0:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    events, _ = mne.events_from_annotations(raw, event_id=event_id)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                \n",
    "                if len(events) == 0:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                                        baseline=None, preload=True, picks=picks, verbose=False)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                \n",
    "                data = epochs.get_data()\n",
    "                labels = epochs.events[:, 2]\n",
    "                mapped = np.array([label_map.get(lbl, -1) for lbl in labels])\n",
    "                valid_mask = mapped >= 0\n",
    "                \n",
    "                if not np.any(valid_mask):\n",
    "                    continue\n",
    "                \n",
    "                all_X.append(data[valid_mask])\n",
    "                all_y.append(mapped[valid_mask])\n",
    "                subj_label = subject_numeric if subject_numeric is not None else -1\n",
    "                all_subjects.append(np.full(np.sum(valid_mask), subj_label))\n",
    "        \n",
    "        if all_X:\n",
    "            return aggregate_results(all_X, all_y, all_subjects)\n",
    "    \n",
    "    # Legacy format fallback\n",
    "    legacy_files = [f for f in os.listdir(data_root) if f.endswith('.fif')]\n",
    "    if not legacy_files:\n",
    "        raise ValueError(\"No valid PhysioNet files found\")\n",
    "    \n",
    "    print(f\"Found {len(legacy_files)} legacy epoch files. Loading...\")\n",
    "    for fname in legacy_files:\n",
    "        filepath = os.path.join(data_root, fname)\n",
    "        try:\n",
    "            epochs = mne.read_epochs(filepath, preload=True, verbose=False)\n",
    "        except Exception:\n",
    "            continue\n",
    "        \n",
    "        current_event_id = epochs.event_id\n",
    "        if not current_event_id:\n",
    "            continue\n",
    "        \n",
    "        label_lookup = {}\n",
    "        if 'T1' in current_event_id:\n",
    "            label_lookup[current_event_id['T1']] = 0\n",
    "        if 'T2' in current_event_id:\n",
    "            label_lookup[current_event_id['T2']] = 1\n",
    "        \n",
    "        if not label_lookup:\n",
    "            continue\n",
    "        \n",
    "        labels = np.array([label_lookup.get(epochs.events[i, -1], -1) for i in range(len(epochs))])\n",
    "        valid = labels >= 0\n",
    "        \n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "        \n",
    "        data = epochs.get_data()[valid]\n",
    "        labels = labels[valid]\n",
    "        subj = normalize_subject(fname.split('_')[0])\n",
    "        subj_arr = np.full(len(labels), subj if subj is not None else -1)\n",
    "        \n",
    "        all_X.append(data)\n",
    "        all_y.append(labels)\n",
    "        all_subjects.append(subj_arr)\n",
    "    \n",
    "    if not all_X:\n",
    "        raise ValueError(\"No valid trials were loaded\")\n",
    "    \n",
    "    return aggregate_results(all_X, all_y, all_subjects)\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for EEG data.\"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: FBCSP\n",
    "class FBCSP:\n",
    "    \"\"\"Filter Bank Common Spatial Patterns with LDA classifier.\"\"\"\n",
    "    def __init__(self, freq_bands, n_components=4, sfreq=128):\n",
    "        self.freq_bands = freq_bands\n",
    "        self.n_components = n_components\n",
    "        self.sfreq = sfreq\n",
    "        self.csp_list = []\n",
    "        self.classifier = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        from mne.decoding import CSP\n",
    "        \n",
    "        all_features = []\n",
    "        \n",
    "        for low, high in self.freq_bands:\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            csp = CSP(n_components=self.n_components, reg=None, log=True, norm_trace=False)\n",
    "            features = csp.fit_transform(X_filtered, y)\n",
    "            self.csp_list.append(csp)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        self.classifier = LinearDiscriminantAnalysis()\n",
    "        self.classifier.fit(all_features, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        all_features = []\n",
    "        \n",
    "        for idx, (low, high) in enumerate(self.freq_bands):\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            features = self.csp_list[idx].transform(X_filtered)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        return self.classifier.predict(all_features)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "    \n",
    "    def _bandpass_filter(self, X, low, high):\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        \n",
    "        nyq = self.sfreq / 2\n",
    "        low_norm = low / nyq\n",
    "        high_norm = high / nyq\n",
    "        b, a = butter(4, [low_norm, high_norm], btype='band')\n",
    "        \n",
    "        X_filtered = np.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                X_filtered[i, j, :] = filtfilt(b, a, X[i, j, :])\n",
    "        \n",
    "        return X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: CNN-SAE\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(n_channels, n_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels // 4, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pooled = torch.mean(x, dim=2)\n",
    "        weights = self.attention(pooled)\n",
    "        return x * weights.unsqueeze(2)\n",
    "\n",
    "\n",
    "class CNNSAE(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.spatial_attention = SpatialAttention(n_channels)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.spatial_attention(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: EEGNet\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, F1=8, D=2, F2=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1 * D)\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(F1 * D, F2, (1, 16), padding=(0, 8), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "\n",
    "        self.fc = nn.Linear(flattened_size, n_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.dropout1(self.pool1(F.elu(self.bn2(self.conv2(x)))))\n",
    "        x = self.dropout2(self.pool2(F.elu(self.bn3(self.conv3(x)))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: ACS-SE-CNN\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        hidden = max(1, channels // reduction)\n",
    "        self.fc1 = nn.Linear(channels, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        squeeze = torch.mean(x, dim=2)\n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation))\n",
    "        return x * excitation.unsqueeze(2)\n",
    "\n",
    "\n",
    "class ACSECNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Linear(n_timepoints, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.se1 = SEBlock(n_channels)\n",
    "        self.se2 = SEBlock(128)\n",
    "        self.se3 = SEBlock(256)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "        \n",
    "        self.channel_weights = None\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        channel_weights = []\n",
    "        for i in range(x.size(1)):\n",
    "            w = self.channel_attention(x[:, i, :])\n",
    "            channel_weights.append(w)\n",
    "        channel_weights = torch.cat(channel_weights, dim=1)\n",
    "        self.channel_weights = channel_weights.detach()\n",
    "        \n",
    "        x = x * channel_weights.unsqueeze(2)\n",
    "        \n",
    "        x = self.se1(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        x = self.se2(x)\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        x = self.se3(x)\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: G-CARM\n",
    "class CARMBlock(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n",
    "        self.norm = nn.LayerNorm(n_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, n_channels, n_time = x.shape\n",
    "        A_norm = torch.softmax(self.A, dim=1)\n",
    "        x_reshaped = x.permute(0, 2, 1)\n",
    "        x_graph = torch.matmul(x_reshaped, A_norm.t())\n",
    "        x_graph = x_graph.permute(0, 2, 1)\n",
    "        return x_graph\n",
    "    \n",
    "    def get_adjacency_matrix(self):\n",
    "        return torch.softmax(self.A, dim=1).detach()\n",
    "\n",
    "\n",
    "class GCARM(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.carm1 = CARMBlock(n_channels)\n",
    "        self.carm2 = CARMBlock(n_channels)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "        test_output = self._forward_features(test_input)\n",
    "        flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.carm1(x)\n",
    "        x = self.carm2(x)\n",
    "        \n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_channel_importance_edge(self):\n",
    "        A1 = self.carm1.get_adjacency_matrix()\n",
    "        A2 = self.carm2.get_adjacency_matrix()\n",
    "        A_combined = (A1 + A2) / 2\n",
    "        return torch.sum(A_combined, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models 6 & 7: Baseline EEG-ARNN and Adaptive Gating EEG-ARNN\n",
    "class GraphConvLayer(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.A = nn.Parameter(torch.randn(num_channels, num_channels) * 0.01)\n",
    "        self.theta = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(hidden_dim)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, C, T = x.shape\n",
    "        A = torch.sigmoid(self.A)\n",
    "        A = 0.5 * (A + A.t())\n",
    "        I = torch.eye(C, device=A.device)\n",
    "        A_hat = A + I\n",
    "        D = torch.diag(torch.pow(A_hat.sum(1).clamp_min(1e-6), -0.5))\n",
    "        A_norm = D @ A_hat @ D\n",
    "\n",
    "        x_perm = x.permute(0, 3, 2, 1).contiguous().view(B * T, C, H)\n",
    "        x_g = A_norm @ x_perm\n",
    "        x_g = self.theta(x_g)\n",
    "        x_g = x_g.view(B, T, C, H).permute(0, 3, 2, 1)\n",
    "        x_out = self.bn(x_g)\n",
    "        return self.act(x_out)\n",
    "\n",
    "    def get_adjacency(self):\n",
    "        with torch.no_grad():\n",
    "            A = torch.sigmoid(self.A)\n",
    "            A = 0.5 * (A + A.t())\n",
    "            return A.cpu().numpy()\n",
    "\n",
    "\n",
    "class TemporalConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=16, pool=True):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=(1, kernel_size),\n",
    "                              padding=(0, kernel_size // 2), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ELU()\n",
    "        self.pool_layer = nn.AvgPool2d(kernel_size=(1, 2)) if pool else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn(self.conv(x)))\n",
    "        if self.pool_layer is not None:\n",
    "            x = self.pool_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BaselineEEGARNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_gate_regularizer = False\n",
    "        self.gate_penalty_tensor = None\n",
    "        self.latest_gate_values = None\n",
    "\n",
    "        self.t1 = TemporalConv(1, hidden_dim, 16, pool=False)\n",
    "        self.g1 = GraphConvLayer(n_channels, hidden_dim)\n",
    "        self.t2 = TemporalConv(hidden_dim, hidden_dim, 16, pool=True)\n",
    "        self.g2 = GraphConvLayer(n_channels, hidden_dim)\n",
    "        self.t3 = TemporalConv(hidden_dim, hidden_dim, 16, pool=True)\n",
    "        self.g3 = GraphConvLayer(n_channels, hidden_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, n_channels, n_timepoints)\n",
    "            feat = self._forward_features(self._prepare_input(dummy))\n",
    "            self.feature_dim = feat.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_dim, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def _prepare_input(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.g1(self.t1(x))\n",
    "        x = self.g2(self.t2(x))\n",
    "        x = self.g3(self.t3(x))\n",
    "        return x\n",
    "\n",
    "    def _forward_from_prepared(self, x):\n",
    "        features = self._forward_features(x)\n",
    "        x = features.view(features.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        prepared = self._prepare_input(x)\n",
    "        self.gate_penalty_tensor = None\n",
    "        self.latest_gate_values = None\n",
    "        return self._forward_from_prepared(prepared)\n",
    "\n",
    "    def get_final_adjacency(self):\n",
    "        return self.g3.get_adjacency()\n",
    "\n",
    "    def get_channel_importance_edge(self):\n",
    "        adjacency = self.get_final_adjacency()\n",
    "        return np.sum(adjacency, axis=1)\n",
    "\n",
    "\n",
    "class AdaptiveGatingEEGARNN(BaselineEEGARNN):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, hidden_dim=128, gate_init=0.9):\n",
    "        super().__init__(n_channels, n_classes, n_timepoints, hidden_dim)\n",
    "        self.use_gate_regularizer = True\n",
    "        \n",
    "        self.gate_net = nn.Sequential(\n",
    "            nn.Linear(n_channels * 2, n_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        init_value = float(np.clip(gate_init, 1e-3, 1 - 1e-3))\n",
    "        init_bias = math.log(init_value / (1.0 - init_value))\n",
    "        with torch.no_grad():\n",
    "            self.gate_net[-2].bias.fill_(init_bias)\n",
    "        \n",
    "        self.latest_gate_values = None\n",
    "\n",
    "    def compute_gates(self, x):\n",
    "        x_s = x.squeeze(1)\n",
    "        ch_mean = x_s.mean(dim=2)\n",
    "        ch_std = x_s.std(dim=2)\n",
    "        stats = torch.cat([ch_mean, ch_std], dim=1)\n",
    "        return self.gate_net(stats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        prepared = self._prepare_input(x)\n",
    "        gates = self.compute_gates(prepared)\n",
    "        self.gate_penalty_tensor = gates\n",
    "        self.latest_gate_values = gates.detach()\n",
    "        gated = prepared * gates.view(gates.size(0), 1, gates.size(1), 1)\n",
    "        return self._forward_from_prepared(gated)\n",
    "\n",
    "    def get_channel_importance_gate(self):\n",
    "        if self.latest_gate_values is None:\n",
    "            return None\n",
    "        return self.latest_gate_values.mean(dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, l1_lambda=0.0):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        gate_penalty = getattr(model, 'gate_penalty_tensor', None)\n",
    "        if l1_lambda > 0 and gate_penalty is not None:\n",
    "            loss = loss + l1_lambda * gate_penalty.abs().mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    denom = max(1, len(dataloader))\n",
    "    return total_loss / denom, correct / max(1, total)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    denom = max(1, len(dataloader))\n",
    "    return total_loss / denom, correct / max(1, total)\n",
    "\n",
    "\n",
    "def train_pytorch_model(model, train_loader, val_loader, config, model_name=''):\n",
    "    \"\"\"Train a PyTorch model with improved scheduler and early stopping.\"\"\"\n",
    "    device = config['device']\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], \n",
    "                          weight_decay=config['weight_decay'])\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=config.get('scheduler_factor', 0.5), \n",
    "        patience=config.get('scheduler_patience', 3), \n",
    "        min_lr=config.get('min_lr', 1e-6),\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    l1_lambda = config.get('gating', {}).get('l1_lambda', 0.0) if getattr(model, 'use_gate_regularizer', False) else 0.0\n",
    "    use_early_stopping = config.get('use_early_stopping', False)\n",
    "    max_patience = config.get('patience', 10)\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, l1_lambda)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        improved = val_acc > best_val_acc or (val_acc == best_val_acc and val_loss < best_val_loss)\n",
    "        if improved:\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        prefix = model_name if model_name else 'Model'\n",
    "        if epoch % 5 == 0 or improved:\n",
    "            print(f\"[{prefix}] Epoch {epoch + 1}/{config['epochs']} - \"\n",
    "                  f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | Best: {best_val_acc:.4f}\")\n",
    "\n",
    "        if use_early_stopping and patience_counter >= max_patience:\n",
    "            print(f\"Early stopping triggered for {prefix} at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return best_state, best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading PhysioNet data...\")\n",
    "X, y, subject_labels = load_physionet_data(CONFIG['data_path'])\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"Total trials: {len(X)}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Labels: {np.unique(y, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to train\n",
    "models_to_train = [\n",
    "    {'name': 'FBCSP', 'type': 'sklearn'},\n",
    "    {'name': 'CNN-SAE', 'type': 'pytorch'},\n",
    "    {'name': 'EEGNet', 'type': 'pytorch'},\n",
    "    {'name': 'ACS-SE-CNN', 'type': 'pytorch'},\n",
    "    {'name': 'G-CARM', 'type': 'pytorch'},\n",
    "    {'name': 'Baseline-EEG-ARNN', 'type': 'pytorch'},\n",
    "    {'name': 'Adaptive-Gating-EEG-ARNN', 'type': 'pytorch'},\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_seed'])\n",
    "\n",
    "print(f\"Starting {CONFIG['n_folds']}-fold cross-validation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "for model_info in models_to_train:\n",
    "    model_name = model_info['name']\n",
    "    model_type = model_info['type']\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}/{CONFIG['n_folds']}\")\n",
    "\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        if model_type == 'sklearn':\n",
    "            model = FBCSP(freq_bands=CONFIG['fbcsp_bands'],\n",
    "                          n_components=CONFIG['fbcsp_n_components'],\n",
    "                          sfreq=CONFIG['sfreq'])\n",
    "            model.fit(X_train, y_train)\n",
    "            val_acc = model.score(X_val, y_val)\n",
    "\n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"{model_name}_fold{fold+1}.pkl\")\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        else:\n",
    "            train_dataset = EEGDataset(X_train, y_train)\n",
    "            val_dataset = EEGDataset(X_val, y_val)\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                      shuffle=True, num_workers=0)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                    shuffle=False, num_workers=0)\n",
    "\n",
    "            base_kwargs = {\n",
    "                'n_channels': CONFIG['n_channels'],\n",
    "                'n_classes': CONFIG['n_classes'],\n",
    "                'n_timepoints': CONFIG['n_timepoints'],\n",
    "            }\n",
    "\n",
    "            if model_name == 'CNN-SAE':\n",
    "                model = CNNSAE(**base_kwargs)\n",
    "            elif model_name == 'EEGNet':\n",
    "                model = EEGNet(**base_kwargs)\n",
    "            elif model_name == 'ACS-SE-CNN':\n",
    "                model = ACSECNN(**base_kwargs)\n",
    "            elif model_name == 'G-CARM':\n",
    "                model = GCARM(**base_kwargs)\n",
    "            elif model_name == 'Baseline-EEG-ARNN':\n",
    "                model = BaselineEEGARNN(hidden_dim=CONFIG['hidden_dim'], **base_kwargs)\n",
    "            elif model_name == 'Adaptive-Gating-EEG-ARNN':\n",
    "                model = AdaptiveGatingEEGARNN(hidden_dim=CONFIG['hidden_dim'],\n",
    "                                              gate_init=CONFIG['gating']['gate_init'],\n",
    "                                              **base_kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "            best_state, val_acc = train_pytorch_model(model, train_loader, val_loader,\n",
    "                                                      CONFIG, model_name)\n",
    "            \n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"{model_name}_fold{fold+1}.pt\")\n",
    "            torch.save(best_state, model_path)\n",
    "            \n",
    "            # Clean up GPU memory\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        fold_accuracies.append(val_acc)\n",
    "        print(f\"Fold {fold + 1} Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f} +/- {std_acc:.4f}\")\n",
    "\n",
    "    all_results.append({\n",
    "        'model': model_name,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'fold_accuracies': fold_accuracies\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All models trained successfully!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('mean_accuracy', ascending=False)\n",
    "results_df.to_csv(os.path.join(CONFIG['results_dir'], 'summary_all_models.csv'), index=False)\n",
    "\n",
    "print(\"\\nInitial Results:\")\n",
    "print(results_df[['model', 'mean_accuracy', 'std_accuracy']])\n",
    "\n",
    "winner = results_df.iloc[0]\n",
    "print(f\"\\nBest Model: {winner['model']}\")\n",
    "print(f\"Accuracy: {winner['mean_accuracy']:.4f} +/- {winner['std_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Channel Selection Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel selection utilities\n",
    "def get_channel_importance_aggregation(model, dataloader, device):\n",
    "    \"\"\"Aggregation Selection (AS) using averaged feature activations.\"\"\"\n",
    "    model.eval()\n",
    "    channel_stats = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            prepared = model._prepare_input(X_batch)\n",
    "            features = model._forward_features(prepared)\n",
    "            activations = torch.mean(torch.abs(features), dim=(1, 3))\n",
    "            channel_stats.append(activations.cpu())\n",
    "\n",
    "    if not channel_stats:\n",
    "        return np.zeros(model.n_channels)\n",
    "    stacked = torch.cat(channel_stats, dim=0)\n",
    "    return stacked.mean(dim=0).numpy()\n",
    "\n",
    "\n",
    "def compute_gate_importance(model, dataloader, device):\n",
    "    \"\"\"Average adaptive gate values across the entire dataset.\"\"\"\n",
    "    model.eval()\n",
    "    gate_batches = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            _ = model(X_batch)\n",
    "            latest = getattr(model, 'latest_gate_values', None)\n",
    "            if latest is not None:\n",
    "                gate_batches.append(latest.cpu())\n",
    "\n",
    "    if not gate_batches:\n",
    "        return np.ones(model.n_channels) / model.n_channels\n",
    "    stacked = torch.cat(gate_batches, dim=0)\n",
    "    return stacked.mean(dim=0).numpy()\n",
    "\n",
    "\n",
    "def select_top_k_channels(importance_scores, k):\n",
    "    \"\"\"Select top k channels based on importance scores.\"\"\"\n",
    "    top_k_indices = np.argsort(importance_scores)[-k:]\n",
    "    return sorted(top_k_indices)\n",
    "\n",
    "\n",
    "def apply_channel_selection(X, selected_channels):\n",
    "    \"\"\"Apply channel selection to data.\"\"\"\n",
    "    return X[:, selected_channels, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to evaluate for channel selection\n",
    "models_to_evaluate = [\n",
    "    {'name': 'Baseline-EEG-ARNN', 'methods': ['edge', 'aggregation']},\n",
    "    {'name': 'Adaptive-Gating-EEG-ARNN', 'methods': ['edge', 'aggregation', 'gate']},\n",
    "]\n",
    "\n",
    "channel_selection_results = []\n",
    "\n",
    "def build_model(model_name, n_channels):\n",
    "    \"\"\"Build model with specified number of channels.\"\"\"\n",
    "    kwargs = {\n",
    "        'n_channels': n_channels,\n",
    "        'n_classes': CONFIG['n_classes'],\n",
    "        'n_timepoints': CONFIG['n_timepoints'],\n",
    "    }\n",
    "    if model_name == 'Baseline-EEG-ARNN':\n",
    "        return BaselineEEGARNN(hidden_dim=CONFIG['hidden_dim'], **kwargs)\n",
    "    return AdaptiveGatingEEGARNN(hidden_dim=CONFIG['hidden_dim'],\n",
    "                                 gate_init=CONFIG['gating']['gate_init'],\n",
    "                                 **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel selection evaluation loop\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CHANNEL SELECTION EVALUATION\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for model_info in models_to_evaluate:\n",
    "    model_name = model_info['name']\n",
    "    selection_methods = model_info['methods']\n",
    "\n",
    "    print(f\"\\nEvaluating {model_name}\\n{'-'*60}\")\n",
    "\n",
    "    for method in selection_methods:\n",
    "        print(f\"\\nMethod: {method.upper()}\")\n",
    "\n",
    "        for k in CONFIG['k_values']:\n",
    "            print(f\"\\n  k={k} channels:\", end=' ')\n",
    "            fold_accuracies = []\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "                X_train, X_val = X[train_idx], X[val_idx]\n",
    "                y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                # Load trained model\n",
    "                model = build_model(model_name, CONFIG['n_channels'])\n",
    "                model_path = os.path.join(CONFIG['models_dir'], f\"{model_name}_fold{fold+1}.pt\")\n",
    "                state_dict = torch.load(model_path, map_location=CONFIG['device'])\n",
    "                model.load_state_dict(state_dict)\n",
    "                model = model.to(CONFIG['device'])\n",
    "                model.eval()\n",
    "\n",
    "                # Compute importance scores\n",
    "                if method == 'edge':\n",
    "                    importance_scores = model.get_channel_importance_edge()\n",
    "                elif method == 'aggregation':\n",
    "                    train_dataset = EEGDataset(X_train, y_train)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                              shuffle=False, num_workers=0)\n",
    "                    importance_scores = get_channel_importance_aggregation(model, train_loader,\n",
    "                                                                            CONFIG['device'])\n",
    "                else:  # gate\n",
    "                    train_dataset = EEGDataset(X_train, y_train)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                              shuffle=False, num_workers=0)\n",
    "                    importance_scores = compute_gate_importance(model, train_loader, CONFIG['device'])\n",
    "\n",
    "                # Select channels\n",
    "                selected_channels = select_top_k_channels(importance_scores, k)\n",
    "                X_train_selected = apply_channel_selection(X_train, selected_channels)\n",
    "                X_val_selected = apply_channel_selection(X_val, selected_channels)\n",
    "\n",
    "                # Train new model with selected channels\n",
    "                new_model = build_model(model_name, k)\n",
    "                train_dataset = EEGDataset(X_train_selected, y_train)\n",
    "                val_dataset = EEGDataset(X_val_selected, y_val)\n",
    "\n",
    "                train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                          shuffle=True, num_workers=0)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                        shuffle=False, num_workers=0)\n",
    "\n",
    "                best_state, val_acc = train_pytorch_model(new_model, train_loader, val_loader,\n",
    "                                                          CONFIG, f\"{model_name}-{method}-k{k}\")\n",
    "                fold_accuracies.append(val_acc)\n",
    "                \n",
    "                # Clean up\n",
    "                del model, new_model\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            mean_acc = np.mean(fold_accuracies)\n",
    "            std_acc = np.std(fold_accuracies)\n",
    "            print(f\"{mean_acc:.4f} +/- {std_acc:.4f}\")\n",
    "\n",
    "            channel_selection_results.append({\n",
    "                'model': model_name,\n",
    "                'method': method,\n",
    "                'k': k,\n",
    "                'mean_accuracy': mean_acc,\n",
    "                'std_accuracy': std_acc,\n",
    "                'fold_accuracies': fold_accuracies\n",
    "            })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Channel selection evaluation complete!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save channel selection results\n",
    "cs_df = pd.DataFrame(channel_selection_results)\n",
    "cs_df.to_csv(os.path.join(CONFIG['results_dir'], 'channel_selection_results.csv'), index=False)\n",
    "\n",
    "print(\"\\nChannel Selection Results:\")\n",
    "print(cs_df[['model', 'method', 'k', 'mean_accuracy', 'std_accuracy']])\n",
    "\n",
    "# Find best method for each model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Best Channel Selection Methods:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name in ['Baseline-EEG-ARNN', 'Adaptive-Gating-EEG-ARNN']:\n",
    "    model_results = cs_df[cs_df['model'] == model_name]\n",
    "    best_result = model_results.loc[model_results['mean_accuracy'].idxmax()]\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Best Method: {best_result['method'].upper()}\")\n",
    "    print(f\"  Best k: {best_result['k']}\")\n",
    "    print(f\"  Accuracy: {best_result['mean_accuracy']:.4f} +/- {best_result['std_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Retention Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retention analysis\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RETENTION ANALYSIS: Adaptive-Gating-EEG-ARNN with Gate Selection\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "retention_results = []\n",
    "\n",
    "for k in CONFIG['retention_k_values']:\n",
    "    print(f\"\\nTesting with k={k} channels:\", end=' ')\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Load trained model\n",
    "        model = build_model('Adaptive-Gating-EEG-ARNN', CONFIG['n_channels'])\n",
    "        model_path = os.path.join(CONFIG['models_dir'], f\"Adaptive-Gating-EEG-ARNN_fold{fold+1}.pt\")\n",
    "        state_dict = torch.load(model_path, map_location=CONFIG['device'])\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to(CONFIG['device'])\n",
    "        model.eval()\n",
    "\n",
    "        # Compute gate importance\n",
    "        train_dataset = EEGDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                  shuffle=False, num_workers=0)\n",
    "        importance_scores = compute_gate_importance(model, train_loader, CONFIG['device'])\n",
    "        selected_channels = select_top_k_channels(importance_scores, k)\n",
    "\n",
    "        # Apply channel selection\n",
    "        X_train_selected = apply_channel_selection(X_train, selected_channels)\n",
    "        X_val_selected = apply_channel_selection(X_val, selected_channels)\n",
    "\n",
    "        # Train new model\n",
    "        new_model = build_model('Adaptive-Gating-EEG-ARNN', k)\n",
    "        train_dataset = EEGDataset(X_train_selected, y_train)\n",
    "        val_dataset = EEGDataset(X_val_selected, y_val)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                  shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'],\n",
    "                                shuffle=False, num_workers=0)\n",
    "\n",
    "        best_state, val_acc = train_pytorch_model(new_model, train_loader, val_loader,\n",
    "                                                  CONFIG, f\"Retention-k{k}\")\n",
    "        fold_accuracies.append(val_acc)\n",
    "        \n",
    "        # Clean up\n",
    "        del model, new_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "    print(f\"{mean_acc:.4f} +/- {std_acc:.4f}\")\n",
    "\n",
    "    retention_results.append({\n",
    "        'k': k,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'fold_accuracies': fold_accuracies\n",
    "    })\n",
    "\n",
    "# Save retention results\n",
    "retention_df = pd.DataFrame(retention_results)\n",
    "retention_df.to_csv(os.path.join(CONFIG['results_dir'], 'retention_analysis.csv'), index=False)\n",
    "\n",
    "print(\"\\nRetention Analysis Results:\")\n",
    "print(retention_df[['k', 'mean_accuracy', 'std_accuracy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Publication-Ready Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "print(\"Generating publication-ready results...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table II: Model Comparison\n",
    "model_results_sorted = results_df.sort_values('mean_accuracy', ascending=False).reset_index(drop=True)\n",
    "model_results_sorted['rank'] = range(1, len(model_results_sorted) + 1)\n",
    "model_results_sorted['accuracy_str'] = model_results_sorted.apply(\n",
    "    lambda row: f\"{row['mean_accuracy']*100:.2f} ± {row['std_accuracy']*100:.2f}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Comparison of baseline methods on PhysioNet Motor Imagery dataset}\n",
    "\\label{tab:model_comparison}\n",
    "\\begin{tabular}{clc}\n",
    "\\toprule\n",
    "\\textbf{Rank} & \\textbf{Method} & \\textbf{Accuracy (\\%)} \\\\\\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for _, row in model_results_sorted.iterrows():\n",
    "    if row['rank'] == 1:\n",
    "        latex_table += f\"{row['rank']} & \\\\textbf{{{row['model']}}} & \\\\textbf{{{row['accuracy_str']}}} \\\\\\\\\\n\"\n",
    "    else:\n",
    "        latex_table += f\"{row['rank']} & {row['model']} & {row['accuracy_str']} \\\\\\\\\\n\"\n",
    "\n",
    "latex_table += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "table_path = os.path.join(CONFIG['results_dir'], 'table_ii_model_comparison.tex')\n",
    "with open(table_path, 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(f\"Table II saved to: {table_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table III: Retention Analysis\n",
    "retention_display = retention_df.copy()\n",
    "retention_display['accuracy_str'] = retention_display.apply(\n",
    "    lambda row: f\"{row['mean_accuracy']*100:.2f} ± {row['std_accuracy']*100:.2f}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "latex_retention = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Performance retention with channel selection using Gate Selection method}\n",
    "\\label{tab:retention_analysis}\n",
    "\\begin{tabular}{cc}\n",
    "\\toprule\n",
    "\\textbf{Channels (k)} & \\textbf{Accuracy (\\%)} \\\\\\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for _, row in retention_display.iterrows():\n",
    "    latex_retention += f\"{row['k']} & {row['accuracy_str']} \\\\\\\\\\n\"\n",
    "\n",
    "latex_retention += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "retention_table_path = os.path.join(CONFIG['results_dir'], 'table_iii_retention.tex')\n",
    "with open(retention_table_path, 'w') as f:\n",
    "    f.write(latex_retention)\n",
    "\n",
    "print(f\"Table III saved to: {retention_table_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Model Comparison Bar Chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x_pos = np.arange(len(model_results_sorted))\n",
    "bars = ax.bar(x_pos, model_results_sorted['mean_accuracy'] * 100, \n",
    "              yerr=model_results_sorted['std_accuracy'] * 100,\n",
    "              capsize=5, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "bars[0].set_color('#FF6B6B')\n",
    "bars[0].set_alpha(1.0)\n",
    "\n",
    "ax.set_xlabel('Method', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Comparison of Baseline Methods on PhysioNet Motor Imagery Dataset', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(model_results_sorted['model'], rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "for bar, row in zip(bars, model_results_sorted.itertuples()):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "            f'{row.mean_accuracy*100:.2f}',\n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = os.path.join(CONFIG['figures_dir'], 'figure_model_comparison.pdf')\n",
    "plt.savefig(fig_path, format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(os.path.join(CONFIG['figures_dir'], 'figure_model_comparison.png'), \n",
    "            format='png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "print(f\"Figure 1 saved to: {fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Retention Analysis Curves\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(retention_df['k'], retention_df['mean_accuracy'] * 100,\n",
    "        marker='o', linewidth=2, markersize=8, \n",
    "        label='Adaptive-Gating-EEG-ARNN (Gate Selection)',\n",
    "        color='#4ECDC4')\n",
    "\n",
    "ax.fill_between(retention_df['k'],\n",
    "                (retention_df['mean_accuracy'] - retention_df['std_accuracy']) * 100,\n",
    "                (retention_df['mean_accuracy'] + retention_df['std_accuracy']) * 100,\n",
    "                alpha=0.2, color='#4ECDC4')\n",
    "\n",
    "baseline_acc = model_results_sorted[model_results_sorted['model'] == 'Adaptive-Gating-EEG-ARNN']['mean_accuracy'].values[0]\n",
    "ax.axhline(y=baseline_acc * 100, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Full 64 channels ({baseline_acc*100:.2f}%)', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Number of Channels (k)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Performance Retention with Channel Selection', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.legend(fontsize=10, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "retention_fig_path = os.path.join(CONFIG['figures_dir'], 'figure_retention_curves.pdf')\n",
    "plt.savefig(retention_fig_path, format='pdf', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(os.path.join(CONFIG['figures_dir'], 'figure_retention_curves.png'),\n",
    "            format='png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "print(f\"Figure 2 saved to: {retention_fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for paper\n",
    "summary = {\n",
    "    'winner': {\n",
    "        'model': model_results_sorted.iloc[0]['model'],\n",
    "        'accuracy': float(model_results_sorted.iloc[0]['mean_accuracy']),\n",
    "        'std': float(model_results_sorted.iloc[0]['std_accuracy']),\n",
    "        'accuracy_pct': f\"{model_results_sorted.iloc[0]['mean_accuracy']*100:.2f}\",\n",
    "        'std_pct': f\"{model_results_sorted.iloc[0]['std_accuracy']*100:.2f}\"\n",
    "    },\n",
    "    'all_models': {},\n",
    "    'channel_selection': {},\n",
    "    'retention': {}\n",
    "}\n",
    "\n",
    "for _, row in model_results_sorted.iterrows():\n",
    "    summary['all_models'][row['model']] = {\n",
    "        'rank': int(row['rank']),\n",
    "        'accuracy': float(row['mean_accuracy']),\n",
    "        'std': float(row['std_accuracy']),\n",
    "        'accuracy_pct': f\"{row['mean_accuracy']*100:.2f}\",\n",
    "        'std_pct': f\"{row['std_accuracy']*100:.2f}\"\n",
    "    }\n",
    "\n",
    "# Best channel selection\n",
    "best_cs = cs_df.loc[cs_df['mean_accuracy'].idxmax()]\n",
    "summary['channel_selection']['best_method'] = best_cs['method']\n",
    "summary['channel_selection']['best_k'] = int(best_cs['k'])\n",
    "summary['channel_selection']['best_accuracy'] = f\"{best_cs['mean_accuracy']*100:.2f}\"\n",
    "\n",
    "# Retention analysis\n",
    "baseline_acc = model_results_sorted.iloc[0]['mean_accuracy']\n",
    "target_acc = baseline_acc * 0.9\n",
    "retention_90pct = retention_df[retention_df['mean_accuracy'] >= target_acc]\n",
    "if len(retention_90pct) > 0:\n",
    "    min_k = retention_90pct['k'].min()\n",
    "    summary['retention']['channels_for_90pct_retention'] = int(min_k)\n",
    "\n",
    "summary_path = os.path.join(CONFIG['results_dir'], 'paper_summary.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nPaper Summary:\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(f\"\\nSummary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Verification and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all required files\n",
    "required_files = [\n",
    "    ('results/summary_all_models.csv', 'Model Results'),\n",
    "    ('results/channel_selection_results.csv', 'Channel Selection Results'),\n",
    "    ('results/retention_analysis.csv', 'Retention Analysis'),\n",
    "    ('results/table_ii_model_comparison.tex', 'LaTeX Table II'),\n",
    "    ('results/table_iii_retention.tex', 'LaTeX Table III'),\n",
    "    ('figures/figure_model_comparison.pdf', 'Figure 1 - Model Comparison'),\n",
    "    ('figures/figure_retention_curves.pdf', 'Figure 2 - Retention Curves'),\n",
    "    ('results/paper_summary.json', 'Paper Summary'),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICATION: Output Files\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "all_present = True\n",
    "for filepath, description in required_files:\n",
    "    if os.path.exists(filepath):\n",
    "        file_size = os.path.getsize(filepath)\n",
    "        print(f\"[OK] {description}\")\n",
    "        print(f\"     Path: {filepath}\")\n",
    "        print(f\"     Size: {file_size:,} bytes\\n\")\n",
    "    else:\n",
    "        print(f\"[MISSING] {description}\")\n",
    "        print(f\"          Expected: {filepath}\\n\")\n",
    "        all_present = False\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUCCESS: All outputs generated successfully!\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"WARNING: Some outputs are missing!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key findings\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY FINDINGS FOR PAPER\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "winner = summary['winner']\n",
    "print(f\"1. BEST MODEL: {winner['model']}\")\n",
    "print(f\"   Accuracy: {winner['accuracy_pct']}% ± {winner['std_pct']}%\\n\")\n",
    "\n",
    "print(f\"2. CHANNEL SELECTION:\")\n",
    "print(f\"   Best Method: {summary['channel_selection']['best_method'].upper()}\")\n",
    "print(f\"   Optimal k: {summary['channel_selection']['best_k']}\")\n",
    "print(f\"   Accuracy: {summary['channel_selection']['best_accuracy']}%\\n\")\n",
    "\n",
    "if 'channels_for_90pct_retention' in summary['retention']:\n",
    "    print(f\"3. RETENTION:\")\n",
    "    print(f\"   90% retention achieved with: {summary['retention']['channels_for_90pct_retention']} channels\")\n",
    "    reduction = (1 - summary['retention']['channels_for_90pct_retention']/64) * 100\n",
    "    print(f\"   Channel reduction: {reduction:.1f}%\\n\")\n",
    "\n",
    "print(f\"4. MODEL RANKING:\")\n",
    "for i, row in enumerate(model_results_sorted.itertuples(), 1):\n",
    "    print(f\"   {i}. {row.model}: {row.mean_accuracy*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pipeline completed successfully!\")\n",
    "print(\"All results ready for paper submission!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}