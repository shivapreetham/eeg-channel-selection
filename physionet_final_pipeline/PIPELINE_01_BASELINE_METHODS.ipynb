{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Pipeline 1: Baseline Methods Evaluation\n\nThis notebook trains and evaluates 5 baseline methods on PhysioNet Motor Imagery:\n1. **FBCSP** - Filter Bank Common Spatial Patterns\n2. **CNN-SAE** - CNN with Spatial Attention\n3. **EEGNet** - Compact temporal convolutional network\n4. **ACS-SE-CNN** - Adaptive Channel Selection SE-CNN\n5. **G-CARM** - Graph Channel Active Reasoning Module\n\n**Plus: Retention Analysis**\n- Tests how baseline methods (EEGNet) perform with reduced channels\n- Uses variance-based channel selection (simple baseline)\n- k-values: [10, 15, 20, 25, 30, 35]\n- Provides comparison baseline for Pipeline 2 (adaptive gating)\n\n**Training Configuration:**\n- Epochs: 30 (with early stopping patience=5)\n- Learning rate: 0.002\n- Batch size: 64\n- 3-fold cross-validation\n\n**Expected Runtime:** ~7-8 hours on Kaggle GPU\n- Baseline training: ~3-4 hours\n- Retention analysis: ~3.5 hours (6 k-values Ã— 3 folds)\n\n**Outputs:**\n- `models/baseline_*.pt` - Trained model checkpoints\n- `results/baseline_methods_results.csv` - Complete metrics for all models\n- `results/baseline_methods_summary.csv` - Summary statistics\n- `results/baseline_retention_analysis.csv` - Retention curve data (for comparison with Pipeline 2)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mne\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_path': '/kaggle/input/eeg-preprocessed-data/derived',\n",
    "    'models_dir': './models',\n",
    "    'results_dir': './results',\n",
    "    \n",
    "    'n_folds': 3,\n",
    "    'random_seed': 42,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    'batch_size': 64,\n",
    "    'epochs': 30,\n",
    "    'learning_rate': 0.002,\n",
    "    'weight_decay': 1e-4,\n",
    "    'patience': 5,\n",
    "    'scheduler_patience': 2,\n",
    "    'scheduler_factor': 0.5,\n",
    "    'use_early_stopping': True,\n",
    "    'min_lr': 1e-6,\n",
    "    \n",
    "    # Data parameters\n",
    "    'n_channels': 64,\n",
    "    'n_classes': 2,\n",
    "    'sfreq': 128,\n",
    "    'tmin': 0.0,\n",
    "    'tmax': 4.0,\n",
    "    'n_timepoints': 513,\n",
    "    'mi_runs': [7, 8, 11, 12],\n",
    "    \n",
    "    # FBCSP parameters\n",
    "    'fbcsp_bands': [(4, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28), (28, 32), (32, 36), (36, 40)],\n",
    "    'fbcsp_n_components': 4,\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['models_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['results_dir'], exist_ok=True)\n",
    "\n",
    "np.random.seed(CONFIG['random_seed'])\n",
    "torch.manual_seed(CONFIG['random_seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['random_seed'])\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"Early stopping patience: {CONFIG['patience']}\")\n",
    "\n",
    "# Estimate runtime\n",
    "n_models = 5\n",
    "total_runs = n_models * CONFIG['n_folds']\n",
    "print(f\"\\nEstimated training runs: {total_runs}\")\n",
    "print(f\"Estimated runtime (~12 min/run): {total_runs * 12 / 60:.1f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_physionet_data(data_path):\n",
    "    \"\"\"Load preprocessed PhysioNet data.\"\"\"\n",
    "    data_root = os.path.abspath(data_path)\n",
    "    if not os.path.isdir(data_root):\n",
    "        raise FileNotFoundError(f\"Data path not found: {data_root}\")\n",
    "\n",
    "    tmin = CONFIG['tmin']\n",
    "    tmax = CONFIG['tmax']\n",
    "    mi_runs = CONFIG['mi_runs']\n",
    "    event_id = {'T1': 1, 'T2': 2}\n",
    "    label_map = {1: 0, 2: 1}\n",
    "\n",
    "    preprocessed_dir = os.path.join(data_root, 'preprocessed')\n",
    "    if os.path.isdir(preprocessed_dir):\n",
    "        data_root = preprocessed_dir\n",
    "    \n",
    "    subject_dirs = [d for d in sorted(os.listdir(data_root))\n",
    "                    if os.path.isdir(os.path.join(data_root, d)) and d.upper().startswith('S')]\n",
    "\n",
    "    all_X, all_y, all_subjects = [], [], []\n",
    "    \n",
    "    print(f\"Loading data from {len(subject_dirs)} subjects...\")\n",
    "    \n",
    "    for subject_dir in subject_dirs:\n",
    "        subject_num = int(subject_dir[1:]) if len(subject_dir) > 1 else -1\n",
    "        subject_path = os.path.join(data_root, subject_dir)\n",
    "        \n",
    "        for run_id in mi_runs:\n",
    "            run_file = f\"{subject_dir}R{run_id:02d}_preproc_raw.fif\"\n",
    "            run_path = os.path.join(subject_path, run_file)\n",
    "            \n",
    "            if not os.path.exists(run_path):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                raw = mne.io.read_raw_fif(run_path, preload=True, verbose=False)\n",
    "                picks = mne.pick_types(raw.info, eeg=True, meg=False, stim=False, eog=False)\n",
    "                if len(picks) == 0:\n",
    "                    continue\n",
    "                \n",
    "                events, _ = mne.events_from_annotations(raw, event_id=event_id)\n",
    "                if len(events) == 0:\n",
    "                    continue\n",
    "                \n",
    "                epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                                    baseline=None, preload=True, picks=picks, verbose=False)\n",
    "                \n",
    "                data = epochs.get_data()\n",
    "                labels = np.array([label_map.get(epochs.events[i, 2], -1) for i in range(len(epochs))])\n",
    "                valid = labels >= 0\n",
    "                \n",
    "                if np.any(valid):\n",
    "                    all_X.append(data[valid])\n",
    "                    all_y.append(labels[valid])\n",
    "                    all_subjects.append(np.full(np.sum(valid), subject_num))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    X = np.concatenate(all_X, axis=0)\n",
    "    y = np.concatenate(all_y, axis=0)\n",
    "    subjects = np.concatenate(all_subjects, axis=0)\n",
    "    \n",
    "    print(f\"Loaded {len(X)} trials from {len(np.unique(subjects))} subjects\")\n",
    "    print(f\"Data shape: {X.shape}\")\n",
    "    print(f\"Labels: {np.bincount(y)}\")\n",
    "    \n",
    "    return X, y, subjects\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBCSP\n",
    "class FBCSP:\n",
    "    def __init__(self, freq_bands, n_components=4, sfreq=128):\n",
    "        self.freq_bands = freq_bands\n",
    "        self.n_components = n_components\n",
    "        self.sfreq = sfreq\n",
    "        self.csp_list = []\n",
    "        self.classifier = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        from mne.decoding import CSP\n",
    "        all_features = []\n",
    "        \n",
    "        for low, high in self.freq_bands:\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            csp = CSP(n_components=self.n_components, reg=None, log=True, norm_trace=False)\n",
    "            features = csp.fit_transform(X_filtered, y)\n",
    "            self.csp_list.append(csp)\n",
    "            all_features.append(features)\n",
    "        \n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        self.classifier = LinearDiscriminantAnalysis()\n",
    "        self.classifier.fit(all_features, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        all_features = []\n",
    "        for idx, (low, high) in enumerate(self.freq_bands):\n",
    "            X_filtered = self._bandpass_filter(X, low, high)\n",
    "            features = self.csp_list[idx].transform(X_filtered)\n",
    "            all_features.append(features)\n",
    "        all_features = np.concatenate(all_features, axis=1)\n",
    "        return self.classifier.predict(all_features)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n",
    "    \n",
    "    def _bandpass_filter(self, X, low, high):\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        nyq = self.sfreq / 2\n",
    "        b, a = butter(4, [low / nyq, high / nyq], btype='band')\n",
    "        X_filtered = np.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                X_filtered[i, j, :] = filtfilt(b, a, X[i, j, :])\n",
    "        return X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-SAE\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(n_channels, n_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels // 4, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pooled = torch.mean(x, dim=2)\n",
    "        weights = self.attention(pooled)\n",
    "        return x * weights.unsqueeze(2)\n",
    "\n",
    "\n",
    "class CNNSAE(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        self.spatial_attention = SpatialAttention(n_channels)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.spatial_attention(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEGNet\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513, F1=8, D=2, F2=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        self.conv2 = nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1 * D)\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv3 = nn.Conv2d(F1 * D, F2, (1, 16), padding=(0, 8), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc = nn.Linear(flattened_size, n_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.dropout1(self.pool1(F.elu(self.bn2(self.conv2(x)))))\n",
    "        x = self.dropout2(self.pool2(F.elu(self.bn3(self.conv3(x)))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACS-SE-CNN\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, max(1, channels // reduction))\n",
    "        self.fc2 = nn.Linear(max(1, channels // reduction), channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        squeeze = torch.mean(x, dim=2)\n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation))\n",
    "        return x * excitation.unsqueeze(2)\n",
    "\n",
    "\n",
    "class ACSECNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Linear(n_timepoints, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.se1 = SEBlock(n_channels)\n",
    "        self.se2 = SEBlock(128)\n",
    "        self.se3 = SEBlock(256)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        channel_weights = []\n",
    "        for i in range(x.size(1)):\n",
    "            w = self.channel_attention(x[:, i, :])\n",
    "            channel_weights.append(w)\n",
    "        channel_weights = torch.cat(channel_weights, dim=1)\n",
    "        x = x * channel_weights.unsqueeze(2)\n",
    "        x = self.se1(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.se2(x)\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.se3(x)\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G-CARM\n",
    "class CARMBlock(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        A_norm = torch.softmax(self.A, dim=1)\n",
    "        x_reshaped = x.permute(0, 2, 1)\n",
    "        x_graph = torch.matmul(x_reshaped, A_norm.t())\n",
    "        return x_graph.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "class GCARM(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=513):\n",
    "        super().__init__()\n",
    "        self.carm1 = CARMBlock(n_channels)\n",
    "        self.carm2 = CARMBlock(n_channels)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.carm1(x)\n",
    "        x = self.carm2(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / max(1, len(dataloader)), correct / max(1, total)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / max(1, len(dataloader)), correct / max(1, total)\n",
    "\n",
    "\n",
    "def train_pytorch_model(model, train_loader, val_loader, config, model_name=''):\n",
    "    device = config['device']\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], \n",
    "                          weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=config['scheduler_factor'], \n",
    "        patience=config['scheduler_patience'], min_lr=config['min_lr'], verbose=False\n",
    "    )\n",
    "    \n",
    "    best_state = deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        improved = val_acc > best_val_acc or (val_acc == best_val_acc and val_loss < best_val_loss)\n",
    "        if improved:\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 5 == 0 or improved:\n",
    "            print(f\"[{model_name}] Epoch {epoch+1}/{config['epochs']} - \"\n",
    "                  f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | Best: {best_val_acc:.4f}\")\n",
    "        \n",
    "        if config['use_early_stopping'] and patience_counter >= config['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    return best_state, best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading PhysioNet data...\")\n",
    "X, y, subjects = load_physionet_data(CONFIG['data_path'])\n",
    "print(f\"\\nData ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train All Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models_to_train = [\n",
    "    {'name': 'FBCSP', 'type': 'sklearn'},\n",
    "    {'name': 'CNN-SAE', 'type': 'pytorch'},\n",
    "    {'name': 'EEGNet', 'type': 'pytorch'},\n",
    "    {'name': 'ACS-SE-CNN', 'type': 'pytorch'},\n",
    "    {'name': 'G-CARM', 'type': 'pytorch'},\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_seed'])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING BASELINE METHODS\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for model_info in models_to_train:\n",
    "    model_name = model_info['name']\n",
    "    model_type = model_info['type']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\nFold {fold + 1}/{CONFIG['n_folds']}\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = FBCSP(freq_bands=CONFIG['fbcsp_bands'],\n",
    "                          n_components=CONFIG['fbcsp_n_components'],\n",
    "                          sfreq=CONFIG['sfreq'])\n",
    "            model.fit(X_train, y_train)\n",
    "            val_acc = model.score(X_val, y_val)\n",
    "            \n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"baseline_{model_name}_fold{fold+1}.pkl\")\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        else:\n",
    "            train_dataset = EEGDataset(X_train, y_train)\n",
    "            val_dataset = EEGDataset(X_val, y_val)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "            \n",
    "            base_kwargs = {\n",
    "                'n_channels': CONFIG['n_channels'],\n",
    "                'n_classes': CONFIG['n_classes'],\n",
    "                'n_timepoints': CONFIG['n_timepoints'],\n",
    "            }\n",
    "            \n",
    "            if model_name == 'CNN-SAE':\n",
    "                model = CNNSAE(**base_kwargs)\n",
    "            elif model_name == 'EEGNet':\n",
    "                model = EEGNet(**base_kwargs)\n",
    "            elif model_name == 'ACS-SE-CNN':\n",
    "                model = ACSECNN(**base_kwargs)\n",
    "            elif model_name == 'G-CARM':\n",
    "                model = GCARM(**base_kwargs)\n",
    "            \n",
    "            best_state, val_acc = train_pytorch_model(model, train_loader, val_loader, CONFIG, model_name)\n",
    "            \n",
    "            model_path = os.path.join(CONFIG['models_dir'], f\"baseline_{model_name}_fold{fold+1}.pt\")\n",
    "            torch.save(best_state, model_path)\n",
    "            \n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        fold_results.append({'fold': fold + 1, 'accuracy': val_acc})\n",
    "        print(f\"Fold {fold + 1} Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    fold_accs = [r['accuracy'] for r in fold_results]\n",
    "    mean_acc = np.mean(fold_accs)\n",
    "    std_acc = np.std(fold_accs)\n",
    "    \n",
    "    print(f\"\\n{model_name} Summary:\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f} +/- {std_acc:.4f}\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'model': model_name,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'fold_results': fold_results\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL BASELINE MODELS TRAINED!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Retention Analysis\n",
    "\n",
    "Test how baseline methods perform with reduced channels using variance-based selection.\n",
    "This provides a fair comparison baseline for the adaptive gating approach in Pipeline 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-based channel importance\n",
    "def get_channel_importance_variance(X_train):\n",
    "    \"\"\"Compute channel importance based on temporal variance.\"\"\"\n",
    "    # X_train: (n_trials, n_channels, n_timepoints)\n",
    "    channel_variance = np.var(X_train, axis=(0, 2))  # variance across trials and time\n",
    "    return channel_variance\n",
    "\n",
    "\n",
    "def select_top_k_channels(importance_scores, k):\n",
    "    \"\"\"Select top k channels based on importance scores.\"\"\"\n",
    "    top_k_indices = np.argsort(importance_scores)[-k:]\n",
    "    return sorted(top_k_indices)\n",
    "\n",
    "\n",
    "def apply_channel_selection(X, selected_channels):\n",
    "    \"\"\"Apply channel selection to data.\"\"\"\n",
    "    return X[:, selected_channels, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retention analysis configuration\n",
    "RETENTION_K_VALUES = [10, 15, 20, 25, 30, 35]\n",
    "RETENTION_MODEL = 'EEGNet'  # Use EEGNet as baseline representative\n",
    "\n",
    "print(f\"Running retention analysis for {RETENTION_MODEL} with k-values: {RETENTION_K_VALUES}\")\n",
    "print(f\"Estimated time: {len(RETENTION_K_VALUES) * CONFIG['n_folds'] * 12 / 60:.1f} hours\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run retention analysis\n",
    "retention_results = []\n",
    "\n",
    "for k in RETENTION_K_VALUES:\n",
    "    print(f\"\nTesting with k={k} channels:\", end=' ')\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Compute channel importance on training data\n",
    "        importance_scores = get_channel_importance_variance(X_train)\n",
    "        selected_channels = select_top_k_channels(importance_scores, k)\n",
    "        \n",
    "        # Apply channel selection\n",
    "        X_train_selected = apply_channel_selection(X_train, selected_channels)\n",
    "        X_val_selected = apply_channel_selection(X_val, selected_channels)\n",
    "        \n",
    "        # Train model with selected channels\n",
    "        train_dataset = EEGDataset(X_train_selected, y_train)\n",
    "        val_dataset = EEGDataset(X_val_selected, y_val)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "        \n",
    "        # Modify config for reduced channels\n",
    "        temp_config = CONFIG.copy()\n",
    "        temp_config['n_channels'] = k\n",
    "        \n",
    "        model = EEGNet(n_channels=k, n_classes=CONFIG['n_classes'], n_timepoints=CONFIG['n_timepoints'])\n",
    "        best_state, val_acc = train_pytorch_model(model, train_loader, val_loader, temp_config, f\"Retention-k{k}\")\n",
    "        \n",
    "        fold_accuracies.append(val_acc)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "    print(f\"{mean_acc:.4f} +/- {std_acc:.4f}\")\n",
    "    \n",
    "    retention_results.append({\n",
    "        'model': RETENTION_MODEL,\n",
    "        'k': k,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'fold_accuracies': fold_accuracies\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save retention results\n",
    "retention_df = pd.DataFrame(retention_results)\n",
    "retention_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_retention_analysis.csv'), index=False)\n",
    "\n",
    "print(\"\nRetention Analysis Results:\")\n",
    "print(retention_df[['k', 'mean_accuracy', 'std_accuracy']])\n",
    "\n",
    "print(\"\nResults saved to: results/baseline_retention_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare detailed results\n",
    "detailed_results = []\n",
    "for result in all_results:\n",
    "    for fold_result in result['fold_results']:\n",
    "        detailed_results.append({\n",
    "            'model': result['model'],\n",
    "            'fold': fold_result['fold'],\n",
    "            'accuracy': fold_result['accuracy']\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_results)\n",
    "detailed_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_methods_results.csv'), index=False)\n",
    "\n",
    "# Prepare summary\n",
    "summary_df = pd.DataFrame(all_results)[['model', 'mean_accuracy', 'std_accuracy']]\n",
    "summary_df = summary_df.sort_values('mean_accuracy', ascending=False).reset_index(drop=True)\n",
    "summary_df['rank'] = range(1, len(summary_df) + 1)\n",
    "summary_df = summary_df[['rank', 'model', 'mean_accuracy', 'std_accuracy']]\n",
    "summary_df.to_csv(os.path.join(CONFIG['results_dir'], 'baseline_methods_summary.csv'), index=False)\n",
    "\n",
    "print(\"\\nResults saved to:\")\n",
    "print(\"  - results/baseline_methods_results.csv\")\n",
    "print(\"  - results/baseline_methods_summary.csv\")\n",
    "\n",
    "print(\"\\nBaseline Methods Summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PIPELINE 1 COMPLETE!\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}