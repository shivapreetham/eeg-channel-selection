{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhysioNet EEG-ARNN Training Pipeline\n",
    "\n",
    "This notebook implements the complete training pipeline with:\n",
    "- Subject-specific 3-fold cross-validation\n",
    "- Edge Selection (ES) and Aggregation Selection (AS)\n",
    "- Experiments with different k values (10, 15, 20, 25)\n",
    "- Comprehensive results and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION: Checking if train_utils.py fix is loaded...\n",
      "================================================================================\n",
      "✓ GOOD: train_utils.py has the annotations fix!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mne\n",
    "\n",
    "# IMPORTANT: Force reload train_utils to get latest fixes\n",
    "import importlib\n",
    "import train_utils\n",
    "importlib.reload(train_utils)\n",
    "\n",
    "from models import EEGARNN, ChannelSelector\n",
    "from train_utils import (\n",
    "    load_preprocessed_data, filter_classes, normalize_data,\n",
    "    cross_validate_subject, EEGDataset\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('ERROR')\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Verify the fix is loaded\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION: Checking if train_utils.py fix is loaded...\")\n",
    "print(\"=\"*80)\n",
    "import inspect\n",
    "source = inspect.getsource(load_preprocessed_data)\n",
    "if 'events_from_annotations' in source:\n",
    "    print(\"✓ GOOD: train_utils.py has the annotations fix!\")\n",
    "else:\n",
    "    print(\"✗ ERROR: train_utils.py is still using old code!\")\n",
    "    print(\"  → Please restart Jupyter kernel: Kernel → Restart Kernel\")\n",
    "    print(\"  → Then re-run all cells from the top\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Configuration:\n",
      "{\n",
      "  \"data\": {\n",
      "    \"preprocessed_dir\": \"data\\\\physionet\\\\derived\\\\preprocessed\",\n",
      "    \"index_file\": \"data\\\\physionet\\\\derived\\\\physionet_preprocessed_index.csv\",\n",
      "    \"selected_classes\": [\n",
      "      1,\n",
      "      2\n",
      "    ],\n",
      "    \"tmin\": -1.0,\n",
      "    \"tmax\": 5.0,\n",
      "    \"baseline\": [\n",
      "      -0.5,\n",
      "      0\n",
      "    ]\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"hidden_dim\": 40,\n",
      "    \"epochs\": 10,\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"batch_size\": 32,\n",
      "    \"n_folds\": 2,\n",
      "    \"patience\": 8\n",
      "  },\n",
      "  \"gating\": {\n",
      "    \"enabled\": true,\n",
      "    \"l1_lambda\": 0.001,\n",
      "    \"gate_init\": 0.9\n",
      "  },\n",
      "  \"channel_selection\": {\n",
      "    \"k_values\": [\n",
      "      10,\n",
      "      15,\n",
      "      20,\n",
      "      25,\n",
      "      \"all\"\n",
      "    ],\n",
      "    \"methods\": [\n",
      "      \"ES\",\n",
      "      \"AS\"\n",
      "    ]\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"results_dir\": \"results\",\n",
      "    \"models_dir\": \"saved_models\",\n",
      "    \"gated_results_file\": \"trial4_gated_subject_results.csv\",\n",
      "    \"gate_importance_file\": \"trial4_gate_importances.csv\",\n",
      "    \"channel_selection_results_file\": \"trial4_channel_selection_results.csv\",\n",
      "    \"retrain_results_file\": \"trial4_retrain_results.csv\",\n",
      "    \"baseline_results_file\": \"subject_results.csv\",\n",
      "    \"comparison_file\": \"trial4_gated_vs_baseline.csv\",\n",
      "    \"results_summary_figure\": \"trial4_gated_results_summary.png\",\n",
      "    \"adjacency_prefix\": \"trial4_adjacency\"\n",
      "  },\n",
      "  \"max_subjects\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_CONFIG = {\n",
    "    'data': {\n",
    "        'preprocessed_dir': Path('data/physionet/derived/preprocessed'),\n",
    "        'index_file': Path('data/physionet/derived/physionet_preprocessed_index.csv'),\n",
    "        'selected_classes': [1, 2],  # T1, T2 (or [1, 2, 3, 4] for 4-class)\n",
    "        'tmin': -1.0,\n",
    "        'tmax': 5.0,\n",
    "        'baseline': (-0.5, 0)\n",
    "    },\n",
    "    'model': {\n",
    "        'hidden_dim': 40,\n",
    "        'epochs': 10,  # Reduced from 100 to 50\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32,\n",
    "        'n_folds': 2,\n",
    "        'patience': 8\n",
    "    },\n",
    "    'gating': {\n",
    "        'enabled': True,\n",
    "        'l1_lambda': 1e-3,\n",
    "        'gate_init': 0.9\n",
    "    },\n",
    "    'channel_selection': {\n",
    "        'k_values': [10, 15, 20, 25, 'all'],  # Different k to test\n",
    "        'methods': ['ES', 'AS']  # Edge Selection, Aggregation Selection\n",
    "    },\n",
    "    'output': {\n",
    "        'results_dir': Path('results'),\n",
    "        'models_dir': Path('saved_models'),\n",
    "        'gated_results_file': 'trial4_gated_subject_results.csv',\n",
    "        'gate_importance_file': 'trial4_gate_importances.csv',\n",
    "        'channel_selection_results_file': 'trial4_channel_selection_results.csv',\n",
    "        'retrain_results_file': 'trial4_retrain_results.csv',\n",
    "        'baseline_results_file': 'subject_results.csv',\n",
    "        'comparison_file': 'trial4_gated_vs_baseline.csv',\n",
    "        'results_summary_figure': 'trial4_gated_results_summary.png',\n",
    "        'adjacency_prefix': 'trial4_adjacency'\n",
    "    },\n",
    "    'max_subjects': 5  # Train on only 5 subjects\n",
    "}\n",
    "\n",
    "EXPERIMENT_CONFIG['output']['results_dir'].mkdir(exist_ok=True)\n",
    "EXPERIMENT_CONFIG['output']['models_dir'].mkdir(exist_ok=True)\n",
    "\n",
    "print('Experiment Configuration:')\n",
    "print(json.dumps(EXPERIMENT_CONFIG, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a2240",
   "metadata": {},
   "source": [
    "## Gated Model Utilities\n",
    "\n",
    "Learnable channel gates with L1 sparsity regularization for trial 4 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fadc7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utilities for models with learnable channel gates\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def _init_gate_logits(num_channels: int, gate_init: float) -> torch.Tensor:\n",
    "    init = torch.full((num_channels,), float(gate_init), dtype=torch.float32)\n",
    "    init = torch.clamp(init, 1e-4, 1 - 1e-4)\n",
    "    return torch.logit(init)\n",
    "\n",
    "\n",
    "class GatedEEGARNN(EEGARNN):\n",
    "    '''EEG-ARNN variant with learnable channel gates.'''\n",
    "    def __init__(self, num_channels=64, num_timepoints=512, num_classes=4, hidden_dim=40, gate_init=0.9):\n",
    "        super().__init__(\n",
    "            num_channels=num_channels,\n",
    "            num_timepoints=num_timepoints,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dim=hidden_dim\n",
    "        )\n",
    "        gate_logits = _init_gate_logits(num_channels, gate_init)\n",
    "        self.gate_logits = nn.Parameter(gate_logits)\n",
    "        self.latest_gates = None\n",
    "\n",
    "    def get_gate_values(self):\n",
    "        return torch.sigmoid(self.gate_logits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_values = torch.sigmoid(self.gate_logits)\n",
    "        self.latest_gates = gate_values.detach().cpu()\n",
    "        x = x * gate_values.view(1, 1, -1, 1)\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "def train_epoch_with_gates(model, dataloader, criterion, optimizer, device, l1_lambda=0.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    gate_penalties, gate_means = [], []\n",
    "\n",
    "    for data, labels in dataloader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if l1_lambda > 0 and hasattr(model, 'get_gate_values'):\n",
    "            gate_values = model.get_gate_values()\n",
    "            gate_penalty = l1_lambda * gate_values.abs().mean()\n",
    "            loss = loss + gate_penalty\n",
    "            gate_penalties.append(gate_penalty.item())\n",
    "            gate_means.append(gate_values.mean().item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / max(len(dataloader), 1)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_penalty = float(np.mean(gate_penalties)) if gate_penalties else 0.0\n",
    "    avg_gate_mean = float(np.mean(gate_means)) if gate_means else 0.0\n",
    "\n",
    "    return avg_loss, accuracy, avg_penalty, avg_gate_mean\n",
    "\n",
    "\n",
    "def train_model_with_gates(model, train_loader, val_loader, device, epochs=100, lr=0.001,\n",
    "                           patience=10, l1_lambda=0.0):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=False\n",
    "    )\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'gate_penalty': [],\n",
    "        'gate_mean': []\n",
    "    }\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = deepcopy(model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc, gate_penalty, gate_mean = train_epoch_with_gates(\n",
    "            model, train_loader, criterion, optimizer, device, l1_lambda=l1_lambda\n",
    "        )\n",
    "        val_loss, val_acc, _, _ = train_utils.evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['gate_penalty'].append(gate_penalty)\n",
    "        history['gate_mean'].append(gate_mean)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"    Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return history, best_model_state\n",
    "\n",
    "\n",
    "def cross_validate_subject_with_gates(\n",
    "    data, labels, num_channels, num_timepoints, num_classes,\n",
    "    device, n_splits=3, epochs=30, lr=0.001, batch_size=64, patience=8,\n",
    "    l1_lambda=0.0, gate_init=0.9\n",
    "):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_results = []\n",
    "    adjacency_matrices = []\n",
    "    gate_values_per_fold = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(data, labels)):\n",
    "        print(f\"  Fold {fold + 1}/{n_splits}\", end=\" \", flush=True)\n",
    "\n",
    "        X_train, X_val = data[train_idx], data[val_idx]\n",
    "        y_train, y_val = labels[train_idx], labels[val_idx]\n",
    "\n",
    "        X_train = train_utils.normalize_data(X_train)\n",
    "        X_val = train_utils.normalize_data(X_val)\n",
    "\n",
    "        train_dataset = train_utils.EEGDataset(X_train, y_train)\n",
    "        val_dataset = train_utils.EEGDataset(X_val, y_val)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        model = GatedEEGARNN(\n",
    "            num_channels=num_channels,\n",
    "            num_timepoints=num_timepoints,\n",
    "            num_classes=num_classes,\n",
    "            hidden_dim=EXPERIMENT_CONFIG['model']['hidden_dim'],\n",
    "            gate_init=gate_init\n",
    "        ).to(device)\n",
    "\n",
    "        history, best_state = train_model_with_gates(\n",
    "            model, train_loader, val_loader, device,\n",
    "            epochs=epochs, lr=lr, patience=patience, l1_lambda=l1_lambda\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "        _, val_acc, val_preds, val_labels = train_utils.evaluate(\n",
    "            model, val_loader, nn.CrossEntropyLoss(), device\n",
    "        )\n",
    "\n",
    "        adj_matrix = model.get_final_adjacency_matrix()\n",
    "        adjacency_matrices.append(adj_matrix)\n",
    "\n",
    "        gate_values = model.get_gate_values().detach().cpu().numpy()\n",
    "        gate_values_per_fold.append(gate_values)\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'val_acc': val_acc,\n",
    "            'history': history,\n",
    "            'gate_mean': float(gate_values.mean()),\n",
    "            'gate_std': float(gate_values.std()),\n",
    "            'preds': val_preds,\n",
    "            'labels': val_labels\n",
    "        })\n",
    "\n",
    "        print(f\"-> Acc: {val_acc:.3f}\")\n",
    "\n",
    "    avg_adjacency = np.mean(adjacency_matrices, axis=0)\n",
    "    avg_gate_values = np.mean(np.stack(gate_values_per_fold, axis=0), axis=0)\n",
    "\n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'avg_accuracy': np.mean([r['val_acc'] for r in fold_results]),\n",
    "        'std_accuracy': np.std([r['val_acc'] for r in fold_results]),\n",
    "        'adjacency_matrix': avg_adjacency,\n",
    "        'gate_values_per_fold': gate_values_per_fold,\n",
    "        'avg_gate_values': avg_gate_values\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total preprocessed runs: 669\n",
      "Successful runs: 669\n",
      "\n",
      "Subjects available: 51\n",
      "\n",
      "Runs per category:\n",
      "category\n",
      "motor_execution    292\n",
      "motor_imagery      295\n",
      "resting_state       82\n",
      "Name: run, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>run</th>\n",
       "      <th>status</th>\n",
       "      <th>path</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>original_sfreq</th>\n",
       "      <th>n_channels_original</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>bad_channels</th>\n",
       "      <th>n_bad_channels</th>\n",
       "      <th>notch_applied</th>\n",
       "      <th>final_sfreq</th>\n",
       "      <th>n_channels_final</th>\n",
       "      <th>file_size_mb</th>\n",
       "      <th>category</th>\n",
       "      <th>task</th>\n",
       "      <th>bad_channels_interpolated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S001</td>\n",
       "      <td>R01</td>\n",
       "      <td>success</td>\n",
       "      <td>data\\physionet\\derived\\preprocessed\\S001\\S001R...</td>\n",
       "      <td>2025-10-23T17:52:38.863386</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64</td>\n",
       "      <td>60.99375</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>1.917076</td>\n",
       "      <td>resting_state</td>\n",
       "      <td>Baseline eyes open</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S001</td>\n",
       "      <td>R02</td>\n",
       "      <td>success</td>\n",
       "      <td>data\\physionet\\derived\\preprocessed\\S001\\S001R...</td>\n",
       "      <td>2025-10-23T17:52:39.482853</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64</td>\n",
       "      <td>60.99375</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>1.917076</td>\n",
       "      <td>resting_state</td>\n",
       "      <td>Baseline eyes closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S001</td>\n",
       "      <td>R04</td>\n",
       "      <td>success</td>\n",
       "      <td>data\\physionet\\derived\\preprocessed\\S001\\S001R...</td>\n",
       "      <td>2025-10-23T17:52:39.869856</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64</td>\n",
       "      <td>124.99375</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>3.918468</td>\n",
       "      <td>motor_execution</td>\n",
       "      <td>Open/close right fist (executed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S001</td>\n",
       "      <td>R05</td>\n",
       "      <td>success</td>\n",
       "      <td>data\\physionet\\derived\\preprocessed\\S001\\S001R...</td>\n",
       "      <td>2025-10-23T17:52:40.658595</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64</td>\n",
       "      <td>124.99375</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>3.918468</td>\n",
       "      <td>motor_execution</td>\n",
       "      <td>Open/close both fists (executed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S001</td>\n",
       "      <td>R06</td>\n",
       "      <td>success</td>\n",
       "      <td>data\\physionet\\derived\\preprocessed\\S001\\S001R...</td>\n",
       "      <td>2025-10-23T17:52:41.551311</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64</td>\n",
       "      <td>124.99375</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[50.0]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>3.918468</td>\n",
       "      <td>motor_execution</td>\n",
       "      <td>Open/close both feet (executed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  run   status                                               path  \\\n",
       "0    S001  R01  success  data\\physionet\\derived\\preprocessed\\S001\\S001R...   \n",
       "1    S001  R02  success  data\\physionet\\derived\\preprocessed\\S001\\S001R...   \n",
       "2    S001  R04  success  data\\physionet\\derived\\preprocessed\\S001\\S001R...   \n",
       "3    S001  R05  success  data\\physionet\\derived\\preprocessed\\S001\\S001R...   \n",
       "4    S001  R06  success  data\\physionet\\derived\\preprocessed\\S001\\S001R...   \n",
       "\n",
       "                    timestamp  original_sfreq  n_channels_original  \\\n",
       "0  2025-10-23T17:52:38.863386           160.0                   64   \n",
       "1  2025-10-23T17:52:39.482853           160.0                   64   \n",
       "2  2025-10-23T17:52:39.869856           160.0                   64   \n",
       "3  2025-10-23T17:52:40.658595           160.0                   64   \n",
       "4  2025-10-23T17:52:41.551311           160.0                   64   \n",
       "\n",
       "   duration_s bad_channels  n_bad_channels notch_applied  final_sfreq  \\\n",
       "0    60.99375           []               0        [50.0]        128.0   \n",
       "1    60.99375           []               0        [50.0]        128.0   \n",
       "2   124.99375           []               0        [50.0]        128.0   \n",
       "3   124.99375           []               0        [50.0]        128.0   \n",
       "4   124.99375           []               0        [50.0]        128.0   \n",
       "\n",
       "   n_channels_final  file_size_mb         category  \\\n",
       "0                64      1.917076    resting_state   \n",
       "1                64      1.917076    resting_state   \n",
       "2                64      3.918468  motor_execution   \n",
       "3                64      3.918468  motor_execution   \n",
       "4                64      3.918468  motor_execution   \n",
       "\n",
       "                               task bad_channels_interpolated  \n",
       "0                Baseline eyes open                       NaN  \n",
       "1              Baseline eyes closed                       NaN  \n",
       "2  Open/close right fist (executed)                       NaN  \n",
       "3  Open/close both fists (executed)                       NaN  \n",
       "4   Open/close both feet (executed)                       NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df = pd.read_csv(EXPERIMENT_CONFIG['data']['index_file'])\n",
    "success_df = index_df[index_df['status'] == 'success'].copy()\n",
    "\n",
    "print(f\"Total preprocessed runs: {len(index_df)}\")\n",
    "print(f\"Successful runs: {len(success_df)}\")\n",
    "print(f\"\\nSubjects available: {success_df['subject'].nunique()}\")\n",
    "print(f\"\\nRuns per category:\")\n",
    "print(success_df.groupby('category')['run'].count())\n",
    "\n",
    "success_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Selection\n",
    "\n",
    "Select subjects for training. For motor imagery, we focus on motor execution and motor imagery runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects with >=10 motor runs: 49\n",
      "\n",
      "First 10 subjects: ['S001', 'S002', 'S005', 'S006', 'S007', 'S008', 'S011', 'S014', 'S015', 'S016']\n",
      "\n",
      "Will train on 5 subjects\n",
      "Selected subjects: ['S001', 'S002', 'S005', 'S006', 'S007']\n"
     ]
    }
   ],
   "source": [
    "# Filter motor-related runs (execution and imagery)\n",
    "motor_runs = success_df[success_df['category'].isin(['motor_execution', 'motor_imagery'])].copy()\n",
    "\n",
    "# Count runs per subject\n",
    "subject_counts = motor_runs.groupby('subject').size().reset_index(name='num_runs')\n",
    "subject_counts = subject_counts[subject_counts['num_runs'] >= 10]  # At least 10 runs\n",
    "\n",
    "selected_subjects = subject_counts['subject'].tolist()\n",
    "\n",
    "print(f\"Subjects with >=10 motor runs: {len(selected_subjects)}\")\n",
    "print(f\"\\nFirst 10 subjects: {selected_subjects[:10]}\")\n",
    "\n",
    "# Limit to max_subjects for this experiment\n",
    "max_subjects = EXPERIMENT_CONFIG.get('max_subjects', len(selected_subjects))\n",
    "selected_subjects = selected_subjects[:max_subjects]\n",
    "\n",
    "print(f\"\\nWill train on {len(selected_subjects)} subjects\")\n",
    "print(f\"Selected subjects: {selected_subjects}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_data(subject_id, preprocessed_dir, motor_runs_df, config):\n",
    "    \"\"\"\n",
    "    Load all motor runs for a subject and concatenate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray or None\n",
    "        (n_trials, n_channels, n_timepoints)\n",
    "    labels : np.ndarray or None\n",
    "        (n_trials,)\n",
    "    channel_names : list\n",
    "        List of channel names\n",
    "    \"\"\"\n",
    "    subject_runs = motor_runs_df[motor_runs_df['subject'] == subject_id]\n",
    "    \n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    channel_names = None\n",
    "    \n",
    "    for _, run_info in subject_runs.iterrows():\n",
    "        fif_path = Path(run_info['path'])\n",
    "        \n",
    "        if not fif_path.exists():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            data, labels = load_preprocessed_data(\n",
    "                fif_path,\n",
    "                tmin=config['data']['tmin'],\n",
    "                tmax=config['data']['tmax'],\n",
    "                baseline=config['data']['baseline']\n",
    "            )\n",
    "            \n",
    "            if data is not None and len(data) > 0:\n",
    "                all_data.append(data)\n",
    "                all_labels.append(labels)\n",
    "                \n",
    "                if channel_names is None:\n",
    "                    raw = mne.io.read_raw_fif(fif_path, preload=False, verbose='ERROR')\n",
    "                    channel_names = raw.ch_names\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {fif_path.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(all_data) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    all_data = np.concatenate(all_data, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    # Filter to selected classes\n",
    "    all_data, all_labels = filter_classes(\n",
    "        all_data, all_labels, config['data']['selected_classes']\n",
    "    )\n",
    "    \n",
    "    return all_data, all_labels, channel_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "Train subject-specific models with 3-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training subjects (gated):   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training subject: S001\n",
      "================================================================================\n",
      "Data shape: (231, 64, 769)\n",
      "Labels: (array([0, 1]), array([154,  77], dtype=int64))\n",
      "Channels: 64\n",
      "  Fold 1/2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training subjects (gated):   0%|          | 0/5 [01:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m model_cfg = EXPERIMENT_CONFIG[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     29\u001b[39m gating_cfg = EXPERIMENT_CONFIG.get(\u001b[33m'\u001b[39m\u001b[33mgating\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m cv_results = \u001b[43mcross_validate_subject_with_gates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_timepoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_timepoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_folds\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpatience\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml1_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgating_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ml1_lambda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgate_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgating_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgate_init\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m gate_values = cv_results[\u001b[33m'\u001b[39m\u001b[33mavg_gate_values\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     47\u001b[39m gate_stats = {\n\u001b[32m     48\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(gate_values.mean()),\n\u001b[32m     49\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(gate_values.std()),\n\u001b[32m     50\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(gate_values.min()),\n\u001b[32m     51\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(gate_values.max())\n\u001b[32m     52\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 156\u001b[39m, in \u001b[36mcross_validate_subject_with_gates\u001b[39m\u001b[34m(data, labels, num_channels, num_timepoints, num_classes, device, n_splits, epochs, lr, batch_size, patience, l1_lambda, gate_init)\u001b[39m\n\u001b[32m    146\u001b[39m val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m0\u001b[39m)\n\u001b[32m    148\u001b[39m model = GatedEEGARNN(\n\u001b[32m    149\u001b[39m     num_channels=num_channels,\n\u001b[32m    150\u001b[39m     num_timepoints=num_timepoints,\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m     gate_init=gate_init\n\u001b[32m    154\u001b[39m ).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m history, best_state = \u001b[43mtrain_model_with_gates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml1_lambda\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m model.load_state_dict(best_state)\n\u001b[32m    162\u001b[39m _, val_acc, val_preds, val_labels = train_utils.evaluate(\n\u001b[32m    163\u001b[39m     model, val_loader, nn.CrossEntropyLoss(), device\n\u001b[32m    164\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mtrain_model_with_gates\u001b[39m\u001b[34m(model, train_loader, val_loader, device, epochs, lr, patience, l1_lambda)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     94\u001b[39m     train_loss, train_acc, gate_penalty, gate_mean = train_epoch_with_gates(\n\u001b[32m     95\u001b[39m         model, train_loader, criterion, optimizer, device, l1_lambda=l1_lambda\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     val_loss, val_acc, _, _ = \u001b[43mtrain_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m    100\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_acc\u001b[39m\u001b[33m'\u001b[39m].append(train_acc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\eeg-channel-selection\\train_utils.py:176\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, dataloader, criterion, device)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[32m    174\u001b[39m     data, labels = data.to(device), labels.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m    179\u001b[39m     total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mGatedEEGARNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m.latest_gates = gate_values.detach().cpu()\n\u001b[32m     32\u001b[39m x = x * gate_values.view(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\eeg-channel-selection\\models.py:183\u001b[39m, in \u001b[36mEEGARNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m    187\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.fc1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\eeg-channel-selection\\models.py:170\u001b[39m, in \u001b[36mEEGARNN._forward_features\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    169\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.tfem1(x)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     x, A1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcarm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.tfem2(x)\n\u001b[32m    173\u001b[39m     x, A2 = \u001b[38;5;28mself\u001b[39m.carm2(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\eeg-channel-selection\\models.py:107\u001b[39m, in \u001b[36mCARM.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    104\u001b[39m x_reshaped = x.permute(\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# (batch, time, channels, features)\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Reshape to (batch * time, num_channels, hidden_dim)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m x_flat = \u001b[43mx_reshaped\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.view(batch_size * time_steps, num_channels, hidden_dim)\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Graph aggregation: (num_channels, num_channels) @ (batch*time, num_channels, hidden_dim)\u001b[39;00m\n\u001b[32m    110\u001b[39m x_graph = torch.matmul(A_norm, x_flat)  \u001b[38;5;66;03m# (batch*time, num_channels, hidden_dim)\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "all_results = []\n",
    "gate_analysis_records = []\n",
    "\n",
    "for subject_id in tqdm(selected_subjects, desc=\"Training subjects (gated)\"):\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training subject: {subject_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data, labels, channel_names = load_subject_data(\n",
    "        subject_id,\n",
    "        EXPERIMENT_CONFIG['data']['preprocessed_dir'],\n",
    "        motor_runs,\n",
    "        EXPERIMENT_CONFIG\n",
    "    )\n",
    "\n",
    "    if data is None or len(data) < 30:\n",
    "        print(f\"Skipping {subject_id}: insufficient data\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(f\"Labels: {np.unique(labels, return_counts=True)}\")\n",
    "    print(f\"Channels: {len(channel_names)}\")\n",
    "\n",
    "    num_channels = data.shape[1]\n",
    "    num_timepoints = data.shape[2]\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    model_cfg = EXPERIMENT_CONFIG['model']\n",
    "    gating_cfg = EXPERIMENT_CONFIG.get('gating', {})\n",
    "\n",
    "    cv_results = cross_validate_subject_with_gates(\n",
    "        data, labels,\n",
    "        num_channels=num_channels,\n",
    "        num_timepoints=num_timepoints,\n",
    "        num_classes=num_classes,\n",
    "        device=device,\n",
    "        n_splits=model_cfg['n_folds'],\n",
    "        epochs=model_cfg['epochs'],\n",
    "        lr=model_cfg['learning_rate'],\n",
    "        batch_size=model_cfg['batch_size'],\n",
    "        patience=model_cfg.get('patience', 8),\n",
    "        l1_lambda=gating_cfg.get('l1_lambda', 0.0),\n",
    "        gate_init=gating_cfg.get('gate_init', 0.9)\n",
    "    )\n",
    "\n",
    "    gate_values = cv_results['avg_gate_values']\n",
    "    gate_stats = {\n",
    "        'mean': float(gate_values.mean()),\n",
    "        'std': float(gate_values.std()),\n",
    "        'min': float(gate_values.min()),\n",
    "        'max': float(gate_values.max())\n",
    "    }\n",
    "\n",
    "    print(f\"Gated accuracy: {cv_results['avg_accuracy']:.4f} +/- {cv_results['std_accuracy']:.4f}\")\n",
    "    print(f\"Gate mean: {gate_stats['mean']:.4f} | min: {gate_stats['min']:.4f} | max: {gate_stats['max']:.4f}\")\n",
    "\n",
    "    result = {\n",
    "        'subject': subject_id,\n",
    "        'num_trials': int(len(data)),\n",
    "        'num_channels': int(num_channels),\n",
    "        'num_timepoints': int(num_timepoints),\n",
    "        'num_classes': int(num_classes),\n",
    "        'gated_acc': float(cv_results['avg_accuracy']),\n",
    "        'gated_std': float(cv_results['std_accuracy']),\n",
    "        'adjacency_matrix': cv_results['adjacency_matrix'],\n",
    "        'channel_names': channel_names,\n",
    "        'gate_values': gate_values.tolist(),\n",
    "        'gate_values_per_fold': [gv.tolist() for gv in cv_results['gate_values_per_fold']],\n",
    "        'gate_mean': gate_stats['mean'],\n",
    "        'gate_std': gate_stats['std'],\n",
    "        'gate_min': gate_stats['min'],\n",
    "        'gate_max': gate_stats['max'],\n",
    "        'fold_results': cv_results['fold_results']\n",
    "    }\n",
    "\n",
    "    all_results.append(result)\n",
    "\n",
    "    for channel_name, gate_value in zip(channel_names, gate_values):\n",
    "        gate_analysis_records.append({\n",
    "            'subject': subject_id,\n",
    "            'channel': channel_name,\n",
    "            'gate_value': float(gate_value)\n",
    "        })\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Training complete for {len(all_results)} subjects\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802a342",
   "metadata": {},
   "source": [
    "## Channel Gate Analysis\n",
    "\n",
    "Aggregate the learned gate strengths across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8af767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gate_importance_df = pd.DataFrame(gate_analysis_records)\n",
    "\n",
    "if len(gate_importance_df) > 0:\n",
    "    subject_gate_summary = gate_importance_df.groupby('subject')['gate_value'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "    print('Per-subject gate statistics:')\n",
    "    display(subject_gate_summary)\n",
    "\n",
    "    channel_gate_summary = (\n",
    "        gate_importance_df.groupby('channel')['gate_value']\n",
    "        .agg(['mean', 'std'])\n",
    "        .sort_values('mean', ascending=False)\n",
    "    )\n",
    "    print('Top channels by mean gate value:')\n",
    "    display(channel_gate_summary.head(15))\n",
    "\n",
    "    gate_importance_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['gate_importance_file']\n",
    "    channel_gate_summary.reset_index().to_csv(gate_importance_path, index=False)\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Gate importance saved to: {gate_importance_path}\")\n",
    "\n",
    "    channel_gate_summary_df = channel_gate_summary.reset_index()\n",
    "else:\n",
    "    print('No gate values recorded. Ensure training ran successfully.')\n",
    "    channel_gate_summary_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Selection Experiments\n",
    "\n",
    "Test different k values with Edge Selection and Aggregation Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_selection_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    for result in tqdm(all_results, desc=\"Channel selection experiments\"):\n",
    "        subject_id = result['subject']\n",
    "        adj_matrix = result['adjacency_matrix']\n",
    "        channel_names = result['channel_names']\n",
    "        \n",
    "        print(f\"\\nProcessing channel selection for {subject_id}\")\n",
    "        \n",
    "        selector = ChannelSelector(adj_matrix, channel_names)\n",
    "        \n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            print(f\"  Method: {method}\")\n",
    "            \n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    k_val = result['num_channels']\n",
    "                    selected_channels = channel_names\n",
    "                else:\n",
    "                    k_val = min(k, result['num_channels'])  # Don't exceed available channels\n",
    "                    \n",
    "                    if method == 'ES':\n",
    "                        selected_channels, _ = selector.edge_selection(k_val)\n",
    "                    else:  # AS\n",
    "                        selected_channels, _ = selector.aggregation_selection(k_val)\n",
    "                \n",
    "                print(f\"    k={k_val}: {len(selected_channels)} channels selected\")\n",
    "                \n",
    "                channel_selection_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy_full': result['gated_acc']\n",
    "                })\n",
    "\n",
    "    channel_selection_df = pd.DataFrame(channel_selection_results)\n",
    "    print(f\"\\nChannel selection results: {len(channel_selection_df)} experiments\")\n",
    "    display(channel_selection_df.head(10))\n",
    "else:\n",
    "    channel_selection_df = pd.DataFrame()\n",
    "    print(\"\\nNo results available for channel selection experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from train_utils import retrain_with_selected_channels\n",
    "\n",
    "# Store all retraining results\n",
    "retrain_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    subject_data_cache = {}\n",
    "\n",
    "    for result in all_results:\n",
    "        subject_id = result['subject']\n",
    "        print(f\"Loading data for {subject_id}\")\n",
    "\n",
    "        data, labels, channel_names = load_subject_data(\n",
    "            subject_id,\n",
    "            EXPERIMENT_CONFIG['data']['preprocessed_dir'],\n",
    "            motor_runs,\n",
    "            EXPERIMENT_CONFIG\n",
    "        )\n",
    "\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        subject_data_cache[subject_id] = {\n",
    "            'data': data,\n",
    "            'labels': labels,\n",
    "            'channel_names': channel_names\n",
    "        }\n",
    "\n",
    "    print(f\"{'='*80}\")\n",
    "    print('RETRAINING WITH SELECTED CHANNELS')\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    for result in tqdm(all_results, desc='Retraining subjects'):\n",
    "        subject_id = result['subject']\n",
    "\n",
    "        if subject_id not in subject_data_cache:\n",
    "            continue\n",
    "\n",
    "        cache = subject_data_cache[subject_id]\n",
    "        data = cache['data']\n",
    "        labels = cache['labels']\n",
    "        channel_names = cache['channel_names']\n",
    "\n",
    "        print(f\"Retraining {subject_id}\")\n",
    "\n",
    "        selector = ChannelSelector(result['adjacency_matrix'], channel_names)\n",
    "\n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    continue\n",
    "\n",
    "                k_val = min(k, result['num_channels'])\n",
    "\n",
    "                if method == 'ES':\n",
    "                    selected_channels, selected_indices = selector.edge_selection(k_val)\n",
    "                else:\n",
    "                    selected_channels, selected_indices = selector.aggregation_selection(k_val)\n",
    "\n",
    "                print(f\"  {method} k={k_val}: Retraining with {len(selected_channels)} channels...\")\n",
    "\n",
    "                retrain_res = retrain_with_selected_channels(\n",
    "                    data, labels,\n",
    "                    selected_channel_indices=selected_indices,\n",
    "                    num_timepoints=result['num_timepoints'],\n",
    "                    num_classes=result['num_classes'],\n",
    "                    device=device,\n",
    "                    n_splits=EXPERIMENT_CONFIG['model']['n_folds'],\n",
    "                    epochs=EXPERIMENT_CONFIG['model']['epochs'],\n",
    "                    lr=EXPERIMENT_CONFIG['model']['learning_rate']\n",
    "                )\n",
    "\n",
    "                acc_drop = result['gated_acc'] - retrain_res['avg_accuracy']\n",
    "\n",
    "                print(f\"    Accuracy: {retrain_res['avg_accuracy']:.4f} +/- {retrain_res['std_accuracy']:.4f}\")\n",
    "                print(f\"    Drop from full: {acc_drop:.4f} ({acc_drop/result['gated_acc']*100:.1f}%)\")\n",
    "\n",
    "                retrain_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_channels_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy': retrain_res['avg_accuracy'],\n",
    "                    'std': retrain_res['std_accuracy'],\n",
    "                    'full_channels_acc': result['gated_acc'],\n",
    "                    'accuracy_drop': acc_drop,\n",
    "                    'accuracy_drop_pct': acc_drop / result['gated_acc'] * 100\n",
    "                })\n",
    "\n",
    "    retrain_df = pd.DataFrame(retrain_results)\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f'Retraining complete: {len(retrain_df)} experiments')\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    retrain_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['retrain_results_file']\n",
    "    retrain_df.to_csv(retrain_path, index=False)\n",
    "    print(f\"Retrain results saved to: {retrain_path}\")\n",
    "else:\n",
    "    retrain_df = pd.DataFrame()\n",
    "    print('No results to retrain. Please run training first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain with Selected Channels\n",
    "\n",
    "Now retrain the model using ONLY the selected channels and compare accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OVERALL RESULTS SUMMARY (Gated Model)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Subjects trained: {len(results_df)}\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"Mean gated accuracy: {results_df['gated_acc'].mean():.4f} +/- {results_df['gated_acc'].std():.4f}\")\n",
    "    print(f\"Best subject: {results_df.loc[results_df['gated_acc'].idxmax(), 'subject']} ({results_df['gated_acc'].max():.4f})\")\n",
    "    print(f\"Worst subject: {results_df.loc[results_df['gated_acc'].idxmin(), 'subject']} ({results_df['gated_acc'].min():.4f})\")\n",
    "\n",
    "    results_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['gated_results_file']\n",
    "    cols_to_save = ['subject', 'num_trials', 'num_channels', 'gated_acc', 'gated_std', 'gate_mean', 'gate_std', 'gate_min', 'gate_max']\n",
    "    results_df[cols_to_save].to_csv(results_path, index=False)\n",
    "    print(f\"Results saved to: {results_path}\")\n",
    "\n",
    "    display(results_df[cols_to_save].head(10))\n",
    "else:\n",
    "    print(\"No subjects were successfully trained. Check the data loading and preprocessing steps.\")\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    axes[0, 0].hist(results_df['gated_acc'], bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(results_df['gated_acc'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 0].set_title('Accuracy Distribution (Gated Model)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Accuracy')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0, 1].scatter(results_df['num_trials'], results_df['gated_acc'], alpha=0.6, s=100)\n",
    "    axes[0, 1].set_title('Accuracy vs Number of Trials', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Number of Trials')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    top_10 = results_df.nlargest(min(10, len(results_df)), 'gated_acc')\n",
    "    axes[1, 0].barh(range(len(top_10)), top_10['gated_acc'], color='green', alpha=0.7)\n",
    "    axes[1, 0].set_yticks(range(len(top_10)))\n",
    "    axes[1, 0].set_yticklabels(top_10['subject'])\n",
    "    axes[1, 0].set_title(f'Top {len(top_10)} Subjects by Gated Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Accuracy')\n",
    "    axes[1, 0].invert_yaxis()\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "    sorted_results = results_df.sort_values('gated_acc')\n",
    "    axes[1, 1].plot(range(len(sorted_results)), sorted_results['gated_acc'], marker='o', markersize=4, alpha=0.6)\n",
    "    axes[1, 1].set_title('Subject Ranking (Gated Accuracy)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Rank')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    summary_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['results_summary_figure']\n",
    "    plt.savefig(summary_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Visualizations saved to: {summary_path}\")\n",
    "else:\n",
    "    print('No results to visualize. Please ensure subjects were successfully trained.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Adjacency Matrix (Example Subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(all_results) > 0:\n",
    "    best_idx = results_df['gated_acc'].idxmax()\n",
    "    best_result = all_results[best_idx]\n",
    "\n",
    "    print(f\"Visualizing adjacency matrix for best subject: {best_result['subject']}\")\n",
    "    print(f\"Accuracy: {best_result['gated_acc']:.4f}\")\n",
    "\n",
    "    selector = ChannelSelector(best_result['adjacency_matrix'], best_result['channel_names'])\n",
    "\n",
    "    adj_path = EXPERIMENT_CONFIG['output']['results_dir'] / f\"{EXPERIMENT_CONFIG['output']['adjacency_prefix']}_{best_result['subject']}.png\"\n",
    "    fig = selector.visualize_adjacency(save_path=adj_path)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Adjacency figure saved to: {adj_path}\")\n",
    "\n",
    "    print(\"Top 10 Edges (Edge Selection):\")\n",
    "    selected_channels_es, _ = selector.edge_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_es}\")\n",
    "\n",
    "    print(\"Top 10 Channels (Aggregation Selection):\")\n",
    "    selected_channels_as, _ = selector.aggregation_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_as}\")\n",
    "else:\n",
    "    print('No results available for adjacency visualization.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(results_df) > 0:\n",
    "    results_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['gated_results_file']\n",
    "    results_df[['subject', 'num_trials', 'num_channels', 'gated_acc', 'gated_std', 'gate_mean', 'gate_std', 'gate_min', 'gate_max']].to_csv(results_path, index=False)\n",
    "\n",
    "    if len(channel_selection_df) > 0:\n",
    "        channel_selection_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['channel_selection_results_file']\n",
    "        channel_selection_df.to_csv(channel_selection_path, index=False)\n",
    "    else:\n",
    "        channel_selection_path = None\n",
    "\n",
    "    config_path = EXPERIMENT_CONFIG['output']['results_dir'] / 'experiment_config_trial4_gated.json'\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(EXPERIMENT_CONFIG, f, indent=2, default=str)\n",
    "\n",
    "    print('All results exported successfully!')\n",
    "    print(f'  - Subject results: {results_path}')\n",
    "    if channel_selection_path:\n",
    "        print(f'  - Channel selection: {channel_selection_path}')\n",
    "    print(f'  - Config: {config_path}')\n",
    "else:\n",
    "    print('No results to export.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b603c",
   "metadata": {},
   "source": [
    "## Baseline Comparison\n",
    "\n",
    "Compare gated trial results with the baseline EEG-ARNN run from `physionet_training.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95423b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['baseline_results_file']\n",
    "comparison_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['comparison_file']\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    if baseline_path.exists():\n",
    "        baseline_df = pd.read_csv(baseline_path)\n",
    "        comparison_df = results_df.merge(\n",
    "            baseline_df[['subject', 'all_channels_acc', 'all_channels_std']],\n",
    "            on='subject',\n",
    "            how='left'\n",
    "        )\n",
    "        comparison_df['accuracy_delta'] = comparison_df['gated_acc'] - comparison_df['all_channels_acc']\n",
    "        comparison_df.rename(columns={\n",
    "            'all_channels_acc': 'baseline_acc',\n",
    "            'all_channels_std': 'baseline_std'\n",
    "        }, inplace=True)\n",
    "\n",
    "        display_columns = ['subject', 'baseline_acc', 'baseline_std', 'gated_acc', 'gated_std', 'accuracy_delta', 'gate_mean', 'gate_std']\n",
    "        display(comparison_df[display_columns])\n",
    "\n",
    "        comparison_df[display_columns].to_csv(comparison_path, index=False)\n",
    "        print(f\"Baseline comparison saved to: {comparison_path}\")\n",
    "    else:\n",
    "        print(f\"Baseline results not found at {baseline_path}. Run physionet_training.ipynb first.\")\n",
    "else:\n",
    "    print('No gated results available to compare against baseline.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
