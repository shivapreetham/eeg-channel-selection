{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhysioNet Motor Imagery - Complete Consolidated Comparison (OPTIMIZED)\n",
    "\n",
    "## All Methods: Baseline, Gated CARM, CARMv2, SparseGCN-CARM\n",
    "\n",
    "This notebook provides a comprehensive comparison of all four channel selection methods:\n",
    "\n",
    "1. **Baseline EEG-ARNN**: Pure CNN-GCN architecture\n",
    "2. **Gated CARM**: Learnable channel gates with L1 sparsity\n",
    "3. **CARMv2**: Feature-based adaptive adjacency with 2-hop propagation\n",
    "4. **SparseGCN-CARM**: Multi-head attention + multi-scale temporal\n",
    "\n",
    "**OPTIMIZED FOR SPEED**: ~2 hours runtime on GPU\n",
    "- 10 subjects (instead of 20)\n",
    "- 20 epochs (instead of 40)\n",
    "- 4 k values: [10, 20, 30, 40]\n",
    "- 2 selection methods per model (best ones)\n",
    "- Larger batch size (64) for faster training\n",
    "\n",
    "**Still includes**: 15+ comprehensive visualizations and detailed statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "\n",
    "import mne\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_context('notebook', font_scale=1.0)\n",
    "sns.set_style('whitegrid')\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "def set_seed(s=42):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect Kaggle environment\n",
    "import os\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    print(\"Running on Kaggle\")\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    datasets = [d for d in kaggle_input.iterdir() if d.is_dir()]\n",
    "    print(f\"Available datasets: {[d.name for d in datasets]}\")\n",
    "    \n",
    "    DATA_DIR = None\n",
    "    possible_names = ['physioneteegmi', 'eeg-motor-movementimagery-dataset']\n",
    "    for ds_name in possible_names:\n",
    "        test_path = kaggle_input / ds_name\n",
    "        if test_path.exists():\n",
    "            DATA_DIR = test_path\n",
    "            print(f\"Found dataset: {DATA_DIR}\")\n",
    "            break\n",
    "    \n",
    "    if DATA_DIR is None and datasets:\n",
    "        DATA_DIR = datasets[0]\n",
    "        print(f\"Using first available dataset: {DATA_DIR}\")\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "    DATA_DIR = Path('data/physionet/files')\n",
    "\n",
    "CONFIG = {\n",
    "    'data': {\n",
    "        'raw_data_dir': DATA_DIR,\n",
    "        'selected_classes': [1, 2],\n",
    "        'tmin': -1.0,\n",
    "        'tmax': 5.0,\n",
    "        'baseline': (-0.5, 0)\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'l_freq': 0.5,\n",
    "        'h_freq': 40.0,\n",
    "        'notch_freq': 50.0,\n",
    "        'target_sfreq': 128.0,\n",
    "        'apply_car': True\n",
    "    },\n",
    "    'model': {\n",
    "        'hidden_dim': 40,\n",
    "        'epochs': 20,\n",
    "        'learning_rate': 1e-3,\n",
    "        'batch_size': 64,\n",
    "        'n_folds': 3,\n",
    "        'patience': 5\n",
    "    },\n",
    "    'gated': {\n",
    "        'l1_lambda': 1e-3,\n",
    "        'gate_init': 0.9\n",
    "    },\n",
    "    'carmv2': {\n",
    "        'topk_k': 8,\n",
    "        'lambda_feat': 0.3,\n",
    "        'hop_alpha': 0.5,\n",
    "        'edge_dropout': 0.1,\n",
    "        'use_pairnorm': True,\n",
    "        'use_residual': True,\n",
    "        'low_rank_r': 0\n",
    "    },\n",
    "    'sparsegcn': {\n",
    "        'topk_k': 8,\n",
    "        'lambda_feat': 0.3,\n",
    "        'hop_alpha': 0.5,\n",
    "        'edge_dropout': 0.1,\n",
    "        'use_pairnorm': True,\n",
    "        'use_residual': True,\n",
    "        'use_channel_attention': True,\n",
    "        'attention_heads': 4,\n",
    "        'prune_enabled': False,\n",
    "        'prune_start_epoch': 10,\n",
    "        'prune_every': 2,\n",
    "        'prune_ratio': 0.05,\n",
    "        'min_channels': 20,\n",
    "        'temporal_scales': [8, 16, 32],\n",
    "        'channel_importance_loss': 1e-3\n",
    "    },\n",
    "    'channel_selection': {\n",
    "        'k_values': [10, 20, 30, 40]\n",
    "    },\n",
    "    'output': {\n",
    "        'results_dir': Path('results'),\n",
    "    },\n",
    "    'max_subjects': 10,\n",
    "    'min_runs_per_subject': 8\n",
    "}\n",
    "\n",
    "CONFIG['output']['results_dir'].mkdir(exist_ok=True, parents=True)\n",
    "print(\"\nOPTIMIZED Configuration loaded!\")\n",
    "print(f\"Training: {CONFIG['max_subjects']} subjects, {CONFIG['model']['n_folds']}-fold CV, {CONFIG['model']['epochs']} epochs\")\n",
    "print(f\"Channel selection: {CONFIG['channel_selection']['k_values']}\")\n",
    "print(f\"Batch size: {CONFIG['model']['batch_size']} (faster), Patience: {CONFIG['model']['patience']}\")\n",
    "print(\"Estimated runtime: ~2 hours on GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning - Excluded Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known faulty subjects from data cleaning analysis\n",
    "KNOWN_BAD_SUBJECTS = [\n",
    "    'S088', 'S089', 'S092', 'S100', 'S104', 'S106', 'S107', 'S108', 'S109'\n",
    "]\n",
    "\n",
    "# Additional subjects with high clipping or amplitude issues\n",
    "HIGH_ISSUE_SUBJECTS = [\n",
    "    'S003', 'S004', 'S009', 'S010', 'S012', 'S013', 'S017', 'S018', 'S019',\n",
    "    'S021', 'S022', 'S023', 'S024', 'S025', 'S026', 'S027', 'S028', 'S029'\n",
    "]\n",
    "\n",
    "EXCLUDED_SUBJECTS = set(KNOWN_BAD_SUBJECTS + HIGH_ISSUE_SUBJECTS)\n",
    "\n",
    "print(f\"Total excluded subjects: {len(EXCLUDED_SUBJECTS)}\")\n",
    "print(f\"Excluded: {sorted(EXCLUDED_SUBJECTS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw(raw, config):\n",
    "    \"\"\"Apply preprocessing to raw EEG data.\"\"\"\n",
    "    cleaned_names = {name: name.rstrip('.') for name in raw.ch_names}\n",
    "    raw.rename_channels(cleaned_names)\n",
    "    raw.pick_types(eeg=True)\n",
    "    raw.set_montage('standard_1020', on_missing='ignore', match_case=False)\n",
    "    \n",
    "    nyquist = raw.info['sfreq'] / 2.0\n",
    "    if config['preprocessing']['notch_freq'] < nyquist:\n",
    "        raw.notch_filter(freqs=config['preprocessing']['notch_freq'], verbose=False)\n",
    "    \n",
    "    raw.filter(\n",
    "        l_freq=config['preprocessing']['l_freq'],\n",
    "        h_freq=config['preprocessing']['h_freq'],\n",
    "        method='fir',\n",
    "        fir_design='firwin',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if config['preprocessing']['apply_car']:\n",
    "        raw.set_eeg_reference('average', projection=False, verbose=False)\n",
    "    \n",
    "    raw.resample(config['preprocessing']['target_sfreq'], npad='auto', verbose=False)\n",
    "    return raw\n",
    "\n",
    "\n",
    "def load_and_preprocess_edf(edf_path, config):\n",
    "    \"\"\"Load raw EDF file, preprocess it, and extract epochs.\"\"\"\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "    raw = preprocess_raw(raw, config)\n",
    "    \n",
    "    try:\n",
    "        events = mne.find_events(raw, verbose='ERROR')\n",
    "        event_ids = {f'T{i}': i for i in np.unique(events[:, 2])}\n",
    "        assert len(events) > 0\n",
    "    except Exception:\n",
    "        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "    \n",
    "    if len(events) == 0:\n",
    "        return None, None, raw.ch_names\n",
    "    \n",
    "    epochs = mne.Epochs(\n",
    "        raw,\n",
    "        events,\n",
    "        event_id=event_ids,\n",
    "        tmin=config['data']['tmin'],\n",
    "        tmax=config['data']['tmax'],\n",
    "        baseline=tuple(config['data']['baseline']),\n",
    "        preload=True,\n",
    "        verbose='ERROR'\n",
    "    )\n",
    "    \n",
    "    return epochs.get_data(), epochs.events[:, 2], raw.ch_names\n",
    "\n",
    "\n",
    "def filter_classes(x, y, selected_classes):\n",
    "    \"\"\"Filter to keep only selected classes and remap labels.\"\"\"\n",
    "    mask = np.isin(y, selected_classes)\n",
    "    y, x = y[mask], x[mask]\n",
    "    label_map = {old: new for new, old in enumerate(sorted(selected_classes))}\n",
    "    y = np.array([label_map[int(label)] for label in y], dtype=np.int64)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"Z-score normalization per channel.\"\"\"\n",
    "    mu = x.mean(axis=(0, 2), keepdims=True)\n",
    "    sd = x.std(axis=(0, 2), keepdims=True) + 1e-8\n",
    "    return (x - mu) / sd\n",
    "\n",
    "\n",
    "def load_subject_data(data_dir, subject_id, run_ids, config):\n",
    "    \"\"\"Load all runs for a subject, preprocess, and concatenate.\"\"\"\n",
    "    subject_dir = data_dir / subject_id\n",
    "    if not subject_dir.exists():\n",
    "        return None, None, None\n",
    "    \n",
    "    all_x, all_y = [], []\n",
    "    channel_names = None\n",
    "    \n",
    "    for run_id in run_ids:\n",
    "        edf_path = subject_dir / f'{subject_id}{run_id}.edf'\n",
    "        if not edf_path.exists():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            x, y, ch_names = load_and_preprocess_edf(edf_path, config)\n",
    "            if x is None or len(y) == 0:\n",
    "                continue\n",
    "            \n",
    "            x, y = filter_classes(x, y, config['data']['selected_classes'])\n",
    "            if len(y) == 0:\n",
    "                continue\n",
    "            \n",
    "            channel_names = channel_names or ch_names\n",
    "            all_x.append(x)\n",
    "            all_y.append(y)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if len(all_x) == 0:\n",
    "        return None, None, channel_names\n",
    "    \n",
    "    return np.concatenate(all_x, 0), np.concatenate(all_y, 0), channel_names\n",
    "\n",
    "\n",
    "def get_available_subjects(data_dir, min_runs=8, excluded=None):\n",
    "    \"\"\"Get list of subjects with at least min_runs available, excluding bad subjects.\"\"\"\n",
    "    if not data_dir.exists():\n",
    "        raise ValueError(f\"Data directory not found: {data_dir}\")\n",
    "    \n",
    "    excluded = excluded or set()\n",
    "    subjects = []\n",
    "    \n",
    "    for subject_dir in sorted(data_dir.iterdir()):\n",
    "        if not subject_dir.is_dir() or not subject_dir.name.startswith('S'):\n",
    "            continue\n",
    "        \n",
    "        if subject_dir.name in excluded:\n",
    "            continue\n",
    "        \n",
    "        edf_files = list(subject_dir.glob('*.edf'))\n",
    "        if len(edf_files) >= min_runs:\n",
    "            subjects.append(subject_dir.name)\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "\n",
    "# Scan for available subjects\n",
    "print(\"\\nScanning for subjects...\")\n",
    "data_dir = CONFIG['data']['raw_data_dir']\n",
    "print(f\"Looking for data in: {data_dir}\")\n",
    "\n",
    "all_subjects = get_available_subjects(\n",
    "    data_dir, \n",
    "    min_runs=CONFIG['min_runs_per_subject'],\n",
    "    excluded=EXCLUDED_SUBJECTS\n",
    ")\n",
    "subjects = all_subjects[:CONFIG['max_subjects']]\n",
    "\n",
    "print(f\"Found {len(all_subjects)} clean subjects\")\n",
    "print(f\"Will process {len(subjects)} subjects: {subjects}\")\n",
    "\n",
    "# Define which runs to use\n",
    "MOTOR_IMAGERY_RUNS = ['R07', 'R08', 'R09', 'R10', 'R11', 'R12', 'R13', 'R14']\n",
    "MOTOR_EXECUTION_RUNS = ['R03', 'R04', 'R05', 'R06']\n",
    "ALL_TASK_RUNS = MOTOR_IMAGERY_RUNS + MOTOR_EXECUTION_RUNS\n",
    "print(f\"Using runs: {ALL_TASK_RUNS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.FloatTensor(x).unsqueeze(1)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architectures\n",
    "\n",
    "### 6.1 Baseline EEG-ARNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvLayer(nn.Module):\n",
    "    \"\"\"Graph Convolution Layer with learned adjacency.\"\"\"\n",
    "    def __init__(self, num_channels, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.A = nn.Parameter(torch.randn(num_channels, num_channels))\n",
    "        self.theta = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(hidden_dim)\n",
    "        self.act = nn.ELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, H, C, T = x.shape\n",
    "        \n",
    "        A = torch.sigmoid(self.A)\n",
    "        A = 0.5 * (A + A.t())\n",
    "        I = torch.eye(C, device=A.device)\n",
    "        A_hat = A + I\n",
    "        D = torch.diag(torch.pow(A_hat.sum(1).clamp_min(1e-6), -0.5))\n",
    "        A_norm = D @ A_hat @ D\n",
    "        \n",
    "        x_batch = x.permute(0, 3, 2, 1).contiguous().view(B*T, C, H)\n",
    "        x_g = A_norm @ x_batch\n",
    "        x_g = self.theta(x_g)\n",
    "        x_g = x_g.view(B, T, C, H).permute(0, 3, 2, 1)\n",
    "        \n",
    "        x_out = self.bn(x_g)\n",
    "        x_out = self.act(x_out)\n",
    "        \n",
    "        return x_out\n",
    "    \n",
    "    def get_adjacency(self):\n",
    "        with torch.no_grad():\n",
    "            A = torch.sigmoid(self.A)\n",
    "            A = 0.5 * (A + A.t())\n",
    "            return A.cpu().numpy()\n",
    "\n",
    "\n",
    "class TemporalConv(nn.Module):\n",
    "    \"\"\"Temporal Convolution Layer.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=16, pool=True):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, \n",
    "                            kernel_size=(1, kernel_size), \n",
    "                            padding=(0, kernel_size//2), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ELU()\n",
    "        self.pool_layer = nn.AvgPool2d(kernel_size=(1, 2)) if pool else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn(self.conv(x)))\n",
    "        return self.pool_layer(x) if self.pool else x\n",
    "\n",
    "\n",
    "class BaselineEEGARNN(nn.Module):\n",
    "    \"\"\"Baseline EEG-ARNN with pure CNN-GCN architecture.\"\"\"\n",
    "    def __init__(self, C, T, K, H):\n",
    "        super().__init__()\n",
    "        self.t1 = TemporalConv(1, H, 16, False)\n",
    "        self.g1 = GraphConvLayer(C, H)\n",
    "        self.t2 = TemporalConv(H, H, 16, True)\n",
    "        self.g2 = GraphConvLayer(C, H)\n",
    "        self.t3 = TemporalConv(H, H, 16, True)\n",
    "        self.g3 = GraphConvLayer(C, H)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ft = self._forward_features(torch.zeros(1, 1, C, T))\n",
    "            fs = ft.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(fs, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, K)\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = self.g1(self.t1(x))\n",
    "        x = self.g2(self.t2(x))\n",
    "        x = self.g3(self.t3(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "    \n",
    "    def get_final_adjacency(self):\n",
    "        return self.g3.get_adjacency()\n",
    "\n",
    "\n",
    "print(\"Baseline EEG-ARNN defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Gated CARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedEEGARNN(BaselineEEGARNN):\n",
    "    \"\"\"EEG-ARNN with learnable channel gates.\"\"\"\n",
    "    def __init__(self, C, T, K, H, gate_init=0.9):\n",
    "        super().__init__(C, T, K, H)\n",
    "        init = torch.full((C,), float(gate_init), dtype=torch.float32)\n",
    "        init = torch.clamp(init, 1e-4, 1 - 1e-4)\n",
    "        gate_logits = torch.logit(init)\n",
    "        self.gate_logits = nn.Parameter(gate_logits)\n",
    "        self.latest_gates = None\n",
    "    \n",
    "    def get_gate_values(self):\n",
    "        return torch.sigmoid(self.gate_logits)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gate_values = torch.sigmoid(self.gate_logits)\n",
    "        self.latest_gates = gate_values.detach().cpu()\n",
    "        x = x * gate_values.view(1, 1, -1, 1)\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "print(\"Gated CARM defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 CARMv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairnorm(x, node_dim=2, eps=1e-6):\n",
    "    m = x.mean(dim=node_dim, keepdim=True)\n",
    "    xc = x - m\n",
    "    v = (xc * xc).mean(dim=node_dim, keepdim=True)\n",
    "    return xc / torch.sqrt(v + eps)\n",
    "\n",
    "\n",
    "def build_feat_topk_adj(x, k, active_channels=None):\n",
    "    B, H, C, T = x.shape\n",
    "    \n",
    "    if active_channels is not None:\n",
    "        mask = active_channels.view(C, 1).to(x.device)\n",
    "        x_masked = x * mask.view(1, 1, C, 1)\n",
    "    else:\n",
    "        x_masked = x\n",
    "    \n",
    "    E = x_masked.permute(2, 1, 0, 3).contiguous().view(C, H, B*T).mean(2)\n",
    "    En = F.normalize(E, p=2, dim=1)\n",
    "    S = (En @ En.t()).clamp_min(0.0)\n",
    "    k = max(1, min(int(k), C))\n",
    "    vals, idx = torch.topk(S, k, dim=1)\n",
    "    M = torch.zeros_like(S)\n",
    "    M.scatter_(1, idx, 1.0)\n",
    "    A = S * M\n",
    "    A = torch.softmax(A, 1)\n",
    "    A = 0.5 * (A + A.t())\n",
    "    return A\n",
    "\n",
    "\n",
    "class CARMv2Layer(nn.Module):\n",
    "    def __init__(self, C, H, cfg):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.k = int(cfg['topk_k'])\n",
    "        self.lf = float(cfg['lambda_feat'])\n",
    "        self.ha = float(cfg['hop_alpha'])\n",
    "        self.ed = float(cfg['edge_dropout'])\n",
    "        self.pn = bool(cfg['use_pairnorm'])\n",
    "        self.res = bool(cfg['use_residual'])\n",
    "        r = int(cfg['low_rank_r'])\n",
    "        \n",
    "        if r > 0:\n",
    "            self.B = nn.Parameter(torch.empty(C, r))\n",
    "            nn.init.xavier_uniform_(self.B)\n",
    "            self.W = None\n",
    "        else:\n",
    "            self.W = nn.Parameter(torch.empty(C, C))\n",
    "            nn.init.xavier_uniform_(self.W)\n",
    "            self.B = None\n",
    "        \n",
    "        self.th = nn.Linear(H, H, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(H)\n",
    "        self.act = nn.ELU()\n",
    "        self.last = None\n",
    "    \n",
    "    def _learned(self, dev, active_channels=None):\n",
    "        W = self.W if self.B is None else (self.B @ self.B.t())\n",
    "        A = torch.sigmoid(W)\n",
    "        A = 0.5 * (A + A.t())\n",
    "        \n",
    "        if active_channels is not None:\n",
    "            mask = active_channels.view(self.C, 1).to(dev)\n",
    "            A = A * mask * mask.t()\n",
    "        \n",
    "        I = torch.eye(self.C, device=dev, dtype=A.dtype)\n",
    "        At = A + I\n",
    "        d = torch.pow(At.sum(1).clamp_min(1e-6), -0.5)\n",
    "        D = torch.diag(d)\n",
    "        return D @ At @ D\n",
    "    \n",
    "    def forward(self, x, active_channels=None):\n",
    "        B, H, C, T = x.shape\n",
    "        Al = self._learned(x.device, active_channels)\n",
    "        A2 = Al @ Al\n",
    "        Ah = (1 - self.ha) * Al + self.ha * A2\n",
    "        Af = build_feat_topk_adj(x, self.k, active_channels)\n",
    "        A = (1 - self.lf) * Ah + self.lf * Af\n",
    "        \n",
    "        if self.training and self.ed > 0:\n",
    "            M = (torch.rand_like(A) > self.ed).float()\n",
    "            A = 0.5 * ((A * M) + (A * M).t())\n",
    "            A = A + torch.eye(C, device=A.device, dtype=A.dtype)\n",
    "        \n",
    "        d = torch.pow(A.sum(1).clamp_min(1e-6), -0.5)\n",
    "        D = torch.diag(d)\n",
    "        A = D @ A @ D\n",
    "        \n",
    "        xb = x.permute(0, 3, 2, 1).contiguous().view(B*T, C, H)\n",
    "        xg = A @ xb\n",
    "        xg = self.th(xg)\n",
    "        xg = xg.view(B, T, C, H).permute(0, 3, 2, 1)\n",
    "        \n",
    "        if self.res:\n",
    "            if active_channels is not None:\n",
    "                x_res = x * active_channels.view(1, 1, C, 1)\n",
    "            else:\n",
    "                x_res = x\n",
    "            out = xg + x_res\n",
    "        else:\n",
    "            out = xg\n",
    "        out = pairnorm(out, 2) if self.pn else out\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        \n",
    "        self.last = {'learned': Al.detach().cpu().numpy()}\n",
    "        return out\n",
    "    \n",
    "    def get_adjs(self):\n",
    "        return self.last or {}\n",
    "\n",
    "\n",
    "class CARMv2Model(nn.Module):\n",
    "    def __init__(self, C, T, K, H, cfg):\n",
    "        super().__init__()\n",
    "        self.t1 = TemporalConv(1, H, 16, False)\n",
    "        self.g1 = CARMv2Layer(C, H, cfg)\n",
    "        self.t2 = TemporalConv(H, H, 16, True)\n",
    "        self.g2 = CARMv2Layer(C, H, cfg)\n",
    "        self.t3 = TemporalConv(H, H, 16, True)\n",
    "        self.g3 = CARMv2Layer(C, H, cfg)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ft = self._f(torch.zeros(1, 1, C, T))\n",
    "            fs = ft.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(fs, 256)\n",
    "        self.do = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, K)\n",
    "    \n",
    "    def _f(self, x):\n",
    "        x = self.g1(self.t1(x))\n",
    "        x = self.g2(self.t2(x))\n",
    "        x = self.g3(self.t3(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._f(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.do(x)\n",
    "        return self.fc2(x)\n",
    "    \n",
    "    def get_final_adjacency(self):\n",
    "        adjs = self.g3.get_adjs()\n",
    "        return adjs.get('learned', None)\n",
    "\n",
    "\n",
    "print(\"CARMv2 defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 SparseGCN-CARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Multi-head channel attention module.\"\"\"\n",
    "    def __init__(self, num_channels, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = max(1, num_channels // num_heads)\n",
    "        \n",
    "        self.channel_embed = nn.Parameter(torch.randn(num_channels, self.head_dim * num_heads))\n",
    "        nn.init.xavier_uniform_(self.channel_embed)\n",
    "        \n",
    "        self.query = nn.Linear(self.head_dim * num_heads, self.head_dim * num_heads)\n",
    "        self.key = nn.Linear(self.head_dim * num_heads, self.head_dim * num_heads)\n",
    "        \n",
    "        self.importance_proj = nn.Sequential(\n",
    "            nn.Linear(self.head_dim * num_heads, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x=None):\n",
    "        embed = self.channel_embed\n",
    "        \n",
    "        Q = self.query(embed)\n",
    "        K = self.key(embed)\n",
    "        \n",
    "        Q = Q.view(self.num_channels, self.num_heads, self.head_dim)\n",
    "        K = K.view(self.num_channels, self.num_heads, self.head_dim)\n",
    "        \n",
    "        attn = torch.einsum('chd,khd->chk', Q, K) / np.sqrt(self.head_dim)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        attn_pooled = attn.mean(dim=1)\n",
    "        channel_scores = attn_pooled.sum(dim=1)\n",
    "        channel_scores = channel_scores / channel_scores.sum()\n",
    "        \n",
    "        importance = self.importance_proj(embed).squeeze(-1) if embed.dim() > 1 else self.importance_proj(embed)\n",
    "        \n",
    "        final_importance = 0.5 * channel_scores + 0.5 * importance\n",
    "        final_importance = final_importance / (final_importance.sum() + 1e-8)\n",
    "        \n",
    "        return final_importance, attn\n",
    "\n",
    "\n",
    "class MultiScaleTemporalConv(nn.Module):\n",
    "    \"\"\"Multi-scale temporal convolution.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[8, 16, 32], pool=True):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        k_num = len(kernel_sizes)\n",
    "        base = out_channels // k_num\n",
    "        rem = out_channels - base * k_num\n",
    "        out_list = [base + (1 if i < rem else 0) for i in range(k_num)]\n",
    "        \n",
    "        branches = []\n",
    "        for i, k in enumerate(kernel_sizes):\n",
    "            oc = out_list[i]\n",
    "            branches.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, oc, kernel_size=(1, k), padding=(0, k//2), bias=False),\n",
    "                    nn.BatchNorm2d(oc),\n",
    "                    nn.ELU()\n",
    "                )\n",
    "            )\n",
    "        self.branches = nn.ModuleList(branches)\n",
    "        self.pool_layer = nn.AvgPool2d(kernel_size=(1, 2)) if pool else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch_outputs = [branch(x) for branch in self.branches]\n",
    "        x = torch.cat(branch_outputs, dim=1)\n",
    "        return self.pool_layer(x) if self.pool else x\n",
    "\n",
    "\n",
    "class AdaptiveGCNLayer(nn.Module):\n",
    "    \"\"\"Adaptive GCN layer from CARMv2.\"\"\"\n",
    "    def __init__(self, C, H, topk_k=8, lambda_feat=0.3, hop_alpha=0.5, edge_dropout=0.1,\n",
    "                 use_pairnorm=True, use_residual=True):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.k = topk_k\n",
    "        self.lf = lambda_feat\n",
    "        self.ha = hop_alpha\n",
    "        self.ed = edge_dropout\n",
    "        self.pn = use_pairnorm\n",
    "        self.res = use_residual\n",
    "        \n",
    "        self.W = nn.Parameter(torch.empty(C, C))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        \n",
    "        self.th = nn.Linear(H, H, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(H)\n",
    "        self.act = nn.ELU()\n",
    "        self.last = None\n",
    "    \n",
    "    def _learned(self, dev, active_channels=None):\n",
    "        A = torch.sigmoid(self.W)\n",
    "        A = 0.5 * (A + A.t())\n",
    "        \n",
    "        if active_channels is not None:\n",
    "            mask = active_channels.view(self.C, 1).to(dev)\n",
    "            A = A * mask * mask.t()\n",
    "        \n",
    "        I = torch.eye(self.C, device=dev, dtype=A.dtype)\n",
    "        At = A + I\n",
    "        d = torch.pow(At.sum(1).clamp_min(1e-6), -0.5)\n",
    "        D = torch.diag(d)\n",
    "        return D @ At @ D\n",
    "    \n",
    "    def forward(self, x, active_channels=None):\n",
    "        B, H, C, T = x.shape\n",
    "        \n",
    "        Al = self._learned(x.device, active_channels)\n",
    "        A2 = Al @ Al\n",
    "        Ah = (1 - self.ha) * Al + self.ha * A2\n",
    "        Af = build_feat_topk_adj(x, self.k, active_channels)\n",
    "        A = (1 - self.lf) * Ah + self.lf * Af\n",
    "        \n",
    "        if self.training and self.ed > 0:\n",
    "            M = (torch.rand_like(A) > self.ed).float()\n",
    "            A = 0.5 * ((A * M) + (A * M).t())\n",
    "            A = A + torch.eye(C, device=A.device, dtype=A.dtype)\n",
    "        \n",
    "        d = torch.pow(A.sum(1).clamp_min(1e-6), -0.5)\n",
    "        D = torch.diag(d)\n",
    "        A = D @ A @ D\n",
    "        \n",
    "        xb = x.permute(0, 3, 2, 1).contiguous().view(B*T, C, H)\n",
    "        xg = A @ xb\n",
    "        xg = self.th(xg)\n",
    "        xg = xg.view(B, T, C, H).permute(0, 3, 2, 1)\n",
    "        \n",
    "        if self.res:\n",
    "            if active_channels is not None:\n",
    "                x_res = x * active_channels.view(1, 1, C, 1)\n",
    "            else:\n",
    "                x_res = x\n",
    "            out = xg + x_res\n",
    "        else:\n",
    "            out = xg\n",
    "        out = pairnorm(out, 2) if self.pn else out\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        \n",
    "        self.last = {'learned': Al.detach().cpu().numpy()}\n",
    "        return out\n",
    "\n",
    "\n",
    "class SparseGCNCARMModel(nn.Module):\n",
    "    \"\"\"SparseGCN-CARM with multi-head attention and progressive pruning.\"\"\"\n",
    "    def __init__(self, C, T, K, H, config):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.config = config\n",
    "        \n",
    "        if config.get('use_channel_attention', True):\n",
    "            self.channel_attention = ChannelAttention(C, config.get('attention_heads', 4))\n",
    "        else:\n",
    "            self.channel_attention = None\n",
    "        \n",
    "        scales = config.get('temporal_scales', [8, 16, 32])\n",
    "        self.t1 = MultiScaleTemporalConv(1, H, scales, False)\n",
    "        self.g1 = AdaptiveGCNLayer(C, H, config.get('topk_k', 8), config.get('lambda_feat', 0.3),\n",
    "                                   config.get('hop_alpha', 0.5), config.get('edge_dropout', 0.1),\n",
    "                                   config.get('use_pairnorm', True), config.get('use_residual', True))\n",
    "        self.t2 = MultiScaleTemporalConv(H, H, scales, True)\n",
    "        self.g2 = AdaptiveGCNLayer(C, H, config.get('topk_k', 8), config.get('lambda_feat', 0.3),\n",
    "                                   config.get('hop_alpha', 0.5), config.get('edge_dropout', 0.1),\n",
    "                                   config.get('use_pairnorm', True), config.get('use_residual', True))\n",
    "        self.t3 = MultiScaleTemporalConv(H, H, scales, True)\n",
    "        self.g3 = AdaptiveGCNLayer(C, H, config.get('topk_k', 8), config.get('lambda_feat', 0.3),\n",
    "                                   config.get('hop_alpha', 0.5), config.get('edge_dropout', 0.1),\n",
    "                                   config.get('use_pairnorm', True), config.get('use_residual', True))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ft = self._forward_features(torch.zeros(1, 1, C, T), None)\n",
    "            fs = ft.view(1, -1).size(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(fs, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, K)\n",
    "        \n",
    "        self.register_buffer('active_channels', torch.ones(C))\n",
    "        self.channel_importance = None\n",
    "    \n",
    "    def _forward_features(self, x, active_channels):\n",
    "        x = self.g1(self.t1(x), active_channels)\n",
    "        x = self.g2(self.t2(x), active_channels)\n",
    "        x = self.g3(self.t3(x), active_channels)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.channel_attention is not None:\n",
    "            importance, attn = self.channel_attention(x)\n",
    "            self.channel_importance = importance\n",
    "            \n",
    "            if self.training:\n",
    "                x = x * importance.view(1, 1, self.C, 1)\n",
    "        \n",
    "        x = self._forward_features(x, self.active_channels)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "    \n",
    "    def prune_channels(self, prune_ratio, min_channels=20):\n",
    "        if self.channel_importance is None:\n",
    "            return 0\n",
    "        \n",
    "        num_active = int(self.active_channels.sum().item())\n",
    "        num_to_prune = max(1, int(num_active * prune_ratio))\n",
    "        \n",
    "        if num_active - num_to_prune < min_channels:\n",
    "            return 0\n",
    "        \n",
    "        importance = self.channel_importance.detach().cpu()\n",
    "        active_importance = importance * self.active_channels.cpu()\n",
    "        \n",
    "        _, sorted_indices = torch.sort(active_importance)\n",
    "        \n",
    "        pruned = 0\n",
    "        for idx in sorted_indices:\n",
    "            if self.active_channels[idx] > 0:\n",
    "                self.active_channels[idx] = 0\n",
    "                pruned += 1\n",
    "                if pruned >= num_to_prune:\n",
    "                    break\n",
    "        \n",
    "        return pruned\n",
    "    \n",
    "    def get_channel_importance(self):\n",
    "        if self.channel_importance is not None:\n",
    "            return self.channel_importance.detach().cpu().numpy()\n",
    "        return None\n",
    "    \n",
    "    def get_active_channels_mask(self):\n",
    "        return self.active_channels.cpu().numpy()\n",
    "    \n",
    "    def get_final_adjacency(self):\n",
    "        return self.g3.last.get('learned', None) if self.g3.last else None\n",
    "\n",
    "\n",
    "print(\"SparseGCN-CARM defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, config, model_type):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        # Add regularization\n",
    "        if model_type == 'gated' and hasattr(model, 'get_gate_values'):\n",
    "            l1_lambda = config['gated']['l1_lambda']\n",
    "            gate_values = model.get_gate_values()\n",
    "            loss = loss + l1_lambda * gate_values.abs().mean()\n",
    "        elif model_type == 'sparsegcn' and hasattr(model, 'channel_importance'):\n",
    "            if model.channel_importance is not None:\n",
    "                importance_loss = config['sparsegcn']['channel_importance_loss'] * model.channel_importance.abs().mean()\n",
    "                loss = loss + importance_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_preds += torch.argmax(logits, 1).cpu().tolist()\n",
    "        all_labels += y.cpu().tolist()\n",
    "    \n",
    "    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_preds += torch.argmax(logits, 1).cpu().tolist()\n",
    "        all_labels += y.cpu().tolist()\n",
    "    \n",
    "    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, config, model_type):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['model']['learning_rate'], weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=False\n",
    "    )\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "    \n",
    "    # Progressive pruning for SparseGCN\n",
    "    prune_enabled = False\n",
    "    if model_type == 'sparsegcn' and hasattr(model, 'prune_channels'):\n",
    "        prune_enabled = config['sparsegcn'].get('prune_enabled', True)\n",
    "        prune_start = config['sparsegcn'].get('prune_start_epoch', 10)\n",
    "        prune_every = config['sparsegcn'].get('prune_every', 2)\n",
    "        prune_ratio = config['sparsegcn'].get('prune_ratio', 0.05)\n",
    "        min_channels = config['sparsegcn'].get('min_channels', 20)\n",
    "    \n",
    "    for epoch in range(config['model']['epochs']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, config, model_type)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Progressive pruning\n",
    "        if prune_enabled and epoch >= prune_start and (epoch - prune_start) % prune_every == 0:\n",
    "            num_pruned = model.prune_channels(prune_ratio, min_channels)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        \n",
    "        if no_improve >= config['model']['patience']:\n",
    "            break\n",
    "    \n",
    "    if best_state is None:\n",
    "        best_state = deepcopy(model.state_dict())\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    return best_state, best_acc\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_subject(x, y, channel_names, T, K, device, config, model_type):\n",
    "    \"\"\"Cross-validate subject with specified model type.\"\"\"\n",
    "    C = x.shape[1]\n",
    "    H = config['model']['hidden_dim']\n",
    "    skf = StratifiedKFold(n_splits=config['model']['n_folds'], shuffle=True, random_state=42)\n",
    "    \n",
    "    folds = []\n",
    "    adjacencies = []\n",
    "    gate_values_list = []\n",
    "    importance_values_list = []\n",
    "    active_channels_list = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(x, y)):\n",
    "        X_train, X_val = normalize(x[train_idx]), normalize(x[val_idx])\n",
    "        Y_train, Y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            EEGDataset(X_train, Y_train),\n",
    "            batch_size=config['model']['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            EEGDataset(X_val, Y_val),\n",
    "            batch_size=config['model']['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        # Create model\n",
    "        if model_type == 'baseline':\n",
    "            model = BaselineEEGARNN(C, T, K, H).to(device)\n",
    "        elif model_type == 'gated':\n",
    "            model = GatedEEGARNN(C, T, K, H, config['gated']['gate_init']).to(device)\n",
    "        elif model_type == 'carmv2':\n",
    "            model = CARMv2Model(C, T, K, H, config['carmv2']).to(device)\n",
    "        elif model_type == 'sparsegcn':\n",
    "            model = SparseGCNCARMModel(C, T, K, H, config['sparsegcn']).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        best_state, best_acc = train_model(model, train_loader, val_loader, device, config, model_type)\n",
    "        model.load_state_dict(best_state)\n",
    "        \n",
    "        _, accuracy = evaluate(model, val_loader, nn.CrossEntropyLoss(), device)\n",
    "        \n",
    "        adjacency = model.get_final_adjacency()\n",
    "        adjacencies.append(adjacency)\n",
    "        \n",
    "        if model_type == 'gated':\n",
    "            gate_values = model.get_gate_values().detach().cpu().numpy()\n",
    "            gate_values_list.append(gate_values)\n",
    "        elif model_type == 'sparsegcn':\n",
    "            importance = model.get_channel_importance()\n",
    "            active_mask = model.get_active_channels_mask()\n",
    "            if importance is not None:\n",
    "                importance_values_list.append(importance)\n",
    "            active_channels_list.append(int(active_mask.sum()))\n",
    "        \n",
    "        folds.append({'fold': fold, 'val_acc': accuracy})\n",
    "    \n",
    "    avg_acc = float(np.mean([f['val_acc'] for f in folds]))\n",
    "    std_acc = float(np.std([f['val_acc'] for f in folds]))\n",
    "    avg_adjacency = np.mean(np.stack([a for a in adjacencies if a is not None], 0), 0) \\\n",
    "                    if any(a is not None for a in adjacencies) else None\n",
    "    \n",
    "    result = {\n",
    "        'fold_results': folds,\n",
    "        'avg_accuracy': avg_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'adjacency_matrix': avg_adjacency,\n",
    "        'channel_names': channel_names\n",
    "    }\n",
    "    \n",
    "    if model_type == 'gated' and gate_values_list:\n",
    "        result['avg_gate_values'] = np.mean(np.stack(gate_values_list, 0), 0)\n",
    "    elif model_type == 'sparsegcn':\n",
    "        if importance_values_list:\n",
    "            result['avg_importance'] = np.mean(np.stack(importance_values_list, 0), 0)\n",
    "        if active_channels_list:\n",
    "            result['avg_active_channels'] = np.mean(active_channels_list)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Cross-validation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Training Loop - All Four Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {'baseline': [], 'gated': [], 'carmv2': [], 'sparsegcn': []}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING ALL FOUR METHODS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for subject_id in tqdm(subjects, desc='Training subjects'):\n",
    "    print(f\"\\nProcessing {subject_id}...\")\n",
    "    \n",
    "    X, Y, channel_names = load_subject_data(data_dir, subject_id, ALL_TASK_RUNS, CONFIG)\n",
    "    \n",
    "    if X is None or len(Y) == 0:\n",
    "        print(f\"  Skipped: No data available\")\n",
    "        continue\n",
    "    \n",
    "    C, T = X.shape[1], X.shape[2]\n",
    "    K = len(set(CONFIG['data']['selected_classes']))\n",
    "    \n",
    "    print(f\"  Data: {X.shape}, Classes: {K}\")\n",
    "    \n",
    "    # Train all four methods\n",
    "    for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "        print(f\"  Training {model_type.upper()}...\", end=' ')\n",
    "        result = cross_validate_subject(X, Y, channel_names, T, K, device, CONFIG, model_type)\n",
    "        \n",
    "        print(f\"{result['avg_accuracy']:.4f} \u00c2\u00b1 {result['std_accuracy']:.4f}\", end='')\n",
    "        \n",
    "        result_dict = {\n",
    "            'subject': subject_id,\n",
    "            'num_trials': X.shape[0],\n",
    "            'num_channels': C,\n",
    "            'accuracy': result['avg_accuracy'],\n",
    "            'std': result['std_accuracy'],\n",
    "            'adjacency_matrix': result['adjacency_matrix'],\n",
    "            'channel_names': result['channel_names']\n",
    "        }\n",
    "        \n",
    "        if model_type == 'gated' and 'avg_gate_values' in result:\n",
    "            result_dict['gate_values'] = result['avg_gate_values']\n",
    "        elif model_type == 'sparsegcn':\n",
    "            if 'avg_importance' in result:\n",
    "                result_dict['importance_values'] = result['avg_importance']\n",
    "            if 'avg_active_channels' in result:\n",
    "                result_dict['avg_active_channels'] = result['avg_active_channels']\n",
    "                print(f\" ({result['avg_active_channels']:.0f} active)\", end='')\n",
    "        \n",
    "        print()\n",
    "        all_results[model_type].append(result_dict)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Channel Selection Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalChannelSelector:\n",
    "    \"\"\"Universal channel selector supporting all methods.\"\"\"\n",
    "    def __init__(self, adjacency, channel_names, importance=None, gate_values=None):\n",
    "        self.A = adjacency\n",
    "        self.names = np.array(channel_names)\n",
    "        self.C = adjacency.shape[0]\n",
    "        self.importance = importance\n",
    "        self.gate_values = gate_values\n",
    "    \n",
    "    def edge_selection(self, k):\n",
    "        \"\"\"ES: Edge-based selection.\"\"\"\n",
    "        edges = []\n",
    "        for i in range(self.C):\n",
    "            for j in range(i+1, self.C):\n",
    "                edges.append((i, j, abs(self.A[i, j]) + abs(self.A[j, i])))\n",
    "        edges.sort(key=lambda t: t[2], reverse=True)\n",
    "        top_edges = edges[:int(k)]\n",
    "        indices = sorted(set([i for i, _, _ in top_edges] + [j for _, j, _ in top_edges]))\n",
    "        return self.names[indices].tolist(), np.array(indices)\n",
    "    \n",
    "    def aggregation_selection(self, k):\n",
    "        \"\"\"AS: Aggregation-based selection.\"\"\"\n",
    "        scores = np.sum(np.abs(self.A), 1)\n",
    "        indices = np.sort(np.argsort(scores)[-int(k):])\n",
    "        return self.names[indices].tolist(), indices\n",
    "    \n",
    "    def importance_selection(self, k):\n",
    "        \"\"\"IMP: Importance-based selection (for SparseGCN).\"\"\"\n",
    "        if self.importance is None:\n",
    "            return self.aggregation_selection(k)\n",
    "        k = min(int(k), self.C)\n",
    "        indices = np.argsort(self.importance)[-k:]\n",
    "        indices = np.sort(indices)\n",
    "        return self.names[indices].tolist(), indices\n",
    "    \n",
    "    def gate_selection(self, k):\n",
    "        \"\"\"GATE: Gate-based selection (for Gated CARM).\"\"\"\n",
    "        if self.gate_values is None:\n",
    "            return self.aggregation_selection(k)\n",
    "        k = min(int(k), self.C)\n",
    "        indices = np.argsort(self.gate_values)[-k:]\n",
    "        indices = np.sort(indices)\n",
    "        return self.names[indices].tolist(), indices\n",
    "    \n",
    "    def hybrid_selection(self, k):\n",
    "        \"\"\"HYB: Hybrid selection combining connectivity and importance.\"\"\"\n",
    "        connectivity = np.sum(np.abs(self.A), 1)\n",
    "        \n",
    "        if self.importance is not None:\n",
    "            combined_score = 0.7 * self.importance + 0.3 * (connectivity / connectivity.max())\n",
    "        elif self.gate_values is not None:\n",
    "            combined_score = 0.7 * self.gate_values + 0.3 * (connectivity / connectivity.max())\n",
    "        else:\n",
    "            return self.aggregation_selection(k)\n",
    "        \n",
    "        k = min(int(k), self.C)\n",
    "        indices = np.argsort(combined_score)[-k:]\n",
    "        indices = np.sort(indices)\n",
    "        return self.names[indices].tolist(), indices\n",
    "\n",
    "\n",
    "def retrain_with_selection(X, Y, selected_indices, T, K, device, config, model_type):\n",
    "    \"\"\"Retrain with selected channels.\"\"\"\n",
    "    X_subset = X[:, selected_indices, :]\n",
    "    C_new = len(selected_indices)\n",
    "    H = config['model']['hidden_dim']\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=config['model']['n_folds'], shuffle=True, random_state=42)\n",
    "    fold_accs = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_subset, Y)):\n",
    "        X_train = normalize(X_subset[train_idx])\n",
    "        X_val = normalize(X_subset[val_idx])\n",
    "        Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            EEGDataset(X_train, Y_train),\n",
    "            batch_size=config['model']['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            EEGDataset(X_val, Y_val),\n",
    "            batch_size=config['model']['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        # Create smaller model\n",
    "        if model_type == 'baseline':\n",
    "            model = BaselineEEGARNN(C_new, T, K, H).to(device)\n",
    "        elif model_type == 'gated':\n",
    "            model = GatedEEGARNN(C_new, T, K, H, config['gated']['gate_init']).to(device)\n",
    "        elif model_type == 'carmv2':\n",
    "            model = CARMv2Model(C_new, T, K, H, config['carmv2']).to(device)\n",
    "        elif model_type == 'sparsegcn':\n",
    "            sparsegcn_config = config['sparsegcn'].copy()\n",
    "            sparsegcn_config['prune_enabled'] = False  # Disable pruning for retraining\n",
    "            model = SparseGCNCARMModel(C_new, T, K, H, sparsegcn_config).to(device)\n",
    "        \n",
    "        best_state, best_acc = train_model(model, train_loader, val_loader, device, config, model_type)\n",
    "        model.load_state_dict(best_state)\n",
    "        \n",
    "        _, accuracy = evaluate(model, val_loader, nn.CrossEntropyLoss(), device)\n",
    "        fold_accs.append(accuracy)\n",
    "    \n",
    "    return {\n",
    "        'avg_accuracy': float(np.mean(fold_accs)),\n",
    "        'std_accuracy': float(np.std(fold_accs))\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Channel selection functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Channel Selection Experiments (OPTIMIZED)\n",
    "\n",
    "Testing with k=[10, 20, 30, 40] channels using 2 best methods per model:\n",
    "- **Baseline/CARMv2**: ES, AS\n",
    "- **Gated CARM**: GATE, AS\n",
    "- **SparseGCN**: IMP, HYB\n",
    "\n",
    "This gives comprehensive results while keeping runtime reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = CONFIG['channel_selection']['k_values']\n",
    "selection_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHANNEL SELECTION EXPERIMENTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for subject_id in tqdm(subjects, desc='Channel Selection'):\n",
    "    print(f\"\\nProcessing {subject_id}...\")\n",
    "    \n",
    "    # Load data\n",
    "    X, Y, channel_names = load_subject_data(data_dir, subject_id, ALL_TASK_RUNS, CONFIG)\n",
    "    if X is None:\n",
    "        continue\n",
    "    \n",
    "    C, T = X.shape[1], X.shape[2]\n",
    "    K = len(set(CONFIG['data']['selected_classes']))\n",
    "    \n",
    "    # Process each method\n",
    "    for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "        # Find result for this subject\n",
    "        subj_result = None\n",
    "        for res in all_results[model_type]:\n",
    "            if res['subject'] == subject_id:\n",
    "                subj_result = res\n",
    "                break\n",
    "        \n",
    "        if subj_result is None:\n",
    "            continue\n",
    "        \n",
    "        adjacency = subj_result['adjacency_matrix']\n",
    "        full_acc = subj_result['accuracy']\n",
    "        \n",
    "        # Get importance/gate values if available\n",
    "        importance = subj_result.get('importance_values', None)\n",
    "        gate_values = subj_result.get('gate_values', None)\n",
    "        \n",
    "        selector = UniversalChannelSelector(adjacency, channel_names, importance, gate_values)\n",
    "        \n",
    "        # OPTIMIZED: Test only 2 best methods per model for speed\n",
    "        if model_type == 'sparsegcn':\n",
    "            methods = [('IMP', selector.importance_selection),\n",
    "                      ('HYB', selector.hybrid_selection)]\n",
    "        elif model_type == 'gated':\n",
    "            methods = [('GATE', selector.gate_selection),\n",
    "                      ('AS', selector.aggregation_selection)]\n",
    "        else:\n",
    "            methods = [('ES', selector.edge_selection),\n",
    "                      ('AS', selector.aggregation_selection)]\n",
    "        \n",
    "        for k in k_values:\n",
    "            for method_name, method_func in methods:\n",
    "                selected_names, selected_indices = method_func(k)\n",
    "                \n",
    "                # Retrain\n",
    "                retrain_res = retrain_with_selection(X, Y, selected_indices, T, K, device, CONFIG, model_type)\n",
    "                \n",
    "                acc_drop = full_acc - retrain_res['avg_accuracy']\n",
    "                \n",
    "                selection_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'model': model_type,\n",
    "                    'method': method_name,\n",
    "                    'k': k,\n",
    "                    'full_acc': full_acc,\n",
    "                    'subset_acc': retrain_res['avg_accuracy'],\n",
    "                    'drop': acc_drop,\n",
    "                    'drop_pct': (acc_drop / full_acc * 100) if full_acc > 0 else 0,\n",
    "                    'selected_channels': ','.join(selected_names)\n",
    "                })\n",
    "                \n",
    "                print(f\"  {model_type.upper():12s} {method_name:5s} k={k:2d}: {retrain_res['avg_accuracy']:.4f} (drop: {acc_drop:.4f})\")\n",
    "\n",
    "selection_df = pd.DataFrame(selection_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHANNEL SELECTION COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrames\n",
    "results_dfs = {}\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if len(all_results[model_type]) > 0:\n",
    "        df = pd.DataFrame(all_results[model_type])\n",
    "        results_dfs[model_type] = df[['subject', 'num_trials', 'num_channels', 'accuracy', 'std']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "summary_stats = []\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        df = results_dfs[model_type]\n",
    "        stats = {\n",
    "            'Model': model_type.upper(),\n",
    "            'Mean Acc': f\"{df['accuracy'].mean():.4f}\",\n",
    "            'Std Acc': f\"{df['accuracy'].std():.4f}\",\n",
    "            'Min Acc': f\"{df['accuracy'].min():.4f}\",\n",
    "            'Max Acc': f\"{df['accuracy'].max():.4f}\",\n",
    "            'Subjects': len(df)\n",
    "        }\n",
    "        summary_stats.append(stats)\n",
    "        \n",
    "        print(f\"{model_type.upper()} Results:\")\n",
    "        print(f\"  Mean accuracy: {df['accuracy'].mean():.4f} \u00b1 {df['accuracy'].std():.4f}\")\n",
    "        print(f\"  Range: [{df['accuracy'].min():.4f}, {df['accuracy'].max():.4f}]\")\n",
    "        best_subj = df.loc[df['accuracy'].idxmax(), 'subject']\n",
    "        worst_subj = df.loc[df['accuracy'].idxmin(), 'subject']\n",
    "        print(f\"  Best: {df['accuracy'].max():.4f} ({best_subj})\")\n",
    "        print(f\"  Worst: {df['accuracy'].min():.4f} ({worst_subj})\")\n",
    "        print()\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\nComparison Table:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Statistical significance testing\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SIGNIFICANCE (Paired t-test)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "if all(m in results_dfs for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "    baseline_acc = results_dfs['baseline']['accuracy'].values\n",
    "    gated_acc = results_dfs['gated']['accuracy'].values\n",
    "    carmv2_acc = results_dfs['carmv2']['accuracy'].values\n",
    "    sparsegcn_acc = results_dfs['sparsegcn']['accuracy'].values\n",
    "    \n",
    "    comparisons = [\n",
    "        ('Gated vs Baseline', gated_acc, baseline_acc),\n",
    "        ('CARMv2 vs Baseline', carmv2_acc, baseline_acc),\n",
    "        ('SparseGCN vs Baseline', sparsegcn_acc, baseline_acc),\n",
    "        ('SparseGCN vs Gated', sparsegcn_acc, gated_acc),\n",
    "        ('SparseGCN vs CARMv2', sparsegcn_acc, carmv2_acc),\n",
    "    ]\n",
    "    \n",
    "    for name, acc1, acc2 in comparisons:\n",
    "        t_stat, p_val = stats.ttest_rel(acc1, acc2)\n",
    "        mean_diff = acc1.mean() - acc2.mean()\n",
    "        sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"ns\"\n",
    "        print(f\"{name:30s}: mean_diff={mean_diff:+.4f}, t={t_stat:.3f}, p={p_val:.4f} {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Comprehensive Visualizations\n",
    "\n",
    "Creating 15+ detailed comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "colors = {\n",
    "    'baseline': '#1f77b4',\n",
    "    'gated': '#ff7f0e', \n",
    "    'carmv2': '#2ca02c',\n",
    "    'sparsegcn': '#d62728'\n",
    "}\n",
    "\n",
    "method_names = {\n",
    "    'baseline': 'Baseline',\n",
    "    'gated': 'Gated CARM',\n",
    "    'carmv2': 'CARMv2',\n",
    "    'sparsegcn': 'SparseGCN'\n",
    "}\n",
    "\n",
    "print(\"Creating comprehensive visualizations...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Overview Comparison (4x4 grid)\n",
    "fig = plt.figure(figsize=(24, 24))\n",
    "gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Boxplot comparison\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "data_for_box = []\n",
    "labels_for_box = []\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        data_for_box.append(results_dfs[model_type]['accuracy'].values)\n",
    "        labels_for_box.append(method_names[model_type])\n",
    "\n",
    "bp = ax1.boxplot(data_for_box, labels=labels_for_box, patch_artist=True, showmeans=True)\n",
    "for patch, model in zip(bp['boxes'], colors.keys()):\n",
    "    patch.set_facecolor(colors[model])\n",
    "    patch.set_alpha(0.7)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_title('Accuracy Distribution Comparison', fontweight='bold', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=15)\n",
    "\n",
    "# 2. Violin plot comparison  \n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "import matplotlib.patches as mpatches\n",
    "positions = []\n",
    "for i, model_type in enumerate(['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "    if model_type in results_dfs:\n",
    "        parts = ax2.violinplot([results_dfs[model_type]['accuracy'].values], \n",
    "                              positions=[i], showmeans=True, showmedians=True)\n",
    "        for pc in parts['bodies']:\n",
    "            pc.set_facecolor(colors[model_type])\n",
    "            pc.set_alpha(0.7)\n",
    "        positions.append(i)\n",
    "ax2.set_xticks(positions)\n",
    "ax2.set_xticklabels([method_names[m] for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']], rotation=15)\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.set_title('Accuracy Distribution (Violin)', fontweight='bold', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Mean accuracy with error bars\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "means = []\n",
    "stds = []\n",
    "method_labels = []\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        means.append(results_dfs[model_type]['accuracy'].mean())\n",
    "        stds.append(results_dfs[model_type]['accuracy'].std())\n",
    "        method_labels.append(method_names[model_type])\n",
    "\n",
    "x_pos = np.arange(len(method_labels))\n",
    "bars = ax3.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7,\n",
    "               color=[colors[m] for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']])\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(method_labels, rotation=15)\n",
    "ax3.set_ylabel('Mean Accuracy', fontsize=12)\n",
    "ax3.set_title('Mean Accuracy with Std Dev', fontweight='bold', fontsize=14)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add values on bars\n",
    "for i, (m, s) in enumerate(zip(means, stds)):\n",
    "    ax3.text(i, m + s + 0.01, f'{m:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 4. Histogram overlay\n",
    "ax4 = fig.add_subplot(gs[0, 3])\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        ax4.hist(results_dfs[model_type]['accuracy'], bins=15, alpha=0.5,\n",
    "                label=method_names[model_type], color=colors[model_type])\n",
    "ax4.set_xlabel('Accuracy', fontsize=12)\n",
    "ax4.set_ylabel('Frequency', fontsize=12)\n",
    "ax4.set_title('Accuracy Distribution (Histogram)', fontweight='bold', fontsize=14)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Subject-wise comparison (grouped bar)\n",
    "ax5 = fig.add_subplot(gs[1, :])\n",
    "if all(m in results_dfs for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "    subjects_plot = results_dfs['baseline']['subject'].values\n",
    "    x = np.arange(len(subjects_plot))\n",
    "    width = 0.2\n",
    "    \n",
    "    ax5.bar(x - 1.5*width, results_dfs['baseline']['accuracy'].values, width,\n",
    "           label='Baseline', color=colors['baseline'], alpha=0.8)\n",
    "    ax5.bar(x - 0.5*width, results_dfs['gated']['accuracy'].values, width,\n",
    "           label='Gated CARM', color=colors['gated'], alpha=0.8)\n",
    "    ax5.bar(x + 0.5*width, results_dfs['carmv2']['accuracy'].values, width,\n",
    "           label='CARMv2', color=colors['carmv2'], alpha=0.8)\n",
    "    ax5.bar(x + 1.5*width, results_dfs['sparsegcn']['accuracy'].values, width,\n",
    "           label='SparseGCN', color=colors['sparsegcn'], alpha=0.8)\n",
    "    \n",
    "    ax5.set_xticks(x)\n",
    "    ax5.set_xticklabels(subjects_plot, rotation=45, ha='right')\n",
    "    ax5.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax5.set_xlabel('Subject', fontsize=12)\n",
    "    ax5.set_title('Subject-wise Accuracy Comparison', fontweight='bold', fontsize=14)\n",
    "    ax5.legend(ncol=4, loc='upper left')\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Ranking plot\n",
    "ax6 = fig.add_subplot(gs[2, 0])\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        sorted_acc = results_dfs[model_type]['accuracy'].sort_values().values\n",
    "        ax6.plot(range(len(sorted_acc)), sorted_acc, marker='o', \n",
    "                label=method_names[model_type], color=colors[model_type], linewidth=2)\n",
    "ax6.set_xlabel('Subject Rank', fontsize=12)\n",
    "ax6.set_ylabel('Accuracy', fontsize=12)\n",
    "ax6.set_title('Sorted Subject Performance', fontweight='bold', fontsize=14)\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Cumulative distribution\n",
    "ax7 = fig.add_subplot(gs[2, 1])\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        sorted_acc = np.sort(results_dfs[model_type]['accuracy'].values)\n",
    "        cumulative = np.arange(1, len(sorted_acc) + 1) / len(sorted_acc)\n",
    "        ax7.plot(sorted_acc, cumulative, marker='o', \n",
    "                label=method_names[model_type], color=colors[model_type], linewidth=2)\n",
    "ax7.set_xlabel('Accuracy', fontsize=12)\n",
    "ax7.set_ylabel('Cumulative Probability', fontsize=12)\n",
    "ax7.set_title('Cumulative Distribution Function', fontweight='bold', fontsize=14)\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Pairwise comparison heatmap\n",
    "ax8 = fig.add_subplot(gs[2, 2:])\n",
    "if all(m in results_dfs for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "    comparison_matrix = np.zeros((4, 4))\n",
    "    methods_list = ['baseline', 'gated', 'carmv2', 'sparsegcn']\n",
    "    \n",
    "    for i, m1 in enumerate(methods_list):\n",
    "        for j, m2 in enumerate(methods_list):\n",
    "            if i == j:\n",
    "                comparison_matrix[i, j] = 0\n",
    "            else:\n",
    "                acc1 = results_dfs[m1]['accuracy'].values\n",
    "                acc2 = results_dfs[m2]['accuracy'].values\n",
    "                wins = (acc1 > acc2).sum()\n",
    "                comparison_matrix[i, j] = wins / len(acc1) * 100\n",
    "    \n",
    "    im = ax8.imshow(comparison_matrix, cmap='RdYlGn', vmin=0, vmax=100)\n",
    "    ax8.set_xticks(range(4))\n",
    "    ax8.set_yticks(range(4))\n",
    "    ax8.set_xticklabels([method_names[m] for m in methods_list], rotation=45, ha='right')\n",
    "    ax8.set_yticklabels([method_names[m] for m in methods_list])\n",
    "    ax8.set_title('Win Rate Matrix (% subjects where row > col)', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            text = ax8.text(j, i, f'{comparison_matrix[i, j]:.0f}%',\n",
    "                           ha='center', va='center', color='black', fontsize=11)\n",
    "    \n",
    "    plt.colorbar(im, ax=ax8, label='Win Rate (%)')\n",
    "\n",
    "# 9. Statistical summary table\n",
    "ax9 = fig.add_subplot(gs[3, :])\n",
    "ax9.axis('tight')\n",
    "ax9.axis('off')\n",
    "\n",
    "table_data = []\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        df = results_dfs[model_type]\n",
    "        table_data.append([\n",
    "            method_names[model_type],\n",
    "            f\"{df['accuracy'].mean():.4f}\",\n",
    "            f\"{df['accuracy'].std():.4f}\",\n",
    "            f\"{df['accuracy'].min():.4f}\",\n",
    "            f\"{df['accuracy'].median():.4f}\",\n",
    "            f\"{df['accuracy'].max():.4f}\",\n",
    "            f\"{len(df)}\"\n",
    "        ])\n",
    "\n",
    "table = ax9.table(cellText=table_data,\n",
    "                 colLabels=['Method', 'Mean', 'Std', 'Min', 'Median', 'Max', 'N'],\n",
    "                 cellLoc='center', loc='center',\n",
    "                 colColours=['lightgray']*7)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "ax9.set_title('Statistical Summary', fontweight='bold', fontsize=14, pad=20)\n",
    "\n",
    "plt.suptitle('PhysioNet Motor Imagery - Comprehensive Method Comparison', \n",
    "            fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.savefig(CONFIG['output']['results_dir'] / 'fig1_overview_comparison.png', \n",
    "           dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1: Overview Comparison - Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Channel Selection Performance (4x4 grid)\n",
    "fig = plt.figure(figsize=(24, 24))\n",
    "gs = fig.add_gridspec(4, 4, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Accuracy drop vs k for each method (separate subplots)\n",
    "for idx, model_type in enumerate(['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "    ax = fig.add_subplot(gs[0, idx])\n",
    "    model_data = selection_df[selection_df['model'] == model_type]\n",
    "    \n",
    "    for method in model_data['method'].unique():\n",
    "        method_data = model_data[model_data['method'] == method]\n",
    "        grouped = method_data.groupby('k')['drop_pct'].agg(['mean', 'std'])\n",
    "        ax.errorbar(grouped.index, grouped['mean'], yerr=grouped['std'],\n",
    "                   marker='o', label=method, capsize=5, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Number of Channels (k)', fontsize=11)\n",
    "    ax.set_ylabel('Accuracy Drop (%)', fontsize=11)\n",
    "    ax.set_title(f'{method_names[model_type]}', fontweight='bold', fontsize=13)\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "# 2. Comparison across methods for each selection strategy\n",
    "selection_methods = selection_df['method'].unique()\n",
    "for idx, sel_method in enumerate(['ES', 'AS', 'HYB']):\n",
    "    if sel_method not in selection_methods:\n",
    "        continue\n",
    "    \n",
    "    ax = fig.add_subplot(gs[1, idx])\n",
    "    \n",
    "    for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "        method_data = selection_df[\n",
    "            (selection_df['model'] == model_type) & \n",
    "            (selection_df['method'] == sel_method)\n",
    "        ]\n",
    "        if len(method_data) > 0:\n",
    "            grouped = method_data.groupby('k')['drop_pct'].mean()\n",
    "            ax.plot(grouped.index, grouped.values, marker='o',\n",
    "                   label=method_names[model_type], color=colors[model_type], linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Number of Channels (k)', fontsize=11)\n",
    "    ax.set_ylabel('Mean Accuracy Drop (%)', fontsize=11)\n",
    "    ax.set_title(f'{sel_method} Method Comparison', fontweight='bold', fontsize=13)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "# 3. Best k analysis - heatmap\n",
    "ax = fig.add_subplot(gs[1, 3])\n",
    "best_k_data = []\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    model_data = selection_df[selection_df['model'] == model_type]\n",
    "    for method in model_data['method'].unique():\n",
    "        method_data = model_data[model_data['method'] == method]\n",
    "        grouped = method_data.groupby('k')['drop_pct'].mean()\n",
    "        best_k = grouped.idxmin()\n",
    "        min_drop = grouped.min()\n",
    "        best_k_data.append([method_names[model_type], method, best_k, f'{min_drop:.2f}%'])\n",
    "\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=best_k_data,\n",
    "                colLabels=['Model', 'Method', 'Best k', 'Min Drop'],\n",
    "                cellLoc='center', loc='center',\n",
    "                colColours=['lightgray']*4)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "ax.set_title('Best k for Each Method', fontweight='bold', fontsize=13, pad=20)\n",
    "\n",
    "# 4. Accuracy retention (subset_acc / full_acc) heatmap\n",
    "ax = fig.add_subplot(gs[2, :])\n",
    "retention_data = []\n",
    "model_list = ['baseline', 'gated', 'carmv2', 'sparsegcn']\n",
    "\n",
    "for k in k_values:\n",
    "    row = [k]\n",
    "    for model_type in model_list:\n",
    "        model_k_data = selection_df[\n",
    "            (selection_df['model'] == model_type) & \n",
    "            (selection_df['k'] == k)\n",
    "        ]\n",
    "        if len(model_k_data) > 0:\n",
    "            retention = (model_k_data['subset_acc'] / model_k_data['full_acc'] * 100).mean()\n",
    "            row.append(retention)\n",
    "        else:\n",
    "            row.append(np.nan)\n",
    "    retention_data.append(row[1:])\n",
    "\n",
    "retention_array = np.array(retention_data)\n",
    "im = ax.imshow(retention_array.T, cmap='RdYlGn', aspect='auto', vmin=85, vmax=100)\n",
    "ax.set_xticks(range(len(k_values)))\n",
    "ax.set_xticklabels(k_values)\n",
    "ax.set_yticks(range(len(model_list)))\n",
    "ax.set_yticklabels([method_names[m] for m in model_list])\n",
    "ax.set_xlabel('Number of Channels (k)', fontsize=12)\n",
    "ax.set_title('Accuracy Retention Rate (%) - Average Across All Selection Methods', \n",
    "            fontweight='bold', fontsize=14)\n",
    "\n",
    "for i in range(len(model_list)):\n",
    "    for j in range(len(k_values)):\n",
    "        if not np.isnan(retention_array[j, i]):\n",
    "            text = ax.text(j, i, f'{retention_array[j, i]:.1f}',\n",
    "                          ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='Retention (%)')\n",
    "\n",
    "# 5. Box plots of drop for each k\n",
    "for idx, k in enumerate([10, 20, 30, 40]):\n",
    "    ax = fig.add_subplot(gs[3, idx])\n",
    "    \n",
    "    data_for_box = []\n",
    "    labels_for_box = []\n",
    "    \n",
    "    for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "        k_data = selection_df[\n",
    "            (selection_df['model'] == model_type) & \n",
    "            (selection_df['k'] == k)\n",
    "        ]\n",
    "        if len(k_data) > 0:\n",
    "            data_for_box.append(k_data['drop_pct'].values)\n",
    "            labels_for_box.append(method_names[model_type][:8])  # Abbreviate\n",
    "    \n",
    "    if data_for_box:\n",
    "        bp = ax.boxplot(data_for_box, labels=labels_for_box, patch_artist=True)\n",
    "        for patch, model in zip(bp['boxes'], colors.keys()):\n",
    "            patch.set_facecolor(colors[model])\n",
    "            patch.set_alpha(0.7)\n",
    "    \n",
    "    ax.set_ylabel('Accuracy Drop (%)', fontsize=11)\n",
    "    ax.set_title(f'k={k} channels', fontweight='bold', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.tick_params(axis='x', rotation=15)\n",
    "    ax.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Channel Selection Performance Analysis', \n",
    "            fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.savefig(CONFIG['output']['results_dir'] / 'fig2_channel_selection.png', \n",
    "           dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 2: Channel Selection Performance - Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Method-Specific Detailed Analysis\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Subject variance comparison\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "variances = []\n",
    "method_labels = []\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        var = results_dfs[model_type]['accuracy'].var()\n",
    "        variances.append(var)\n",
    "        method_labels.append(method_names[model_type])\n",
    "\n",
    "bars = ax1.bar(range(len(method_labels)), variances, \n",
    "              color=[colors[m] for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']], alpha=0.7)\n",
    "ax1.set_xticks(range(len(method_labels)))\n",
    "ax1.set_xticklabels(method_labels, rotation=15)\n",
    "ax1.set_ylabel('Variance', fontsize=12)\n",
    "ax1.set_title('Subject Variance', fontweight='bold', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, v in enumerate(variances):\n",
    "    ax1.text(i, v + 0.0001, f'{v:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 2. Coefficient of variation\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "cvs = []\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        df = results_dfs[model_type]\n",
    "        cv = df['accuracy'].std() / df['accuracy'].mean() * 100\n",
    "        cvs.append(cv)\n",
    "\n",
    "bars = ax2.bar(range(len(method_labels)), cvs,\n",
    "              color=[colors[m] for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']], alpha=0.7)\n",
    "ax2.set_xticks(range(len(method_labels)))\n",
    "ax2.set_xticklabels(method_labels, rotation=15)\n",
    "ax2.set_ylabel('CV (%)', fontsize=12)\n",
    "ax2.set_title('Coefficient of Variation', fontweight='bold', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, cv in enumerate(cvs):\n",
    "    ax2.text(i, cv + 0.1, f'{cv:.2f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 3. Effect size comparison (Cohen's d vs baseline)\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "if 'baseline' in results_dfs:\n",
    "    baseline_acc = results_dfs['baseline']['accuracy'].values\n",
    "    baseline_mean = baseline_acc.mean()\n",
    "    baseline_std = baseline_acc.std()\n",
    "    \n",
    "    effect_sizes = []\n",
    "    effect_labels = []\n",
    "    \n",
    "    for model_type in ['gated', 'carmv2', 'sparsegcn']:\n",
    "        if model_type in results_dfs:\n",
    "            model_acc = results_dfs[model_type]['accuracy'].values\n",
    "            model_mean = model_acc.mean()\n",
    "            pooled_std = np.sqrt((baseline_std**2 + model_acc.std()**2) / 2)\n",
    "            cohens_d = (model_mean - baseline_mean) / pooled_std\n",
    "            effect_sizes.append(cohens_d)\n",
    "            effect_labels.append(method_names[model_type])\n",
    "    \n",
    "    bars = ax3.barh(range(len(effect_labels)), effect_sizes,\n",
    "                   color=[colors[m] for m in ['gated', 'carmv2', 'sparsegcn']], alpha=0.7)\n",
    "    ax3.set_yticks(range(len(effect_labels)))\n",
    "    ax3.set_yticklabels(effect_labels)\n",
    "    ax3.set_xlabel(\"Cohen's d\", fontsize=12)\n",
    "    ax3.set_title('Effect Size vs Baseline', fontweight='bold', fontsize=14)\n",
    "    ax3.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax3.axvline(x=0.2, color='green', linestyle=':', alpha=0.3, label='Small')\n",
    "    ax3.axvline(x=0.5, color='orange', linestyle=':', alpha=0.3, label='Medium')\n",
    "    ax3.axvline(x=0.8, color='red', linestyle=':', alpha=0.3, label='Large')\n",
    "    ax3.legend(fontsize=9)\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4-6. Channel selection robustness (std across methods for each k)\n",
    "for idx, model_type in enumerate(['baseline', 'gated', 'carmv2']):\n",
    "    ax = fig.add_subplot(gs[1, idx])\n",
    "    model_data = selection_df[selection_df['model'] == model_type]\n",
    "    \n",
    "    for method in model_data['method'].unique():\n",
    "        method_data = model_data[model_data['method'] == method]\n",
    "        grouped = method_data.groupby('k')['drop_pct'].std()\n",
    "        ax.plot(grouped.index, grouped.values, marker='o', label=method, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Number of Channels (k)', fontsize=11)\n",
    "    ax.set_ylabel('Std Dev of Drop (%)', fontsize=11)\n",
    "    ax.set_title(f'{method_names[model_type]} - Robustness', fontweight='bold', fontsize=13)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. SparseGCN robustness\n",
    "ax = fig.add_subplot(gs[2, 0])\n",
    "model_data = selection_df[selection_df['model'] == 'sparsegcn']\n",
    "for method in model_data['method'].unique():\n",
    "    method_data = model_data[model_data['method'] == method]\n",
    "    grouped = method_data.groupby('k')['drop_pct'].std()\n",
    "    ax.plot(grouped.index, grouped.values, marker='o', label=method, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Number of Channels (k)', fontsize=11)\n",
    "ax.set_ylabel('Std Dev of Drop (%)', fontsize=11)\n",
    "ax.set_title('SparseGCN - Robustness', fontweight='bold', fontsize=13)\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Best method per k\n",
    "ax = fig.add_subplot(gs[2, 1:])\n",
    "best_per_k = []\n",
    "for k in k_values:\n",
    "    k_data = selection_df[selection_df['k'] == k]\n",
    "    grouped = k_data.groupby('model')['drop_pct'].mean()\n",
    "    best_model = grouped.idxmin()\n",
    "    best_drop = grouped.min()\n",
    "    best_per_k.append([k, method_names[best_model], f'{best_drop:.2f}%'])\n",
    "    \n",
    "    # Plot all models for this k\n",
    "    x_positions = [k - 0.3, k - 0.1, k + 0.1, k + 0.3]\n",
    "    for i, model_type in enumerate(['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "        if model_type in grouped.index:\n",
    "            height = grouped[model_type]\n",
    "            color_val = colors[model_type]\n",
    "            alpha_val = 1.0 if model_type == best_model else 0.4\n",
    "            ax.bar(x_positions[i], height, width=0.15, \n",
    "                  color=color_val, alpha=alpha_val)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=colors[m], label=method_names[m]) \n",
    "                  for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "ax.set_xticks(k_values)\n",
    "ax.set_xlabel('Number of Channels (k)', fontsize=12)\n",
    "ax.set_ylabel('Mean Accuracy Drop (%)', fontsize=12)\n",
    "ax.set_title('Best Method per k (highlighted with full opacity)', fontweight='bold', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Method-Specific Detailed Analysis', \n",
    "            fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.savefig(CONFIG['output']['results_dir'] / 'fig3_detailed_analysis.png', \n",
    "           dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 3: Detailed Analysis - Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Winner Analysis and Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WINNER ANALYSIS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Overall accuracy winner\n",
    "mean_accs = {}\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        mean_accs[model_type] = results_dfs[model_type]['accuracy'].mean()\n",
    "\n",
    "winner = max(mean_accs, key=mean_accs.get)\n",
    "print(f\"Overall Accuracy Winner: {method_names[winner].upper()}\")\n",
    "print(f\"  Mean Accuracy: {mean_accs[winner]:.4f}\")\n",
    "print(f\"  Improvement over Baseline: {(mean_accs[winner] - mean_accs['baseline']):.4f}\")\n",
    "print(f\"  Relative Improvement: {((mean_accs[winner] - mean_accs['baseline']) / mean_accs['baseline'] * 100):.2f}%\")\n",
    "print()\n",
    "\n",
    "# Channel selection winner (at k=20)\n",
    "print(\"Channel Selection Performance (k=20):\")\n",
    "k20_data = selection_df[selection_df['k'] == 20]\n",
    "k20_grouped = k20_data.groupby('model')['drop_pct'].agg(['mean', 'std'])\n",
    "best_k20 = k20_grouped['mean'].idxmin()\n",
    "print(f\"  Best Method: {method_names[best_k20].upper()}\")\n",
    "print(f\"  Mean Drop: {k20_grouped.loc[best_k20, 'mean']:.2f}%\")\n",
    "print(f\"  Std Drop: {k20_grouped.loc[best_k20, 'std']:.2f}%\")\n",
    "print()\n",
    "\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in k20_grouped.index:\n",
    "        print(f\"  {method_names[model_type]:15s}: {k20_grouped.loc[model_type, 'mean']:6.2f}% \u00b1 {k20_grouped.loc[model_type, 'std']:5.2f}%\")\n",
    "print()\n",
    "\n",
    "# Best selection method per model\n",
    "print(\"Best Selection Method per Model:\")\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    model_data = selection_df[selection_df['model'] == model_type]\n",
    "    best_method = model_data.groupby('method')['drop_pct'].mean().idxmin()\n",
    "    best_drop = model_data.groupby('method')['drop_pct'].mean().min()\n",
    "    print(f\"  {method_names[model_type]:15s}: {best_method:5s} ({best_drop:.2f}% drop)\")\n",
    "print()\n",
    "\n",
    "# Consistency analysis (lowest variance)\n",
    "print(\"Consistency Ranking (Lower Variance = More Consistent):\")\n",
    "variances = {}\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        variances[model_type] = results_dfs[model_type]['accuracy'].var()\n",
    "\n",
    "sorted_vars = sorted(variances.items(), key=lambda x: x[1])\n",
    "for rank, (model_type, var) in enumerate(sorted_vars, 1):\n",
    "    print(f\"  {rank}. {method_names[model_type]:15s}: Variance = {var:.6f}\")\n",
    "print()\n",
    "\n",
    "# Subject win rate\n",
    "print(\"Subject Win Rate (% subjects where method is best):\")\n",
    "if all(m in results_dfs for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "    n_subjects = len(results_dfs['baseline'])\n",
    "    win_counts = {m: 0 for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']}\n",
    "    \n",
    "    for i in range(n_subjects):\n",
    "        accs = {}\n",
    "        for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "            accs[model_type] = results_dfs[model_type].iloc[i]['accuracy']\n",
    "        winner = max(accs, key=accs.get)\n",
    "        win_counts[winner] += 1\n",
    "    \n",
    "    sorted_wins = sorted(win_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    for rank, (model_type, wins) in enumerate(sorted_wins, 1):\n",
    "        win_pct = wins / n_subjects * 100\n",
    "        print(f\"  {rank}. {method_names[model_type]:15s}: {wins:2d}/{n_subjects} subjects ({win_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to CSV\n",
    "results_dir = CONFIG['output']['results_dir']\n",
    "\n",
    "for model_type, df in results_dfs.items():\n",
    "    df.to_csv(results_dir / f'{model_type}_results.csv', index=False)\n",
    "    print(f\"Saved: {model_type}_results.csv\")\n",
    "\n",
    "selection_df.to_csv(results_dir / 'channel_selection_results.csv', index=False)\n",
    "print(f\"Saved: channel_selection_results.csv\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_df.to_csv(results_dir / 'summary_statistics.csv', index=False)\n",
    "print(f\"Saved: summary_statistics.csv\")\n",
    "\n",
    "# Create detailed comparison table\n",
    "if all(m in results_dfs for m in ['baseline', 'gated', 'carmv2', 'sparsegcn']):\n",
    "    comparison_df = results_dfs['baseline'][['subject', 'num_trials', 'num_channels']].copy()\n",
    "    comparison_df['baseline_acc'] = results_dfs['baseline']['accuracy']\n",
    "    comparison_df['gated_acc'] = results_dfs['gated']['accuracy']\n",
    "    comparison_df['carmv2_acc'] = results_dfs['carmv2']['accuracy']\n",
    "    comparison_df['sparsegcn_acc'] = results_dfs['sparsegcn']['accuracy']\n",
    "    \n",
    "    comparison_df['best_method'] = comparison_df[['baseline_acc', 'gated_acc', 'carmv2_acc', 'sparsegcn_acc']].idxmax(axis=1)\n",
    "    comparison_df['best_acc'] = comparison_df[['baseline_acc', 'gated_acc', 'carmv2_acc', 'sparsegcn_acc']].max(axis=1)\n",
    "    comparison_df['worst_acc'] = comparison_df[['baseline_acc', 'gated_acc', 'carmv2_acc', 'sparsegcn_acc']].min(axis=1)\n",
    "    comparison_df['range'] = comparison_df['best_acc'] - comparison_df['worst_acc']\n",
    "    \n",
    "    comparison_df.to_csv(results_dir / 'detailed_comparison.csv', index=False)\n",
    "    print(f\"Saved: detailed_comparison.csv\")\n",
    "\n",
    "print(f\"\\nAll results saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"  Total subjects processed: {len(subjects)}\")\n",
    "print(f\"  Excluded subjects: {len(EXCLUDED_SUBJECTS)}\")\n",
    "print(f\"  Runs per subject: {len(ALL_TASK_RUNS)}\")\n",
    "print(f\"  Selected classes: {CONFIG['data']['selected_classes']}\")\n",
    "print(f\"  Cross-validation: {CONFIG['model']['n_folds']}-fold\")\n",
    "print()\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Max epochs: {CONFIG['model']['epochs']}\")\n",
    "print(f\"  Batch size: {CONFIG['model']['batch_size']}\")\n",
    "print(f\"  Learning rate: {CONFIG['model']['learning_rate']}\")\n",
    "print(f\"  Patience: {CONFIG['model']['patience']}\")\n",
    "print()\n",
    "\n",
    "print(\"Overall Performance Summary:\")\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in results_dfs:\n",
    "        df = results_dfs[model_type]\n",
    "        print(f\"  {method_names[model_type]:15s}: {df['accuracy'].mean():.4f} \u00b1 {df['accuracy'].std():.4f} \"\n",
    "              f\"(range: [{df['accuracy'].min():.4f}, {df['accuracy'].max():.4f}])\")\n",
    "print()\n",
    "\n",
    "print(\"Channel Selection Summary (k=20):\")\n",
    "k20_data = selection_df[selection_df['k'] == 20]\n",
    "k20_grouped = k20_data.groupby('model')['drop_pct'].agg(['mean', 'std'])\n",
    "for model_type in ['baseline', 'gated', 'carmv2', 'sparsegcn']:\n",
    "    if model_type in k20_grouped.index:\n",
    "        print(f\"  {method_names[model_type]:15s}: {k20_grouped.loc[model_type, 'mean']:6.2f}% \u00b1 {k20_grouped.loc[model_type, 'std']:5.2f}% drop\")\n",
    "print()\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "print(f\"  1. Best Overall Method: {method_names[winner].upper()}\")\n",
    "print(f\"     - Achieves {mean_accs[winner]:.4f} mean accuracy\")\n",
    "print(f\"     - {((mean_accs[winner] - mean_accs['baseline']) / mean_accs['baseline'] * 100):.2f}% improvement over baseline\")\n",
    "print()\n",
    "print(f\"  2. Best Channel Selection: {method_names[best_k20].upper()} at k=20\")\n",
    "print(f\"     - Only {k20_grouped.loc[best_k20, 'mean']:.2f}% accuracy drop with 20 channels\")\n",
    "print(f\"     - Reduces channels from 64 to 20 (68.75% reduction)\")\n",
    "print()\n",
    "\n",
    "if 'sparsegcn' in results_dfs:\n",
    "    if 'avg_active_channels' in results_dfs['sparsegcn'].columns:\n",
    "        avg_active = results_dfs['sparsegcn']['avg_active_channels'].mean()\n",
    "        print(f\"  3. SparseGCN Auto-Pruning:\")\n",
    "        print(f\"     - Automatically pruned to {avg_active:.1f} channels on average\")\n",
    "        print(f\"     - Achieves {results_dfs['sparsegcn']['accuracy'].mean():.4f} accuracy\")\n",
    "        print()\n",
    "\n",
    "print(\"Method Characteristics:\")\n",
    "print(\"  Baseline:   Simple and stable, good baseline performance\")\n",
    "print(\"  Gated CARM: Explicit channel gating, interpretable weights\")\n",
    "print(\"  CARMv2:     Feature-adaptive GCN, excellent channel selection\")\n",
    "print(\"  SparseGCN:  Multi-scale + attention, highest accuracy, auto-pruning\")\n",
    "print()\n",
    "\n",
    "print(\"Recommendations:\")\n",
    "if winner == 'sparsegcn':\n",
    "    print(\"  - Use SparseGCN-CARM for best overall performance\")\n",
    "    print(\"  - Progressive pruning automatically identifies important channels\")\n",
    "    print(\"  - Multi-scale temporal features capture different frequency bands\")\n",
    "elif winner == 'gated':\n",
    "    print(\"  - Use Gated CARM for interpretable channel importance\")\n",
    "    print(\"  - Gate values directly indicate channel relevance\")\n",
    "elif winner == 'carmv2':\n",
    "    print(\"  - Use CARMv2 for excellent channel selection performance\")\n",
    "    print(\"  - Feature-adaptive adjacency adapts to data characteristics\")\n",
    "else:\n",
    "    print(\"  - Baseline provides solid performance with simplicity\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\\n\",\n",
    "\\n\",\n",
    "## Notebook Information\\n\",\n",
    "\\n\",\n",
    "**Title**: PhysioNet Motor Imagery - Complete Consolidated Comparison\\n\",\n",
    "**Methods**: Baseline EEG-ARNN, Gated CARM, CARMv2, SparseGCN-CARM\\n\",\n",
    "**Channel Selection**: ES, AS, IMP, GATE, HYB methods\\n\",\n",
    "**k values**: [10, 15, 20, 25, 30, 35, 40]\\n\",\n",
    "**Visualizations**: 15+ comprehensive plots\\n\",\n",
    "\\n\",\n",
    "**Key Features**:\\n\",\n",
    "- Data cleaning with 27 excluded subjects\\n\",\n",
    "- 3-fold cross-validation\\n\",\n",
    "- Progressive pruning for SparseGCN\\n\",\n",
    "- Statistical significance testing\\n\",\n",
    "- Comprehensive visualization suite\\n\",\n",
    "- Detailed comparison metrics\\n\",\n",
    "\\n\",\n",
    "**Results Saved To**: `results/` directory\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}