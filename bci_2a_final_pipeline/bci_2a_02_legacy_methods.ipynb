{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# BCI Competition IV 2a Motor Imagery - Legacy Baseline Methods\n\n## Comprehensive Evaluation of 5 Baseline Methods + Channel Selection\n\nThis notebook trains and evaluates:\n1. **FBCSP** - Filter Bank Common Spatial Patterns with LDA\n2. **CNN-SAE** - CNN with Spatial Attention\n3. **EEGNet** - Compact convolutional network\n4. **ACS-SE-CNN** - Attention + Squeeze-Excitation CNN\n5. **G-CARM** - Graph-based CARM\n\n## Channel Selection Methods:\n- **FBCSP**: CSP pattern-based selection\n- **G-CARM**: Edge Selection (ES) / Aggregation Selection (AS)\n- **CNN-SAE, EEGNet, ACS-SE-CNN**: Gradient-based attribution\n\n## Configuration:\n- **30 epochs**, **0.002 LR**, **NO EARLY STOPPING** (for PyTorch models)\n- **9 subjects (A01-A09)**, **3-fold CV**\n- **4 classes**: 769 (left hand), 770 (right hand), 771 (feet), 772 (tongue)\n- **9 filter banks**, **4 CSP components** (for FBCSP)\n- **Channel Selection**: k=[5,8,10,12,15]\n\n## Metrics:\n- Accuracy, Precision, Recall, F1-Score, AUC-ROC (multi-class)\n\n## Output:\n- `bci_2a_legacy_*_results.csv` (full channel results)\n- `bci_2a_legacy_*_retrain_results.csv` (channel selection results)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from scipy.signal import butter, filtfilt\n",
    "import gc\n",
    "\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_context('notebook', font_scale=1.0)\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "def set_seed(s=42):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os",
    "from pathlib import Path",
    "",
    "if os.path.exists('/kaggle/input'):",
    "    print(\"Running on Kaggle\")",
    "    kaggle_input = Path('/kaggle/input')",
    "",
    "    # Try the specific BCI_2a subdirectory first",
    "    DATA_DIR = kaggle_input / 'bci-2a' / 'BCI_2a'",
    "    if DATA_DIR.exists():",
    "        print(f\"Found dataset at: {DATA_DIR}\")",
    "    else:",
    "        # Fallback to searching",
    "        datasets = [d for d in kaggle_input.iterdir() if d.is_dir()]",
    "        print(f\"Available datasets: {[d.name for d in datasets]}\")",
    "",
    "        DATA_DIR = None",
    "        possible_names = ['bci-2a', 'bci-competition-iv-2a']",
    "        for ds_name in possible_names:",
    "            test_path = kaggle_input / ds_name / 'BCI_2a'",
    "            if test_path.exists():",
    "                DATA_DIR = test_path",
    "                print(f\"Found dataset at: {DATA_DIR}\")",
    "                break",
    "            # Try without subdirectory",
    "            test_path = kaggle_input / ds_name",
    "            if test_path.exists():",
    "                DATA_DIR = test_path",
    "                print(f\"Found dataset at: {DATA_DIR}\")",
    "                break",
    "",
    "        if DATA_DIR is None and datasets:",
    "            DATA_DIR = datasets[0]",
    "            print(f\"Using first available dataset: {DATA_DIR}\")",
    "else:",
    "    print(\"Running locally\")",
    "    DATA_DIR = Path('../data/BCI_2a')",
    "",
    "CONFIG = {",
    "    'data': {",
    "        'raw_data_dir': DATA_DIR,",
    "        'selected_classes': [769, 770, 771, 772],",
    "        'tmin': 0.5,",
    "        'tmax': 4.5,",
    "        'baseline': (-0.5, 0)",
    "    },",
    "    'preprocessing': {",
    "        'l_freq': 0.5,",
    "        'h_freq': 40.0,",
    "        'notch_freq': 50.0,",
    "        'target_sfreq': 250.0,",
    "        'apply_car': True",
    "    },",
    "    'model': {",
    "        'epochs': 30,",
    "        'learning_rate': 0.002,",
    "        'batch_size': 64,",
    "        'n_folds': 3,",
    "        'patience': 999",
    "    },",
    "    'fbcsp': {",
    "        'freq_bands': [",
    "            (4, 8), (8, 12), (12, 16), (16, 20), (20, 24),",
    "            (24, 28), (28, 32), (32, 36), (36, 40)",
    "        ],",
    "        'n_components': 4",
    "    },",
    "    'channel_selection': {",
    "        'k_values': [5, 8, 10, 12, 15]",
    "    },",
    "    'output': {",
    "        'results_dir': Path('results'),",
    "    },",
    "    'max_subjects': 9,",
    "    'min_runs_per_subject': 2",
    "}",
    "",
    "CONFIG['output']['results_dir'].mkdir(exist_ok=True, parents=True)",
    "",
    "print(\"",
    "Configuration loaded!\")",
    "print(f\"Training: {CONFIG['max_subjects']} subjects, {CONFIG['model']['n_folds']}-fold CV, {CONFIG['model']['epochs']} epochs\")",
    "print(f\"Learning rate: {CONFIG['model']['learning_rate']}, No early stopping (patience={CONFIG['model']['patience']})\")",
    "print(f\"FBCSP: {len(CONFIG['fbcsp']['freq_bands'])} filter banks, {CONFIG['fbcsp']['n_components']} components\")",
    "print(f\"Channel selection k values: {CONFIG['channel_selection']['k_values']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Data Loading and Preprocessing Functions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"No excluded subjects for BCI 2a dataset - all 9 subjects (A01-A09) are clean\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw(raw, config):",
    "    cleaned_names = {name: name.rstrip('.') for name in raw.ch_names}",
    "    raw.rename_channels(cleaned_names)",
    "    raw.pick_types(eeg=True)",
    "    raw.set_montage('standard_1020', on_missing='ignore', match_case=False)",
    "    ",
    "    nyquist = raw.info['sfreq'] / 2.0",
    "    if config['preprocessing']['notch_freq'] < nyquist:",
    "        raw.notch_filter(freqs=config['preprocessing']['notch_freq'], verbose=False)",
    "    ",
    "    raw.filter(",
    "        l_freq=config['preprocessing']['l_freq'],",
    "        h_freq=config['preprocessing']['h_freq'],",
    "        method='fir',",
    "        fir_design='firwin',",
    "        verbose=False",
    "    )",
    "    ",
    "    if config['preprocessing']['apply_car']:",
    "        raw.set_eeg_reference('average', projection=False, verbose=False)",
    "    ",
    "    raw.resample(config['preprocessing']['target_sfreq'], npad='auto', verbose=False)",
    "    return raw",
    "",
    "",
    "def load_and_preprocess_gdf(gdf_path, config):",
    "    raw = mne.io.read_raw_gdf(gdf_path, preload=True, verbose='ERROR')",
    "    raw = preprocess_raw(raw, config)",
    "    ",
    "    events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')",
    "    ",
    "    # Remove duplicate event timestamps",
    "    unique_times, unique_idx = np.unique(events[:, 0], return_index=True)",
    "    events = events[unique_idx]",
    "    ",
    "    if len(events) == 0:",
    "        return None, None, raw.ch_names",
    "    ",
    "    epochs = mne.Epochs(",
    "        raw,",
    "        events,",
    "        event_id=event_ids,",
    "        tmin=config['data']['tmin'],",
    "        tmax=config['data']['tmax'],",
    "        baseline=tuple(config['data']['baseline']),",
    "        preload=True,",
    "        verbose='ERROR'",
    "    )",
    "    ",
    "    return epochs.get_data(), epochs.events[:, 2], raw.ch_names",
    "",
    "",
    "def filter_classes(x, y, selected_classes):",
    "    mask = np.isin(y, selected_classes)",
    "    y, x = y[mask], x[mask]",
    "    label_map = {old: new for new, old in enumerate(sorted(selected_classes))}",
    "    y = np.array([label_map[int(label)] for label in y], dtype=np.int64)",
    "    return x, y",
    "",
    "",
    "def normalize(x):",
    "    mu = x.mean(axis=(0, 2), keepdims=True)",
    "    sd = x.std(axis=(0, 2), keepdims=True) + 1e-8",
    "    return (x - mu) / sd",
    "",
    "",
    "def load_subject_data(data_dir, subject_id, run_ids, config):",
    "    if not data_dir.exists():",
    "        return None, None, None",
    "    ",
    "    all_x, all_y = [], []",
    "    channel_names = None",
    "    ",
    "    for run_id in run_ids:",
    "        gdf_path = data_dir / f'{subject_id}{run_id}.gdf'",
    "        if not gdf_path.exists():",
    "            continue",
    "        ",
    "        try:",
    "            x, y, ch_names = load_and_preprocess_gdf(gdf_path, config)",
    "            if x is None or len(y) == 0:",
    "                continue",
    "            ",
    "            x, y = filter_classes(x, y, config['data']['selected_classes'])",
    "            if len(y) == 0:",
    "                continue",
    "            ",
    "            channel_names = channel_names or ch_names",
    "            all_x.append(x)",
    "            all_y.append(y)",
    "        except Exception as e:",
    "            print(f\"  Warning: Failed to load {gdf_path.name}: {e}\")",
    "            continue",
    "    ",
    "    if len(all_x) == 0:",
    "        return None, None, channel_names",
    "    ",
    "    return np.concatenate(all_x, 0), np.concatenate(all_y, 0), channel_names",
    "",
    "",
    "def get_available_subjects(data_dir, min_runs=2):",
    "    if not data_dir.exists():",
    "        raise ValueError(f\"Data directory not found: {data_dir}\")",
    "    ",
    "    subjects = []",
    "    ",
    "    for subject_id in ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09']:",
    "        gdf_files = list(data_dir.glob(f'{subject_id}*.gdf'))",
    "        if len(gdf_files) >= min_runs:",
    "            subjects.append(subject_id)",
    "    ",
    "    return subjects",
    "",
    "",
    "print(\"",
    "Scanning for subjects...\")",
    "data_dir = CONFIG['data']['raw_data_dir']",
    "print(f\"Looking for data in: {data_dir}\")",
    "",
    "all_subjects = get_available_subjects(",
    "    data_dir, ",
    "    min_runs=CONFIG['min_runs_per_subject']",
    ")",
    "subjects = all_subjects[:CONFIG['max_subjects']]",
    "",
    "print(f\"Found {len(all_subjects)} subjects with >= {CONFIG['min_runs_per_subject']} runs\")",
    "print(f\"Will process {len(subjects)} subjects: {subjects}\")",
    "",
    "ALL_TASK_RUNS = ['T', 'E']",
    "print(f\"Using runs: {ALL_TASK_RUNS} (T=training, E=evaluation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.FloatTensor(x).unsqueeze(1)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef calculate_comprehensive_metrics(model, dataloader, device):\n    model.eval()\n    all_preds, all_labels, all_probs = [], [], []\n\n    for X_batch, y_batch in dataloader:\n        X_batch = X_batch.to(device)\n        outputs = model(X_batch)\n        probs = torch.softmax(outputs, dim=1)\n        _, predicted = torch.max(outputs, 1)\n\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(y_batch.numpy())\n        all_probs.extend(probs.cpu().numpy())\n\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    all_probs = np.array(all_probs)\n\n    metrics = {\n        'accuracy': accuracy_score(all_labels, all_preds),\n        'precision': precision_score(all_labels, all_preds, average='macro', zero_division=0),\n        'recall': recall_score(all_labels, all_preds, average='macro', zero_division=0),\n        'f1_score': f1_score(all_labels, all_preds, average='macro', zero_division=0),\n    }\n    \n    try:\n        metrics['auc_roc'] = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro') if len(np.unique(all_labels)) > 1 else 0.0\n    except:\n        metrics['auc_roc'] = 0.0\n\n    return metrics\n\n\ndef calculate_sklearn_metrics(y_true, y_pred):\n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n        'recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n        'f1_score': f1_score(y_true, y_pred, average='macro', zero_division=0),\n        'auc_roc': 0.0,\n    }\n\n    return metrics\n\n\nprint(\"Comprehensive metrics functions defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 FBCSP"
   ]
  },
  {
   "cell_type": "code",
   "source": "class FBCSP:\n    def __init__(self, freq_bands, n_components=4, sfreq=250.0):\n        self.freq_bands = freq_bands\n        self.n_components = n_components\n        self.sfreq = sfreq\n        self.csps = []\n        self.lda = LinearDiscriminantAnalysis()\n    \n    def _bandpass_filter(self, data, low_freq, high_freq):\n        nyquist = self.sfreq / 2.0\n        low = low_freq / nyquist\n        high = high_freq / nyquist\n        b, a = butter(5, [low, high], btype='band')\n        return filtfilt(b, a, data, axis=-1)\n    \n    def fit(self, X, y):\n        self.csps = []\n        all_features = []\n        \n        for low_freq, high_freq in self.freq_bands:\n            X_filtered = self._bandpass_filter(X.copy(), low_freq, high_freq)\n            \n            csp = CSP(n_components=self.n_components, reg='ledoit_wolf', log=True, norm_trace=False)\n            csp.fit(X_filtered, y)\n            self.csps.append(csp)\n            \n            features = csp.transform(X_filtered)\n            all_features.append(features)\n        \n        all_features = np.concatenate(all_features, axis=1)\n        self.lda.fit(all_features, y)\n        return self\n    \n    def predict(self, X):\n        all_features = []\n        \n        for idx, (low_freq, high_freq) in enumerate(self.freq_bands):\n            X_filtered = self._bandpass_filter(X.copy(), low_freq, high_freq)\n            features = self.csps[idx].transform(X_filtered)\n            all_features.append(features)\n        \n        all_features = np.concatenate(all_features, axis=1)\n        return self.lda.predict(all_features)\n\nprint(\"FBCSP defined!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    for x, y in dataloader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        logits = model(x)\n        loss = criterion(logits, y)\n\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        all_preds += torch.argmax(logits, 1).cpu().tolist()\n        all_labels += y.cpu().tolist()\n    \n    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n\n\n@torch.no_grad()\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    all_preds, all_labels = [], []\n    \n    for x, y in dataloader:\n        x, y = x.to(device), y.to(device)\n        logits = model(x)\n        loss = criterion(logits, y)\n        \n        total_loss += loss.item()\n        all_preds += torch.argmax(logits, 1).cpu().tolist()\n        all_labels += y.cpu().tolist()\n    \n    return total_loss / max(1, len(dataloader)), accuracy_score(all_labels, all_preds)\n\n\ndef train_model(model, train_loader, val_loader, device, epochs, lr, patience, verbose=True):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=3, verbose=False\n    )\n    \n    best_acc = 0.0\n    best_state = None\n    no_improve = 0\n    \n    epoch_iterator = tqdm(range(epochs), desc='    Epochs', leave=False) if verbose else range(epochs)\n    \n    for epoch in epoch_iterator:\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n        \n        scheduler.step(val_loss)\n        \n        if verbose:\n            epoch_iterator.set_postfix({\n                'train_loss': f'{train_loss:.4f}',\n                'train_acc': f'{train_acc:.4f}',\n                'val_loss': f'{val_loss:.4f}',\n                'val_acc': f'{val_acc:.4f}',\n                'best': f'{best_acc:.4f}'\n            })\n        \n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_state = deepcopy(model.state_dict())\n            no_improve = 0\n        else:\n            no_improve += 1\n        \n        if no_improve >= patience:\n            if verbose:\n                print(f'      Early stopping at epoch {epoch+1}/{epochs}')\n            break\n    \n    if best_state is None:\n        best_state = deepcopy(model.state_dict())\n    \n    model.load_state_dict(best_state)\n    return best_state, best_acc\n\n\nprint(\"Training functions defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 CNN-SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(n_channels, n_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_channels // 4, n_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pooled = torch.mean(x, dim=2)\n",
    "        weights = self.attention(pooled)\n",
    "        return x * weights.unsqueeze(2)\n",
    "\n",
    "\n",
    "class CNNSAE(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769):\n",
    "        super().__init__()\n",
    "        self.spatial_attention = SpatialAttention(n_channels)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.spatial_attention(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 4:\n",
    "            x = x.squeeze(1)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "print(\"CNN-SAE defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769, F1=8, D=2, F2=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, F1, (1, 64), padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(F1)\n",
    "        self.conv2 = nn.Conv2d(F1, F1*D, (n_channels, 1), groups=F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(F1*D)\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv3 = nn.Conv2d(F1*D, F2, (1, 16), padding=(0, 8), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(F2)\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, 1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "\n",
    "        self.fc = nn.Linear(flattened_size, n_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.dropout1(self.pool1(F.elu(self.bn2(self.conv2(x)))))\n",
    "        x = self.dropout2(self.pool2(F.elu(self.bn3(self.conv3(x)))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "print(\"EEGNet defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 ACS-SE-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, max(1, channels // reduction))\n",
    "        self.fc2 = nn.Linear(max(1, channels // reduction), channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        squeeze = torch.mean(x, dim=2)\n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation))\n",
    "        return x * excitation.unsqueeze(2)\n",
    "\n",
    "\n",
    "class ACSECNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769):\n",
    "        super().__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Linear(n_timepoints, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.se1 = SEBlock(n_channels)\n",
    "        self.se2 = SEBlock(128)\n",
    "        self.se3 = SEBlock(256)\n",
    "        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.zeros(1, n_channels, n_timepoints)\n",
    "            test_output = self._forward_features(test_input)\n",
    "            flattened_size = test_output.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        channel_weights = []\n",
    "        for i in range(x.size(1)):\n",
    "            w = self.channel_attention(x[:, i, :])\n",
    "            channel_weights.append(w)\n",
    "        channel_weights = torch.cat(channel_weights, dim=1)\n",
    "        x = x * channel_weights.unsqueeze(2)\n",
    "        x = self.se1(x)\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.se2(x)\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.se3(x)\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 4:\n",
    "            x = x.squeeze(1)\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "print(\"ACS-SE-CNN defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 G-CARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class CARMBlock(nn.Module):\n    def __init__(self, n_channels):\n        super().__init__()\n        self.A = nn.Parameter(torch.randn(n_channels, n_channels) * 0.01)\n\n    def forward(self, x):\n        A_norm = torch.softmax(self.A, dim=1)\n        x_reshaped = x.permute(0, 2, 1)\n        x_graph = torch.matmul(x_reshaped, A_norm.t())\n        return x_graph.permute(0, 2, 1)\n    \n    def get_adjacency(self):\n        with torch.no_grad():\n            return torch.sigmoid(self.A).cpu().numpy()\n\n\nclass GCARM(nn.Module):\n    def __init__(self, n_channels=64, n_classes=2, n_timepoints=769):\n        super().__init__()\n        self.carm1 = CARMBlock(n_channels)\n        self.carm2 = CARMBlock(n_channels)\n        self.conv1 = nn.Conv1d(n_channels, 128, kernel_size=5, padding=2)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(2)\n        self.conv2 = nn.Conv1d(128, 256, kernel_size=5, padding=2)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.pool2 = nn.MaxPool1d(2)\n        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm1d(512)\n        self.pool3 = nn.MaxPool1d(2)\n        self.dropout = nn.Dropout(0.5)\n\n        with torch.no_grad():\n            test_input = torch.zeros(1, n_channels, n_timepoints)\n            test_output = self._forward_features(test_input)\n            flattened_size = test_output.view(1, -1).size(1)\n\n        self.fc1 = nn.Linear(flattened_size, 256)\n        self.fc2 = nn.Linear(256, n_classes)\n\n    def _forward_features(self, x):\n        x = self.carm1(x)\n        x = self.carm2(x)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        return x\n\n    def forward(self, x):\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = self._forward_features(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)\n    \n    def get_final_adjacency(self):\n        return self.carm2.get_adjacency()\n\nprint(\"G-CARM defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef compute_gradient_attribution(model, X, Y, device):\n    model.eval()\n    model.to(device)\n    \n    X_tensor = torch.FloatTensor(X).unsqueeze(1).to(device)\n    X_tensor.requires_grad = True\n    \n    outputs = model(X_tensor)\n    target_class = Y[0]\n    \n    grad_scores = []\n    for i in range(len(X)):\n        if X_tensor.grad is not None:\n            X_tensor.grad.zero_()\n        \n        output = model(X_tensor[i:i+1])\n        score = output[0, target_class]\n        score.backward()\n        \n        if X_tensor.grad is not None:\n            grad = X_tensor.grad[i].abs()\n            channel_importance = grad.squeeze(0).mean(dim=1).cpu().numpy()\n            grad_scores.append(channel_importance)\n    \n    if len(grad_scores) == 0:\n        return np.zeros(X.shape[1])\n    \n    return np.mean(np.stack(grad_scores, 0), 0)\n\n\nclass ChannelSelectorLegacy:\n    def __init__(self, channel_names, model_name, **kwargs):\n        self.names = np.array(channel_names)\n        self.C = len(channel_names)\n        self.model_name = model_name\n        \n        if model_name == 'fbcsp':\n            self.csp_importance = kwargs.get('csp_importance')\n        elif model_name == 'g_carm':\n            self.adjacency = kwargs.get('adjacency')\n        else:\n            self.gradient_scores = kwargs.get('gradient_scores')\n    \n    def select_channels(self, k, method='default'):\n        if self.model_name == 'fbcsp':\n            importance = self.csp_importance\n        elif self.model_name == 'g_carm':\n            if method == 'ES':\n                importance = self._edge_selection_scores()\n            else:\n                importance = self._aggregation_selection_scores()\n        else:\n            importance = self.gradient_scores\n        \n        indices = np.sort(np.argsort(importance)[-int(k):])\n        return self.names[indices].tolist(), indices\n    \n    def _edge_selection_scores(self):\n        edge_importance = np.zeros(self.C)\n        for i in range(self.C):\n            for j in range(self.C):\n                if i != j:\n                    edge_importance[i] += abs(self.adjacency[i, j])\n                    edge_importance[j] += abs(self.adjacency[i, j])\n        return edge_importance\n    \n    def _aggregation_selection_scores(self):\n        return np.sum(np.abs(self.adjacency), 1)\n\n\ndef retrain_legacy_model(X, Y, selected_indices, model_name, config, device):\n    X_selected = X[:, selected_indices, :]\n    C, T = X_selected.shape[1], X_selected.shape[2]\n    K = len(set(config['data']['selected_classes']))\n    \n    skf = StratifiedKFold(n_splits=config['model']['n_folds'], shuffle=True, random_state=42)\n    fold_results = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X_selected, Y)):\n        X_train, X_val = X_selected[train_idx], X_selected[val_idx]\n        Y_train, Y_val = Y[train_idx], Y[val_idx]\n        \n        if model_name == 'fbcsp':\n            model = FBCSP(\n                freq_bands=config['fbcsp']['freq_bands'],\n                n_components=config['fbcsp']['n_components'],\n                sfreq=config['preprocessing']['target_sfreq']\n            )\n            model.fit(X_train, Y_train)\n            y_pred = model.predict(X_val)\n            metrics = calculate_sklearn_metrics(Y_val, y_pred)\n            fold_results.append(metrics)\n        else:\n            X_train_norm = normalize(X_train)\n            X_val_norm = normalize(X_val)\n            \n            train_loader = DataLoader(\n                EEGDataset(X_train_norm, Y_train),\n                batch_size=config['model']['batch_size'],\n                shuffle=True,\n                num_workers=0\n            )\n            val_loader = DataLoader(\n                EEGDataset(X_val_norm, Y_val),\n                batch_size=config['model']['batch_size'],\n                shuffle=False,\n                num_workers=0\n            )\n            \n            if model_name == 'cnn_sae':\n                model = CNNSAE(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n            elif model_name == 'eegnet':\n                model = EEGNet(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n            elif model_name == 'acs_se_cnn':\n                model = ACSECNN(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n            elif model_name == 'g_carm':\n                model = GCARM(n_channels=C, n_classes=K, n_timepoints=T).to(device)\n            \n            best_state, best_acc = train_model(\n                model, train_loader, val_loader, device,\n                config['model']['epochs'],\n                config['model']['learning_rate'],\n                config['model']['patience'],\n                verbose=False\n            )\n            model.load_state_dict(best_state)\n            \n            metrics = calculate_comprehensive_metrics(model, val_loader, device)\n            fold_results.append(metrics)\n            \n            del model\n            torch.cuda.empty_cache()\n            gc.collect()\n    \n    avg_metrics = {}\n    for key in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']:\n        values = [f[key] for f in fold_results]\n        avg_metrics[f'avg_{key}'] = float(np.mean(values))\n        avg_metrics[f'std_{key}'] = float(np.std(values))\n    \n    return avg_metrics\n\n\nprint(\"Channel selection functions defined!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {",
    "    'fbcsp': [],",
    "    'cnn_sae': [],",
    "    'eegnet': [],",
    "    'acs_se_cnn': [],",
    "    'g_carm': []",
    "}",
    "",
    "print(\"\\nStarting training for legacy methods...\\n\")",
    "",
    "for subject_id in tqdm(subjects, desc='Training subjects'):",
    "    print(f\"\\nProcessing {subject_id}...\")",
    "    ",
    "    X, Y, channel_names = load_subject_data(",
    "        data_dir,",
    "        subject_id,",
    "        ALL_TASK_RUNS,",
    "        CONFIG",
    "    )",
    "    ",
    "    if X is None or len(Y) == 0:",
    "        print(f\"  Skipped: No data available\")",
    "        continue",
    "    ",
    "    C, T = X.shape[1], X.shape[2]",
    "    K = len(set(CONFIG['data']['selected_classes']))",
    "    ",
    "    print(f\"  Data shape: {X.shape}\")",
    "    print(f\"  Label distribution: {np.bincount(Y)}\")",
    "    ",
    "    for model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:",
    "        print(f\"\\n  Training {model_name.upper()}...\")",
    "        ",
    "        skf = StratifiedKFold(n_splits=CONFIG['model']['n_folds'], shuffle=True, random_state=42)",
    "        fold_results = []",
    "        fold_models = []",
    "        fold_csp_patterns = []",
    "        fold_adjacencies = []",
    "        ",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, Y)):",
    "            X_train, X_val = X[train_idx], X[val_idx]",
    "            Y_train, Y_val = Y[train_idx], Y[val_idx]",
    "            ",
    "            if model_name == 'fbcsp':",
    "                model = FBCSP(",
    "                    freq_bands=CONFIG['fbcsp']['freq_bands'],",
    "                    n_components=CONFIG['fbcsp']['n_components'],",
    "                    sfreq=CONFIG['preprocessing']['target_sfreq']",
    "                )",
    "                model.fit(X_train, Y_train)",
    "                y_pred = model.predict(X_val)",
    "                metrics = calculate_sklearn_metrics(Y_val, y_pred)",
    "                fold_results.append(metrics)",
    "                ",
    "                csp_patterns = []",
    "                for csp in model.csps:",
    "                    patterns = csp.patterns_",
    "                    csp_patterns.append(np.abs(patterns).mean(axis=1))",
    "                avg_csp_importance = np.mean(np.stack(csp_patterns, 0), 0)",
    "                fold_csp_patterns.append(avg_csp_importance)",
    "                fold_models.append(model)",
    "                ",
    "            else:",
    "                X_train_norm = normalize(X_train)",
    "                X_val_norm = normalize(X_val)",
    "                ",
    "                train_loader = DataLoader(",
    "                    EEGDataset(X_train_norm, Y_train),",
    "                    batch_size=CONFIG['model']['batch_size'],",
    "                    shuffle=True,",
    "                    num_workers=0",
    "                )",
    "                val_loader = DataLoader(",
    "                    EEGDataset(X_val_norm, Y_val),",
    "                    batch_size=CONFIG['model']['batch_size'],",
    "                    shuffle=False,",
    "                    num_workers=0",
    "                )",
    "                ",
    "                if model_name == 'cnn_sae':",
    "                    model = CNNSAE(n_channels=C, n_classes=K, n_timepoints=T).to(device)",
    "                elif model_name == 'eegnet':",
    "                    model = EEGNet(n_channels=C, n_classes=K, n_timepoints=T).to(device)",
    "                elif model_name == 'acs_se_cnn':",
    "                    model = ACSECNN(n_channels=C, n_classes=K, n_timepoints=T).to(device)",
    "                elif model_name == 'g_carm':",
    "                    model = GCARM(n_channels=C, n_classes=K, n_timepoints=T).to(device)",
    "                ",
    "                best_state, best_acc = train_model(",
    "                    model, train_loader, val_loader, device,",
    "                    CONFIG['model']['epochs'],",
    "                    CONFIG['model']['learning_rate'],",
    "                    CONFIG['model']['patience']",
    "                )",
    "                model.load_state_dict(best_state)",
    "                ",
    "                metrics = calculate_comprehensive_metrics(model, val_loader, device)",
    "                fold_results.append(metrics)",
    "                ",
    "                if model_name == 'g_carm':",
    "                    adjacency = model.get_final_adjacency()",
    "                    fold_adjacencies.append(adjacency)",
    "                ",
    "                fold_models.append(deepcopy(model).cpu())",
    "                ",
    "                del model",
    "                torch.cuda.empty_cache()",
    "                gc.collect()",
    "        ",
    "        avg_metrics = {}",
    "        for key in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']:",
    "            values = [f[key] for f in fold_results]",
    "            avg_metrics[f'avg_{key}'] = float(np.mean(values))",
    "            avg_metrics[f'std_{key}'] = float(np.std(values))",
    "        ",
    "        result = {",
    "            'subject': subject_id,",
    "            'num_trials': X.shape[0],",
    "            'num_channels': C,",
    "            **avg_metrics,",
    "            'channel_names': channel_names,",
    "            'fold_models': fold_models",
    "        }",
    "        ",
    "        if model_name == 'fbcsp':",
    "            result['csp_importance'] = np.mean(np.stack(fold_csp_patterns, 0), 0)",
    "        elif model_name == 'g_carm':",
    "            result['adjacency_matrix'] = np.mean(np.stack(fold_adjacencies, 0), 0)",
    "        ",
    "        all_results[model_name].append(result)",
    "        ",
    "        print(f\"    Accuracy: {avg_metrics['avg_accuracy']:.4f} \u00c2\u00b1 {avg_metrics['std_accuracy']:.4f}\")",
    "        print(f\"    F1-Score: {avg_metrics['avg_f1_score']:.4f} \u00c2\u00b1 {avg_metrics['std_f1_score']:.4f}\")",
    "",
    "print(\"\\n\" + \"=\"*80)",
    "print(\"Training Complete!\")",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "source": "retrain_results = {\n    'fbcsp': [],\n    'cnn_sae': [],\n    'eegnet': [],\n    'acs_se_cnn': [],\n    'g_carm': []\n}\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"CHANNEL SELECTION AND RETRAINING\")\nprint(\"=\"*80 + \"\\n\")\n\nfor subject_id in tqdm(subjects, desc='Retraining with channel selection'):\n    print(f\"\\nProcessing {subject_id}...\")\n    \n    X, Y, channel_names = load_subject_data(\n        data_dir,\n        subject_id,\n        ALL_TASK_RUNS,\n        CONFIG\n    )\n    \n    if X is None:\n        continue\n    \n    for model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n        subj_result = None\n        for res in all_results[model_name]:\n            if res['subject'] == subject_id:\n                subj_result = res\n                break\n        \n        if subj_result is None:\n            continue\n        \n        print(f\"\\n  {model_name.upper()} channel selection...\")\n        \n        if model_name == 'fbcsp':\n            selector = ChannelSelectorLegacy(\n                channel_names, model_name,\n                csp_importance=subj_result['csp_importance']\n            )\n            methods = ['default']\n            \n        elif model_name == 'g_carm':\n            selector = ChannelSelectorLegacy(\n                channel_names, model_name,\n                adjacency=subj_result['adjacency_matrix']\n            )\n            methods = ['ES', 'AS']\n            \n        else:\n            X_norm = normalize(X)\n            fold_models = subj_result['fold_models']\n            \n            gradient_scores_list = []\n            for model in fold_models:\n                model_gpu = model.to(device)\n                grad_scores = compute_gradient_attribution(model_gpu, X_norm[:10], Y[:10], device)\n                gradient_scores_list.append(grad_scores)\n                del model_gpu\n                torch.cuda.empty_cache()\n            \n            avg_gradient_scores = np.mean(np.stack(gradient_scores_list, 0), 0)\n            \n            selector = ChannelSelectorLegacy(\n                channel_names, model_name,\n                gradient_scores=avg_gradient_scores\n            )\n            methods = ['default']\n        \n        for method in methods:\n            for k in CONFIG['channel_selection']['k_values']:\n                method_label = f'{model_name.upper()}-{method}' if method != 'default' else model_name.upper()\n                \n                selected_channels, selected_indices = selector.select_channels(k, method)\n                \n                retrain_metrics = retrain_legacy_model(\n                    X, Y, selected_indices, model_name, CONFIG, device\n                )\n                \n                acc_drop = subj_result['avg_accuracy'] - retrain_metrics['avg_accuracy']\n                \n                retrain_results[model_name].append({\n                    'subject': subject_id,\n                    'method': method if method != 'default' else model_name.upper(),\n                    'k': k,\n                    'num_channels_selected': len(selected_channels),\n                    **retrain_metrics,\n                    'full_channels_acc': subj_result['avg_accuracy'],\n                    'accuracy_drop': acc_drop,\n                    'accuracy_drop_pct': (acc_drop / subj_result['avg_accuracy'] * 100) if subj_result['avg_accuracy'] > 0 else 0.0\n                })\n                \n                print(f\"    {method_label}, k={k}: {retrain_metrics['avg_accuracy']:.4f} (drop: {acc_drop:.4f})\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Channel Selection Complete!\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "results_dir = CONFIG['output']['results_dir']\n\nfor model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n    if len(all_results[model_name]) > 0:\n        df = pd.DataFrame([{\n            'subject': r['subject'],\n            'num_trials': r['num_trials'],\n            'num_channels': r['num_channels'],\n            'accuracy': r['avg_accuracy'],\n            'std_accuracy': r['std_accuracy'],\n            'precision': r['avg_precision'],\n            'std_precision': r['std_precision'],\n            'recall': r['avg_recall'],\n            'std_recall': r['std_recall'],\n            'f1_score': r['avg_f1_score'],\n            'std_f1_score': r['std_f1_score'],\n            'auc_roc': r['avg_auc_roc'],\n            'std_auc_roc': r['std_auc_roc'],\n            'specificity': r['avg_specificity'],\n            'std_specificity': r['std_specificity']\n        } for r in all_results[model_name]])\n        \n        df.to_csv(results_dir / f'legacy_{model_name}_results.csv', index=False)\n        print(f\"Saved: legacy_{model_name}_results.csv\")\n\nfor model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n    if len(retrain_results[model_name]) > 0:\n        df = pd.DataFrame(retrain_results[model_name])\n        df.to_csv(results_dir / f'legacy_{model_name}_retrain_results.csv', index=False)\n        print(f\"Saved: legacy_{model_name}_retrain_results.csv\")\n\nprint(f\"\\nAll results saved to {results_dir}\")",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Channel Selection Functions",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "results_dir = CONFIG['output']['results_dir']\n\nfor model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n    if len(all_results[model_name]) > 0:\n        df = pd.DataFrame([{\n            'subject': r['subject'],\n            'num_trials': r['num_trials'],\n            'num_channels': r['num_channels'],\n            'accuracy': r['avg_accuracy'],\n            'std_accuracy': r['std_accuracy'],\n            'precision': r['avg_precision'],\n            'std_precision': r['std_precision'],\n            'recall': r['avg_recall'],\n            'std_recall': r['std_recall'],\n            'f1_score': r['avg_f1_score'],\n            'std_f1_score': r['std_f1_score'],\n            'auc_roc': r['avg_auc_roc'],\n            'std_auc_roc': r['std_auc_roc']\n        } for r in all_results[model_name]])\n        \n        df.to_csv(results_dir / f'bci_2a_legacy_{model_name}_results.csv', index=False)\n        print(f\"Saved: bci_2a_legacy_{model_name}_results.csv\")\n\nprint(f\"\\nAll results saved to {results_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for model_name in ['fbcsp', 'cnn_sae', 'eegnet', 'acs_se_cnn', 'g_carm']:\n",
    "    if len(all_results[model_name]) > 0:\n",
    "        accs = [r['avg_accuracy'] for r in all_results[model_name]]\n",
    "        f1s = [r['avg_f1_score'] for r in all_results[model_name]]\n",
    "        aucs = [r['avg_auc_roc'] for r in all_results[model_name]]\n",
    "        \n",
    "        print(f\"{model_name.upper()} Results:\")\n",
    "        print(f\"  Subjects: {len(all_results[model_name])}\")\n",
    "        print(f\"  Mean accuracy: {np.mean(accs):.4f} \u00c2\u00b1 {np.std(accs):.4f}\")\n",
    "        print(f\"  Mean F1-Score: {np.mean(f1s):.4f} \u00c2\u00b1 {np.std(f1s):.4f}\")\n",
    "        print(f\"  Mean AUC-ROC: {np.mean(aucs):.4f} \u00c2\u00b1 {np.std(aucs):.4f}\")\n",
    "        print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DONE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}