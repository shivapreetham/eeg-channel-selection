Implementation Notes: Multi-Dataset EEG MI Graph-Net (Target >=92% Acc)
-----------------------------------------------------------------------

Objective & Metrics
- Deliver >=92% macro-averaged validation accuracy on BCI 2a, BCI 2b, and PhysioNet motor imagery while using <=40% of channels after selection.
- Track balanced accuracy, macro-F1, and confusion matrices per subject; require no class to fall below 0.88 recall on held-out subjects.
- Support reproducible cross-subject evaluation: LOSO (leave-one-subject-out) and 5-fold group splits with fixed RNG seeds (42, 1337, 2025).

Dataset Coverage
- BCI Competition IV 2a: subjects A01-A09, motor imagery runs T, 4-class task.
- BCI Competition IV 2b: subjects B01-B09, runs 01T-03T, 2-class task.
- PhysioNet MI (EEG Motor Movement/Imagery): subjects S001-S109 (drop S088, S092, S100, S104 if corrupted), runs R03, R04, R07, R08, 2-class task.
- Harmonise metadata (channel names, montage, sampling rate) keeping full cohorts; the notebook currently truncates to the first 2-3 subjects and should be expanded to the full lists above.

Pre-processing & Augmentation Pipeline
- Resample all recordings to 128 Hz with MNE's mne.filter.resample; PhysioNet (160 Hz) -> 128 Hz, BCI 2a (250 Hz) -> 128 Hz, BCI 2b (250 Hz) -> 128 Hz.
- Apply zero-phase band-pass 4-38 Hz, plus 50/60 Hz notch depending on subject locale; retain filter coefficients for reproducibility.
- Re-reference to common average, then run automated ICA (FastICA) removing eye/muscle components per subject using variance ratios (>=0.8).
- Epoch windows: [-0.5, 4.0] seconds aligned to cue; discard trials with absolute amplitude >120 microvolts after filtering.
- Standardise per subject using RobustScaler (median/IQR) then z-score across training fold only; store transformer for validation/test.
- Augment training trials: random temporal jitter (±40 ms), narrow-band amplitude scaling (mu: 8-12 Hz, beta: 18-26 Hz), Gaussian noise (SNR >= 25 dB), mixup (α=0.2) and CutMix (time-axis only).
- Oversample underrepresented classes via augmentation before batching; maintain class_weight for residual imbalance.

Graph Construction & Channel Priors
- Initialise adjacency A0 from 3D sensor coordinates (MNE standard_1005); weight edges by exp(-d^2 / (2σ^2)) with σ=35 mm and keep top-12 neighbours per node.
- Learn residual adjacency ΔA with constraints: symmetric, zero diagonal, L1 penalty 1e-4, Frobenius budget ||ΔA||_F <= 0.5 * ||A0||_F enforced via projection each epoch.
- Build Laplacian L = D^{-1/2}(A0 + ΔA)D^{-1/2}; cache dense and sparse forms.
- Apply edge dropout (rate 0.2) during training to prevent over-reliance on single connections.
- For PhysioNet's 64 channels, compress to 32 most central channels using aggregated degree scores before model input, keeping mapping for inverse transform.

Model: Temporal-Graph Hybrid (EEG-ARNN+)
- Temporal Feature Extraction Module (TFEM+): three depthwise-separable Conv1D branches with kernel sizes {16, 32, 64}, dilation rates {1, 2, 4}; concatenate, batch-norm, ELU, channel squeeze & excitation, dropout 0.3.
- Channel Active Reasoning Module (CARM+): two-layer Chebyshev graph convolution (order 3) followed by graph attention (GATv2) using learned adjacency; residual add & layer norm.
- Repeat TFEM+/CARM+ stack three times with widening factors [1.0, 1.5, 2.0]; include stochastic depth (survival 0.85).
- Shared bottleneck: global average pooling over time, graph-aware pooling (TopKPooling with k=0.6) over channels, concatenate pooled embeddings.
- Classification head: Dense(128, elu) + dropout 0.4 + Dense(num_classes, softmax).
- Multi-task auxiliary heads: subject-ID prediction (for adversarial alignment using gradient reversal, λ=0.2) and band-power regression (mu/beta power) to stabilise feature learning.

Optimization & Training Curriculum
- Stage 1 (pre-training): train on merged dataset (all subjects) with subject-balanced sampler, batch size 48, OneCycle LR schedule (max_lr 1.5e-3, final_lr 1e-5), weight decay 1e-4, gradient clipping 1.5.
- Stage 2 (dataset-specific fine-tune): initialise from Stage 1 weights, fine-tune separately for each dataset with reduced max_lr 5e-4, patience 15, freeze first TFEM+/CARM+ block for first 5 epochs.
- Stage 3 (subject adaptation): optional fine-tune last block + classifier for each subject using 10% labelled trials and mixup to mitigate overfitting.
- Losses: CE with label smoothing 0.05 + adjacency regulariser + adversarial loss (gradient reversal) + auxiliary regression (Huber). Total loss weights: [1.0, 0.1, 0.2, 0.05].
- Use EMA (decay 0.999) of model weights for evaluation checkpoints; save best EMA model per validation metric.

Evaluation & Reporting
- Primary split: LOSO per dataset (train on N-1 subjects, validate on held-out subject). Aggregate metrics across subjects and report mean ± std.
- Secondary split: stratified 5-fold group CV (subject as group) for cross-dataset pre-training sanity check.
- Produce per-class metrics, ROC/PR curves, calibration plots, and channel attention heatmaps.
- Channel selection: compute edge scores |w_ij|+|w_ji| and node scores sum_j |w_ij|; select top-K (K=12 for BCI 2a, 8 for BCI 2b, 16 for PhysioNet). Re-train model on reduced channels and verify accuracy drop <1.5%.
- Statistical testing: paired t-test vs current CNN/GCN baselines on LOSO accuracies (α=0.05).

Notebook Action Items
- Expand DATASETS dict to include full subject lists and expose config flags for LOSO/GroupKFold.
- Replace manual numpy batching with tf.data pipeline that applies augmentation, caching, shuffling, and prefetching.
- Implement adjacency initialisation from sensor positions (store in dataset_store) and pass to model builder.
- Add Stage 1/Stage 2 training loops with checkpoints, EMA tracking, and resume capability.
- Log metrics to TensorBoard + JSON for reproducibility; include scripts to compute aggregated reports.
- Visualise learned adjacency deltas and channel importances per dataset for interpretability.

Key Differences vs Current Notebook
- Current notebook samples only first 2-3 subjects and relies on weak graph augmentation; new plan trains on every available subject with rigorous splits.
- CNN/GCN baselines are replaced with a multi-scale temporal + graph attention hybrid tuned for MI rhythms.
- Training is multi-stage with curriculum, augmentation, and regularisation specifically aimed at pushing validation accuracy beyond 92% while keeping sensors minimal.
