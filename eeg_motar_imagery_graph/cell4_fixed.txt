# Cell 4: Build Complete EEG-ARNN Architecture (FIXED for Keras Functional API)

print("ğŸ—ï¸ Building Complete EEG-ARNN Architecture")
print("=" * 45)

def create_eeg_arnn(input_shape, num_classes, num_channels, name="EEG_ARNN"):
    """
    Create the complete EEG-ARNN architecture as described in the paper.

    Architecture:
    Input â†’ TFEM-CARM Block 1 â†’ TFEM-CARM Block 2 â†’ TFEM-CARM Block 3 â†’
    Final TFEM â†’ Flatten â†’ Dense â†’ Output

    Parameters:
    -----------
    input_shape : tuple
        (num_channels, num_timepoints)
    num_classes : int
        Number of motor imagery classes
    num_channels : int
        Number of EEG channels
    """

    print(f"\nğŸ”§ Building {name} with Graph Neural Networks...")
    print(f"Input shape: {input_shape}")
    print(f"Channels: {num_channels}, Classes: {num_classes}")

    # Input layer
    input_layer = layers.Input(shape=input_shape, name='eeg_input')
    print(f"ğŸ“¥ Input layer: {input_shape}")

    # TFEM-CARM Block 1
    print("ğŸ”§ Building TFEM-CARM Block 1...")
    tfem1 = TFEM(filters=16, kernel_size=16, dropout_rate=0.25, name='tfem_1')
    carm1 = CARM(num_channels=num_channels, output_dim=16, dropout_rate=0.25, name='carm_1')

    x = tfem1(input_layer)
    x = carm1(x)

    # Average pooling to reduce temporal dimension - use Lambda for tensor operations
    x = layers.Lambda(lambda t: tf.transpose(t, [0, 2, 1]), name='transpose_1')(x)
    x = layers.GlobalAveragePooling1D(name='avg_pool_1')(x)
    x = layers.Lambda(lambda t: tf.expand_dims(t, axis=-1), name='expand_1')(x)
    x = layers.Lambda(lambda t: tf.transpose(t, [0, 1, 2]), name='transpose_1b')(x)

    # TFEM-CARM Block 2
    print("ğŸ”§ Building TFEM-CARM Block 2...")
    tfem2 = TFEM(filters=32, kernel_size=8, dropout_rate=0.3, name='tfem_2')
    carm2 = CARM(num_channels=num_channels, output_dim=32, dropout_rate=0.3, name='carm_2')

    x = tfem2(x)
    x = carm2(x)

    # Average pooling
    x = layers.Lambda(lambda t: tf.transpose(t, [0, 2, 1]), name='transpose_2')(x)
    x = layers.GlobalAveragePooling1D(name='avg_pool_2')(x)
    x = layers.Lambda(lambda t: tf.expand_dims(t, axis=-1), name='expand_2')(x)
    x = layers.Lambda(lambda t: tf.transpose(t, [0, 1, 2]), name='transpose_2b')(x)

    # TFEM-CARM Block 3
    print("ğŸ”§ Building TFEM-CARM Block 3...")
    tfem3 = TFEM(filters=64, kernel_size=4, dropout_rate=0.4, name='tfem_3')
    carm3 = CARM(num_channels=num_channels, output_dim=64, dropout_rate=0.4, name='carm_3')

    x = tfem3(x)
    x = carm3(x)

    # Final TFEM for channel fusion
    print("ğŸ”§ Building Final TFEM...")
    # Spatial convolution to fuse channel information - use Lambda for transpose
    x = layers.Lambda(lambda t: tf.transpose(t, [0, 2, 1]), name='transpose_final')(x)
    x = layers.Conv1D(filters=128, kernel_size=1, activation='elu', name='channel_fusion')(x)
    x = layers.BatchNormalization(name='bn_fusion')(x)
    x = layers.Dropout(0.5, name='dropout_fusion')(x)

    # Global pooling and classification
    x = layers.GlobalAveragePooling1D(name='global_pool')(x)

    # Classification head
    x = layers.Dense(256, name='dense_1')(x)
    x = layers.BatchNormalization(name='bn_dense_1')(x)
    x = layers.Activation('elu', name='elu_dense_1')(x)
    x = layers.Dropout(0.5, name='dropout_dense_1')(x)

    x = layers.Dense(128, name='dense_2')(x)
    x = layers.BatchNormalization(name='bn_dense_2')(x)
    x = layers.Activation('elu', name='elu_dense_2')(x)
    x = layers.Dropout(0.5, name='dropout_dense_2')(x)

    # Output layer
    output = layers.Dense(num_classes, activation='softmax', name='classification_output')(x)

    # Create model
    model = models.Model(inputs=input_layer, outputs=output, name=name)

    print("âœ… EEG-ARNN architecture completed!")
    return model

def create_simplified_graph_cnn(input_shape, num_classes, num_channels, name="Simple_GraphCNN"):
    """
    Create a simplified Graph CNN for comparison.

    This version focuses on the core graph convolution concept
    with a simpler architecture for educational purposes.
    """

    print(f"\nğŸ”§ Building {name} (Simplified version)...")

    # Input
    input_layer = layers.Input(shape=input_shape, name='eeg_input')

    # Single TFEM-CARM block
    tfem = TFEM(filters=32, kernel_size=16, dropout_rate=0.25, name='tfem_simple')
    carm = CARM(num_channels=num_channels, output_dim=32, dropout_rate=0.25, name='carm_simple')

    x = tfem(input_layer)
    x = carm(x)

    # Global pooling and classification - use Lambda for transpose
    x = layers.Lambda(lambda t: tf.transpose(t, [0, 2, 1]), name='transpose_simple')(x)
    x = layers.GlobalAveragePooling1D(name='global_pool')(x)

    # Simple classification head
    x = layers.Dense(128, activation='elu', name='dense_simple')(x)
    x = layers.Dropout(0.5, name='dropout_simple')(x)

    output = layers.Dense(num_classes, activation='softmax', name='output_simple')(x)

    model = models.Model(inputs=input_layer, outputs=output, name=name)

    print("âœ… Simplified Graph CNN completed!")
    return model

# Build models if we have data
if epochs_list and len(epochs_list) > 0:
    sample_epochs = epochs_list[0]
    data_shape = sample_epochs.get_data().shape

    num_channels = data_shape[1]
    num_timepoints = data_shape[2]
    num_classes = len(sample_epochs.event_id)

    input_shape = (num_channels, num_timepoints)

    print(f"\nğŸ“Š Model Configuration:")
    print(f"Input shape: {input_shape}")
    print(f"Number of channels: {num_channels}")
    print(f"Number of classes: {num_classes}")
    print(f"Class names: {list(sample_epochs.event_id.keys())}")

    # Create models
    graph_models = {}

    # Full EEG-ARNN
    try:
        eeg_arnn = create_eeg_arnn(input_shape, num_classes, num_channels)
        eeg_arnn.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        graph_models['EEG_ARNN'] = eeg_arnn
    except Exception as e:
        print(f"âŒ Failed to create EEG-ARNN: {e}")
        import traceback
        traceback.print_exc()

    # Simplified Graph CNN
    try:
        simple_gcnn = create_simplified_graph_cnn(input_shape, num_classes, num_channels)
        simple_gcnn.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        graph_models['Simple_GraphCNN'] = simple_gcnn
    except Exception as e:
        print(f"âŒ Failed to create Simple Graph CNN: {e}")
        import traceback
        traceback.print_exc()

    if graph_models:
        print(f"\nğŸ† Successfully created {len(graph_models)} Graph CNN models!")

        # Display model summaries
        for name, model in graph_models.items():
            print(f"\n{'-'*50}")
            print(f"ğŸ“‹ {name} ARCHITECTURE")
            print(f"{'-'*50}")
            model.summary()
            print(f"ğŸ“Š Parameters: {model.count_params():,}")
    else:
        print("âŒ No Graph CNN models created successfully")
        graph_models = {}

else:
    print("âŒ Cannot create models - no epoch data available")
    graph_models = {}
    input_shape = None
    num_channels = 0
