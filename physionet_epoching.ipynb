{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# PhysioNet Motor Imagery - Epoching and Trial Extraction\n",
    "\n",
    "This notebook extracts motor imagery trials from preprocessed PhysioNet data following the methodology from:\n",
    "**Sun et al. (2023) - Graph Convolution Neural Network Based End-to-End Channel Selection**\n",
    "\n",
    "## Pipeline:\n",
    "1. Load preprocessed FIF files (128 Hz, 0.5-40 Hz filtered, CAR referenced)\n",
    "2. Extract events from annotations (T1: left fist, T2: right fist)\n",
    "3. Create epochs with proper time windows\n",
    "4. Apply baseline correction\n",
    "5. Reject bad epochs based on amplitude criteria\n",
    "6. Export to NumPy format for deep learning\n",
    "\n",
    "## Parameters from Paper:\n",
    "- Epoch window: -1.0 to 5.0 seconds (relative to cue onset)\n",
    "- Baseline: -0.5 to 0.0 seconds\n",
    "- Rejection criteria: EEG > 100 μV, flat < 1 μV\n",
    "- Binary classification: Left fist (T1) vs Right fist (T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "DATA_ROOT = Path('data/physionet')\n",
    "DERIVED_DIR = DATA_ROOT / 'derived'\n",
    "PREPROCESSED_DIR = DERIVED_DIR / 'preprocessed'\n",
    "EPOCHS_DIR = DERIVED_DIR / 'epochs'\n",
    "EPOCHS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INDEX_PATH = DERIVED_DIR / 'physionet_preprocessed_index.csv'\n",
    "assert INDEX_PATH.exists(), 'Run preprocessing notebook first'\n",
    "\n",
    "print(f\"Loading preprocessed index from: {INDEX_PATH}\")\n",
    "preprocessed_df = pd.read_csv(INDEX_PATH)\n",
    "print(f\"Found {len(preprocessed_df)} preprocessed runs\")\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Epoching Configuration\n",
    "\n",
    "Following the paper's specifications for PhysioNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "epoch_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHING_CONFIG = {\n",
    "    'tmin': -1.0,  # Start 1 second before cue\n",
    "    'tmax': 5.0,   # End 5 seconds after cue (total 6 seconds)\n",
    "    'baseline': (-0.5, 0),  # Baseline correction window\n",
    "    'reject_criteria': {'eeg': 100e-6},  # Reject if amplitude > 100 μV\n",
    "    'flat_criteria': {'eeg': 1e-6},  # Reject if amplitude < 1 μV\n",
    "    'event_id': {'T1': 1, 'T2': 2},  # T1=left fist, T2=right fist\n",
    "    'picks': 'eeg',\n",
    "    'preload': True\n",
    "}\n",
    "\n",
    "print(\"Epoching Configuration:\")\n",
    "for key, value in EPOCHING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "epoch_functions",
   "metadata": {},
   "source": [
    "## Epoching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_epochs_from_run(fif_path, config):\n",
    "    \"\"\"\n",
    "    Extract motor imagery epochs from a preprocessed FIF file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fif_path : Path\n",
    "        Path to preprocessed FIF file\n",
    "    config : dict\n",
    "        Epoching configuration\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    epochs_info : dict\n",
    "        Dictionary with epoching results and metadata\n",
    "    \"\"\"\n",
    "    fif_path = Path(fif_path)\n",
    "    \n",
    "    epochs_info = {\n",
    "        'subject': fif_path.parent.name,\n",
    "        'run': fif_path.stem.split('_')[0][-3:],\n",
    "        'status': 'processing',\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Load preprocessed data\n",
    "        raw = mne.io.read_raw_fif(fif_path, preload=True, verbose='ERROR')\n",
    "        \n",
    "        epochs_info['sfreq'] = raw.info['sfreq']\n",
    "        epochs_info['n_channels'] = len(raw.ch_names)\n",
    "        epochs_info['duration_s'] = raw.times[-1]\n",
    "        \n",
    "        # Extract events from annotations\n",
    "        events, event_dict = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        \n",
    "        # Filter for T1 and T2 events only (left/right fist)\n",
    "        valid_events = ['T1', 'T2']\n",
    "        event_id = {k: v for k, v in event_dict.items() if k in valid_events}\n",
    "        \n",
    "        if len(event_id) == 0:\n",
    "            epochs_info['status'] = 'skipped'\n",
    "            epochs_info['reason'] = 'No T1/T2 events found'\n",
    "            return epochs_info\n",
    "        \n",
    "        epochs_info['events_found'] = {k: int((events[:, 2] == v).sum()) for k, v in event_id.items()}\n",
    "        epochs_info['total_events'] = sum(epochs_info['events_found'].values())\n",
    "        \n",
    "        # Create epochs\n",
    "        epochs = mne.Epochs(\n",
    "            raw,\n",
    "            events,\n",
    "            event_id=event_id,\n",
    "            tmin=config['tmin'],\n",
    "            tmax=config['tmax'],\n",
    "            baseline=config['baseline'],\n",
    "            picks=config['picks'],\n",
    "            preload=config['preload'],\n",
    "            reject=config['reject_criteria'],\n",
    "            flat=config['flat_criteria'],\n",
    "            verbose='ERROR'\n",
    "        )\n",
    "        \n",
    "        epochs_info['n_epochs_before_rejection'] = len(epochs.events)\n",
    "        \n",
    "        # Drop bad epochs\n",
    "        epochs.drop_bad()\n",
    "        \n",
    "        epochs_info['n_epochs_after_rejection'] = len(epochs)\n",
    "        epochs_info['rejection_rate'] = (epochs_info['n_epochs_before_rejection'] - \n",
    "                                          epochs_info['n_epochs_after_rejection']) / epochs_info['n_epochs_before_rejection']\n",
    "        \n",
    "        if len(epochs) == 0:\n",
    "            epochs_info['status'] = 'failed'\n",
    "            epochs_info['error'] = 'All epochs rejected'\n",
    "            return epochs_info\n",
    "        \n",
    "        # Get epoch data and labels\n",
    "        data = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "        labels = epochs.events[:, 2]  # Event codes\n",
    "        \n",
    "        # Convert labels to 0/1 (T1=0, T2=1)\n",
    "        label_map = {event_id['T1']: 0, event_id['T2']: 1}\n",
    "        labels = np.array([label_map[l] for l in labels])\n",
    "        \n",
    "        epochs_info['label_distribution'] = {\n",
    "            'left_fist': int((labels == 0).sum()),\n",
    "            'right_fist': int((labels == 1).sum())\n",
    "        }\n",
    "        \n",
    "        # Save epochs as NPZ\n",
    "        out_dir = EPOCHS_DIR / epochs_info['subject']\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = out_dir / f\"{epochs_info['subject']}{epochs_info['run']}_epo.npz\"\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            out_path,\n",
    "            data=data,\n",
    "            labels=labels,\n",
    "            ch_names=epochs.ch_names,\n",
    "            sfreq=epochs.info['sfreq'],\n",
    "            times=epochs.times\n",
    "        )\n",
    "        \n",
    "        epochs_info['output_path'] = str(out_path)\n",
    "        epochs_info['data_shape'] = data.shape\n",
    "        epochs_info['file_size_mb'] = out_path.stat().st_size / (1024 * 1024)\n",
    "        epochs_info['status'] = 'success'\n",
    "        \n",
    "    except Exception as e:\n",
    "        epochs_info['status'] = 'error'\n",
    "        epochs_info['error'] = str(e)\n",
    "    \n",
    "    return epochs_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_processing",
   "metadata": {},
   "source": [
    "## Batch Epoching\n",
    "\n",
    "Process all motor imagery runs (exclude resting state R01/R02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch_epoch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for motor imagery runs only (exclude resting state)\n",
    "mi_runs = preprocessed_df[\n",
    "    (preprocessed_df['category'] == 'motor_imagery') | \n",
    "    (preprocessed_df['category'] == 'motor_execution')\n",
    "].copy()\n",
    "\n",
    "print(f\"Processing {len(mi_runs)} motor imagery/execution runs...\\n\")\n",
    "\n",
    "epoch_records = []\n",
    "error_records = []\n",
    "\n",
    "for _, row in tqdm(mi_runs.iterrows(), total=len(mi_runs), desc='Epoching'):\n",
    "    try:\n",
    "        result = extract_epochs_from_run(row['path'], EPOCHING_CONFIG)\n",
    "        \n",
    "        result.update({\n",
    "            'category': row['category'],\n",
    "            'task': row.get('task', '')\n",
    "        })\n",
    "        \n",
    "        if result['status'] == 'error':\n",
    "            error_records.append(result)\n",
    "        else:\n",
    "            epoch_records.append(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_records.append({\n",
    "            'subject': row['subject'],\n",
    "            'run': row['run'],\n",
    "            'status': 'error',\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "epochs_df = pd.DataFrame(epoch_records)\n",
    "errors_df = pd.DataFrame(error_records)\n",
    "\n",
    "# Save index\n",
    "EPOCH_INDEX_PATH = DERIVED_DIR / 'physionet_epochs_index.csv'\n",
    "epochs_df.to_csv(EPOCH_INDEX_PATH, index=False)\n",
    "\n",
    "if len(errors_df) > 0:\n",
    "    ERROR_PATH = DERIVED_DIR / 'physionet_epoching_errors.csv'\n",
    "    errors_df.to_csv(ERROR_PATH, index=False)\n",
    "    print(f\"\\nErrors occurred: {len(errors_df)}\")\n",
    "    print(f\"Error log saved to: {ERROR_PATH}\")\n",
    "\n",
    "print(f\"\\nEpoching complete!\")\n",
    "print(f\"  - Successfully epoched: {len(epochs_df)}\")\n",
    "print(f\"  - Errors: {len(errors_df)}\")\n",
    "print(f\"  - Index saved to: {EPOCH_INDEX_PATH}\")\n",
    "\n",
    "epochs_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality_check",
   "metadata": {},
   "source": [
    "## Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(epochs_df) > 0:\n",
    "    # Parse label distribution\n",
    "    epochs_df['left_fist_count'] = epochs_df['label_distribution'].apply(\n",
    "        lambda x: eval(x)['left_fist'] if isinstance(x, str) else x['left_fist']\n",
    "    )\n",
    "    epochs_df['right_fist_count'] = epochs_df['label_distribution'].apply(\n",
    "        lambda x: eval(x)['right_fist'] if isinstance(x, str) else x['right_fist']\n",
    "    )\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Epochs per run\n",
    "    axes[0, 0].hist(epochs_df['n_epochs_after_rejection'], bins=20, \n",
    "                    color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].set_title('Distribution of Epochs per Run', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Number of Epochs')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rejection rate\n",
    "    axes[0, 1].hist(epochs_df['rejection_rate'] * 100, bins=20, \n",
    "                    color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_title('Epoch Rejection Rate', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Rejection Rate (%)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Label balance\n",
    "    label_data = pd.DataFrame({\n",
    "        'Class': ['Left Fist'] * len(epochs_df) + ['Right Fist'] * len(epochs_df),\n",
    "        'Count': list(epochs_df['left_fist_count']) + list(epochs_df['right_fist_count'])\n",
    "    })\n",
    "    sns.boxplot(data=label_data, x='Class', y='Count', ax=axes[1, 0], palette='Set2')\n",
    "    axes[1, 0].set_title('Label Distribution per Run', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Epochs per Class')\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Epochs by category\n",
    "    category_counts = epochs_df.groupby('category')['n_epochs_after_rejection'].sum()\n",
    "    axes[1, 1].bar(range(len(category_counts)), category_counts.values, \n",
    "                   color=['#2ca02c', '#d62728'], alpha=0.7)\n",
    "    axes[1, 1].set_xticks(range(len(category_counts)))\n",
    "    axes[1, 1].set_xticklabels(category_counts.index, rotation=45, ha='right')\n",
    "    axes[1, 1].set_title('Total Epochs by Category', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Total Epochs')\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nEpoching Statistics:\")\n",
    "    print(f\"  - Total runs processed: {len(epochs_df)}\")\n",
    "    print(f\"  - Total epochs extracted: {epochs_df['n_epochs_after_rejection'].sum()}\")\n",
    "    print(f\"  - Mean epochs per run: {epochs_df['n_epochs_after_rejection'].mean():.2f}\")\n",
    "    print(f\"  - Mean rejection rate: {epochs_df['rejection_rate'].mean() * 100:.2f}%\")\n",
    "    print(f\"  - Total left fist epochs: {epochs_df['left_fist_count'].sum()}\")\n",
    "    print(f\"  - Total right fist epochs: {epochs_df['right_fist_count'].sum()}\")\n",
    "    print(f\"  - Total storage used: {epochs_df['file_size_mb'].sum():.2f} MB\")\n",
    "else:\n",
    "    print(\"No data to visualize. Run the epoching cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject_summary",
   "metadata": {},
   "source": [
    "## Subject-Level Summary\n",
    "\n",
    "Aggregate epochs per subject for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject_agg",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(epochs_df) > 0:\n",
    "    subject_summary = epochs_df.groupby('subject').agg({\n",
    "        'run': 'count',\n",
    "        'n_epochs_after_rejection': 'sum',\n",
    "        'left_fist_count': 'sum',\n",
    "        'right_fist_count': 'sum',\n",
    "        'rejection_rate': 'mean',\n",
    "        'file_size_mb': 'sum'\n",
    "    }).rename(columns={\n",
    "        'run': 'n_runs',\n",
    "        'n_epochs_after_rejection': 'total_epochs'\n",
    "    })\n",
    "    \n",
    "    subject_summary['class_balance_ratio'] = (subject_summary['left_fist_count'] / \n",
    "                                               subject_summary['right_fist_count'])\n",
    "    \n",
    "    SUBJECT_SUMMARY_PATH = DERIVED_DIR / 'physionet_subject_epochs_summary.csv'\n",
    "    subject_summary.to_csv(SUBJECT_SUMMARY_PATH)\n",
    "    \n",
    "    print(f\"\\nSubject summary saved to: {SUBJECT_SUMMARY_PATH}\")\n",
    "    print(f\"\\nTop 10 subjects by epoch count:\")\n",
    "    print(subject_summary.sort_values('total_epochs', ascending=False).head(10))\n",
    "    \n",
    "    print(f\"\\nDataset ready for training!\")\n",
    "    print(f\"  - Total subjects: {len(subject_summary)}\")\n",
    "    print(f\"  - Total trials: {subject_summary['total_epochs'].sum()}\")\n",
    "    print(f\"  - Mean trials per subject: {subject_summary['total_epochs'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What Was Done\n",
    "\n",
    "1. **Event Extraction**: Extracted T1 (left fist) and T2 (right fist) events from annotations\n",
    "2. **Epoching**: Created 6-second epochs (-1 to +5 seconds relative to cue)\n",
    "3. **Baseline Correction**: Applied baseline correction using -0.5 to 0 seconds\n",
    "4. **Quality Control**: Rejected epochs with amplitude > 100 μV or < 1 μV\n",
    "5. **Data Export**: Saved epochs as compressed NPZ files for efficient loading\n",
    "\n",
    "### Output Files\n",
    "\n",
    "- **Epoch NPZ files**: `data/physionet/derived/epochs/{subject}/{subject}{run}_epo.npz`\n",
    "- **Epoch index**: `data/physionet/derived/physionet_epochs_index.csv`\n",
    "- **Subject summary**: `data/physionet/derived/physionet_subject_epochs_summary.csv`\n",
    "\n",
    "### Data Format\n",
    "\n",
    "Each NPZ file contains:\n",
    "- `data`: (n_epochs, n_channels, n_times) - EEG data\n",
    "- `labels`: (n_epochs,) - Binary labels (0=left fist, 1=right fist)\n",
    "- `ch_names`: List of channel names\n",
    "- `sfreq`: Sampling frequency (128 Hz)\n",
    "- `times`: Time array for epochs\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Model Implementation**: Build EEG-ARNN architecture (TFEM + CARM)\n",
    "2. **Training**: Train on PhysioNet data with 10-fold cross-validation\n",
    "3. **Channel Selection**: Apply ES and AS methods\n",
    "4. **Evaluation**: Compare with baseline methods and analyze results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
