{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI 2a EEG-ARNN Training Pipeline\n",
    "\n",
    "This notebook trains subject-specific EEG-ARNN models on the BCI Competition IV 2a dataset with:\n",
    "- Subject-specific 3-fold cross-validation (20 epochs per fold)\n",
    "- Channel selection experiments reused from the PhysioNet pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mne\n",
    "\n",
    "# IMPORTANT: Force reload train_utils to get latest fixes\n",
    "import importlib\n",
    "import train_utils\n",
    "importlib.reload(train_utils)\n",
    "\n",
    "from models import EEGARNN, ChannelSelector\n",
    "from train_utils import (\n",
    "    load_preprocessed_data, filter_classes, normalize_data,\n",
    "    cross_validate_subject, EEGDataset\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('ERROR')\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Verify the fix is loaded\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION: Checking if train_utils.py fix is loaded...\")\n",
    "print(\"=\"*80)\n",
    "import inspect\n",
    "source = inspect.getsource(load_preprocessed_data)\n",
    "if 'events_from_annotations' in source:\n",
    "    print(\"✓ GOOD: train_utils.py has the annotations fix!\")\n",
    "else:\n",
    "    print(\"✗ ERROR: train_utils.py is still using old code!\")\n",
    "    print(\"  → Please restart Jupyter kernel: Kernel → Restart Kernel\")\n",
    "    print(\"  → Then re-run all cells from the top\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_CONFIG = {\n",
    "    'data': {\n",
    "        'raw_dir': Path('data/BCI_2a'),\n",
    "        'subjects': [f'A0{i}' for i in range(1, 10)],\n",
    "        'selected_classes': [769, 770, 771, 772],\n",
    "        'tmin': 0.0,\n",
    "        'tmax': 4.0,\n",
    "        'baseline': None\n",
    "    },\n",
    "    'model': {\n",
    "        'hidden_dim': 40,\n",
    "        'epochs': 20,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32,\n",
    "        'n_folds': 3\n",
    "    },\n",
    "    'channel_selection': {\n",
    "        'k_values': [10, 15, 20, 25, 'all'],\n",
    "        'methods': ['ES', 'AS']\n",
    "    },\n",
    "    'output': {\n",
    "        'results_dir': Path('results/bci_2a'),\n",
    "        'models_dir': Path('saved_models/bci_2a'),\n",
    "        'subject_results_file': 'bci2a_baseline_subject_results.csv',\n",
    "        'channel_selection_results_file': 'bci2a_channel_selection_results.csv',\n",
    "        'config_file': 'bci2a_baseline_experiment_config.json'\n",
    "    },\n",
    "    'max_subjects': None\n",
    "}\n",
    "\n",
    "EXPERIMENT_CONFIG['output']['results_dir'].mkdir(parents=True, exist_ok=True)\n",
    "EXPERIMENT_CONFIG['output']['models_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Experiment Configuration:')\n",
    "print(json.dumps(EXPERIMENT_CONFIG, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build BCI 2a Session Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = EXPERIMENT_CONFIG['data']['raw_dir']\n",
    "selected_classes = EXPERIMENT_CONFIG['data']['selected_classes']\n",
    "\n",
    "records = []\n",
    "missing_subjects = []\n",
    "\n",
    "for subject_id in EXPERIMENT_CONFIG['data']['subjects']:\n",
    "    gdf_path = raw_dir / f\"{subject_id}T.gdf\"\n",
    "    if not gdf_path.exists():\n",
    "        missing_subjects.append(subject_id)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        raw = mne.io.read_raw_gdf(gdf_path, preload=False, verbose='ERROR')\n",
    "        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        selected_event_ids = [event_ids[str(cls)] for cls in selected_classes if str(cls) in event_ids]\n",
    "        trial_mask = np.isin(events[:, 2], selected_event_ids) if selected_event_ids else np.array([])\n",
    "        num_trials = int(trial_mask.sum()) if trial_mask.size else 0\n",
    "    except Exception as exc:\n",
    "        print(f\"[warn] Could not parse {gdf_path.name}: {exc}\")\n",
    "        num_trials = 0\n",
    "\n",
    "    records.append({\n",
    "        'subject': subject_id,\n",
    "        'session': 'T',\n",
    "        'path': gdf_path,\n",
    "        'num_trials': num_trials\n",
    "    })\n",
    "\n",
    "bci_sessions = pd.DataFrame(records)\n",
    "motor_runs = bci_sessions[bci_sessions['num_trials'] > 0].copy()\n",
    "\n",
    "print(f\"Total subjects configured: {len(EXPERIMENT_CONFIG['data']['subjects'])}\")\n",
    "print(f\"Subjects with labelled training data: {motor_runs['subject'].nunique()}\")\n",
    "print(f\"Total labelled trials: {int(motor_runs['num_trials'].sum())}\")\n",
    "\n",
    "if missing_subjects:\n",
    "    print('Missing training files for subjects:', missing_subjects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Selection\n",
    "\n",
    "Select subjects for training. For motor imagery, we focus on motor execution and motor imagery runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_counts = (motor_runs.groupby('subject')['num_trials']\n",
    "                  .sum()\n",
    "                  .reset_index()\n",
    "                  .sort_values('subject'))\n",
    "\n",
    "selected_subjects = subject_counts['subject'].tolist()\n",
    "\n",
    "if not selected_subjects:\n",
    "    raise RuntimeError('No BCI 2a subjects with labelled trials were found.')\n",
    "\n",
    "max_subjects = EXPERIMENT_CONFIG.get('max_subjects')\n",
    "if max_subjects:\n",
    "    selected_subjects = selected_subjects[:max_subjects]\n",
    "    subject_counts = subject_counts[subject_counts['subject'].isin(selected_subjects)]\n",
    "\n",
    "print('Subject trial counts:')\n",
    "print(subject_counts.to_string(index=False))\n",
    "print(f\"\n",
    "Will train on {len(selected_subjects)} subjects\")\n",
    "print(f\"Selected subjects: {selected_subjects}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_data(subject_id, subject_sessions_df, config):\n",
    "    '''\n",
    "    Load all labelled motor imagery trials for a BCI 2a subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray or None\n",
    "        (n_trials, n_channels, n_timepoints)\n",
    "    labels : np.ndarray or None\n",
    "        (n_trials,)\n",
    "    channel_names : list[str] or None\n",
    "        Channel labels preserved from the recording\n",
    "    '''\n",
    "    subject_rows = subject_sessions_df[subject_sessions_df['subject'] == subject_id]\n",
    "\n",
    "    if subject_rows.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    selected_classes = config['data']['selected_classes']\n",
    "\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    channel_names = None\n",
    "\n",
    "    for _, row in subject_rows.iterrows():\n",
    "        gdf_path = Path(row['path'])\n",
    "        if not gdf_path.exists():\n",
    "            print(f\"[warn] Missing file: {gdf_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_gdf(gdf_path, preload=True, verbose='ERROR')\n",
    "            events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "            selected_event_ids = {str(cls): event_ids[str(cls)] for cls in selected_classes if str(cls) in event_ids}\n",
    "            if not selected_event_ids:\n",
    "                print(f\"[warn] No target events found in {gdf_path.name}\")\n",
    "                continue\n",
    "\n",
    "            epochs = mne.Epochs(\n",
    "                raw,\n",
    "                events,\n",
    "                event_id=selected_event_ids,\n",
    "                tmin=config['data']['tmin'],\n",
    "                tmax=config['data']['tmax'],\n",
    "                baseline=config['data']['baseline'],\n",
    "                preload=True,\n",
    "                event_repeated='merge',\n",
    "                picks='eeg',\n",
    "                verbose='ERROR'\n",
    "            )\n",
    "\n",
    "            data = epochs.get_data()\n",
    "            label_lookup = {event_ids[key]: int(key) for key in selected_event_ids}\n",
    "            labels = np.array([label_lookup[event_code] for event_code in epochs.events[:, 2]])\n",
    "\n",
    "            data, labels = filter_classes(data, labels, selected_classes)\n",
    "\n",
    "            if data.size == 0:\n",
    "                continue\n",
    "\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "            if channel_names is None:\n",
    "                channel_names = epochs.ch_names\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(f\"[warn] Failed to load {gdf_path.name}: {exc}\")\n",
    "            continue\n",
    "\n",
    "    if not all_data:\n",
    "        return None, None, None\n",
    "\n",
    "    data = np.concatenate(all_data, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return data, labels, channel_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "Train subject-specific models with 3-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for subject_id in tqdm(selected_subjects, desc='Training subjects'):\n",
    "    print(f\"\n",
    "{'='*80}\")\n",
    "    print(f'Training subject: {subject_id}')\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data, labels, channel_names = load_subject_data(\n",
    "        subject_id,\n",
    "        motor_runs,\n",
    "        EXPERIMENT_CONFIG\n",
    "    )\n",
    "\n",
    "    if data is None or len(data) < 30:\n",
    "        print(f'Skipping {subject_id}: insufficient data')\n",
    "        continue\n",
    "\n",
    "    print(f'Data shape: {data.shape}')\n",
    "    print(f'Labels: {np.unique(labels, return_counts=True)}')\n",
    "    print(f'Channels: {len(channel_names)}')\n",
    "\n",
    "    num_channels = data.shape[1]\n",
    "    num_timepoints = data.shape[2]\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    cv_results = cross_validate_subject(\n",
    "        data, labels,\n",
    "        num_channels=num_channels,\n",
    "        num_timepoints=num_timepoints,\n",
    "        num_classes=num_classes,\n",
    "        device=device,\n",
    "        n_splits=EXPERIMENT_CONFIG['model']['n_folds'],\n",
    "        epochs=EXPERIMENT_CONFIG['model']['epochs'],\n",
    "        lr=EXPERIMENT_CONFIG['model']['learning_rate']\n",
    "    )\n",
    "\n",
    "    print(f\"\n",
    "Average accuracy (all channels): {cv_results['avg_accuracy']:.4f} +/- {cv_results['std_accuracy']:.4f}\")\n",
    "\n",
    "    result = {\n",
    "        'subject': subject_id,\n",
    "        'num_trials': len(data),\n",
    "        'num_channels': num_channels,\n",
    "        'num_timepoints': num_timepoints,\n",
    "        'num_classes': num_classes,\n",
    "        'all_channels_acc': cv_results['avg_accuracy'],\n",
    "        'all_channels_std': cv_results['std_accuracy'],\n",
    "        'adjacency_matrix': cv_results['adjacency_matrix'],\n",
    "        'channel_names': channel_names\n",
    "    }\n",
    "\n",
    "    all_results.append(result)\n",
    "\n",
    "print(f\"\n",
    "{'='*80}\")\n",
    "print(f'Training complete for {len(all_results)} subjects')\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Selection Experiments\n",
    "\n",
    "Test different k values with Edge Selection and Aggregation Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_selection_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    for result in tqdm(all_results, desc=\"Channel selection experiments\"):\n",
    "        subject_id = result['subject']\n",
    "        adj_matrix = result['adjacency_matrix']\n",
    "        channel_names = result['channel_names']\n",
    "        \n",
    "        print(f\"\\nProcessing channel selection for {subject_id}\")\n",
    "        \n",
    "        selector = ChannelSelector(adj_matrix, channel_names)\n",
    "        \n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            print(f\"  Method: {method}\")\n",
    "            \n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    k_val = result['num_channels']\n",
    "                    selected_channels = channel_names\n",
    "                else:\n",
    "                    k_val = min(k, result['num_channels'])  # Don't exceed available channels\n",
    "                    \n",
    "                    if method == 'ES':\n",
    "                        selected_channels, _ = selector.edge_selection(k_val)\n",
    "                    else:  # AS\n",
    "                        selected_channels, _ = selector.aggregation_selection(k_val)\n",
    "                \n",
    "                print(f\"    k={k_val}: {len(selected_channels)} channels selected\")\n",
    "                \n",
    "                channel_selection_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy_full': result['all_channels_acc']\n",
    "                })\n",
    "\n",
    "    channel_selection_df = pd.DataFrame(channel_selection_results)\n",
    "    print(f\"\\nChannel selection results: {len(channel_selection_df)} experiments\")\n",
    "    display(channel_selection_df.head(10))\n",
    "else:\n",
    "    channel_selection_df = pd.DataFrame()\n",
    "    print(\"\\nNo results available for channel selection experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import retrain_with_selected_channels\n",
    "\n",
    "# Store all retraining results\n",
    "retrain_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    # We need the original data for each subject  \n",
    "    # Load subject data cache\n",
    "    subject_data_cache = {}\n",
    "    \n",
    "    for result in all_results:\n",
    "        subject_id = result['subject']\n",
    "        print(f\"\\nLoading data for {subject_id}\")\n",
    "        \n",
    "        # Load subject data\n",
    "        data, labels, channel_names = load_subject_data(\n",
    "            subject_id, \n",
    "            EXPERIMENT_CONFIG['data']['preprocessed_dir'],\n",
    "            motor_runs,\n",
    "            EXPERIMENT_CONFIG\n",
    "        )\n",
    "        \n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        subject_data_cache[subject_id] = {\n",
    "            'data': data,\n",
    "            'labels': labels,\n",
    "            'channel_names': channel_names\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"RETRAINING WITH SELECTED CHANNELS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for result in tqdm(all_results, desc=\"Retraining subjects\"):\n",
    "        subject_id = result['subject']\n",
    "        \n",
    "        if subject_id not in subject_data_cache:\n",
    "            continue\n",
    "            \n",
    "        cache = subject_data_cache[subject_id]\n",
    "        data = cache['data']\n",
    "        labels = cache['labels']\n",
    "        channel_names = cache['channel_names']\n",
    "        \n",
    "        print(f\"\\nRetraining {subject_id}\")\n",
    "        \n",
    "        selector = ChannelSelector(result['adjacency_matrix'], channel_names)\n",
    "        \n",
    "        # Test each k value for both methods\n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    continue  # Skip, already have full results\n",
    "                \n",
    "                k_val = min(k, result['num_channels'])\n",
    "                \n",
    "                # Get selected channels\n",
    "                if method == 'ES':\n",
    "                    selected_channels, selected_indices = selector.edge_selection(k_val)\n",
    "                else:  # AS\n",
    "                    selected_channels, selected_indices = selector.aggregation_selection(k_val)\n",
    "                \n",
    "                print(f\"  {method} k={k_val}: Retraining with {len(selected_channels)} channels...\")\n",
    "                \n",
    "                # Retrain with selected channels\n",
    "                retrain_res = retrain_with_selected_channels(\n",
    "                    data, labels,\n",
    "                    selected_channel_indices=selected_indices,\n",
    "                    num_timepoints=result['num_timepoints'],\n",
    "                    num_classes=result['num_classes'],\n",
    "                    device=device,\n",
    "                    n_splits=EXPERIMENT_CONFIG['model']['n_folds'],\n",
    "                    epochs=EXPERIMENT_CONFIG['model']['epochs'],\n",
    "                    lr=EXPERIMENT_CONFIG['model']['learning_rate']\n",
    "                )\n",
    "                \n",
    "                acc_drop = result['all_channels_acc'] - retrain_res['avg_accuracy']\n",
    "                \n",
    "                print(f\"    Accuracy: {retrain_res['avg_accuracy']:.4f} ± {retrain_res['std_accuracy']:.4f}\")\n",
    "                print(f\"    Drop from full: {acc_drop:.4f} ({acc_drop/result['all_channels_acc']*100:.1f}%)\")\n",
    "                \n",
    "                retrain_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_channels_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy': retrain_res['avg_accuracy'],\n",
    "                    'std': retrain_res['std_accuracy'],\n",
    "                    'full_channels_acc': result['all_channels_acc'],\n",
    "                    'accuracy_drop': acc_drop,\n",
    "                    'accuracy_drop_pct': acc_drop / result['all_channels_acc'] * 100\n",
    "                })\n",
    "    \n",
    "    retrain_df = pd.DataFrame(retrain_results)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Retraining complete: {len(retrain_df)} experiments\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Save retrain results\n",
    "    retrain_path = EXPERIMENT_CONFIG['output']['results_dir'] / 'retrain_results.csv'\n",
    "    retrain_df.to_csv(retrain_path, index=False)\n",
    "    print(f\"Retrain results saved to: {retrain_path}\")\n",
    "else:\n",
    "    retrain_df = pd.DataFrame()\n",
    "    print(\"No results to retrain. Please run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain with Selected Channels\n",
    "\n",
    "Now retrain the model using ONLY the selected channels and compare accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OVERALL RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSubjects trained: {len(results_df)}\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"Mean accuracy (all channels): {results_df['all_channels_acc'].mean():.4f} ± {results_df['all_channels_acc'].std():.4f}\")\n",
    "    print(f\"Best subject: {results_df.loc[results_df['all_channels_acc'].idxmax(), 'subject']} ({results_df['all_channels_acc'].max():.4f})\")\n",
    "    print(f\"Worst subject: {results_df.loc[results_df['all_channels_acc'].idxmin(), 'subject']} ({results_df['all_channels_acc'].min():.4f})\")\n",
    "\n",
    "    # Save results\n",
    "    results_path = EXPERIMENT_CONFIG['output']['results_dir'] / 'subject_results.csv'\n",
    "    results_df[['subject', 'num_trials', 'num_channels', 'all_channels_acc', 'all_channels_std']].to_csv(results_path, index=False)\n",
    "    print(f\"\\nResults saved to: {results_path}\")\n",
    "\n",
    "    display(results_df[['subject', 'num_trials', 'num_channels', 'all_channels_acc', 'all_channels_std']].head(10))\n",
    "else:\n",
    "    print(\"\\nNo subjects were successfully trained. Check the data loading and preprocessing steps.\")\n",
    "    results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Accuracy distribution\n",
    "    axes[0, 0].hist(results_df['all_channels_acc'], bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(results_df['all_channels_acc'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 0].set_title('Accuracy Distribution (All Channels)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Accuracy')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy vs num trials\n",
    "    axes[0, 1].scatter(results_df['num_trials'], results_df['all_channels_acc'], alpha=0.6, s=100)\n",
    "    axes[0, 1].set_title('Accuracy vs Number of Trials', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Number of Trials')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Top 10 subjects\n",
    "    top_10 = results_df.nlargest(min(10, len(results_df)), 'all_channels_acc')\n",
    "    axes[1, 0].barh(range(len(top_10)), top_10['all_channels_acc'], color='green', alpha=0.7)\n",
    "    axes[1, 0].set_yticks(range(len(top_10)))\n",
    "    axes[1, 0].set_yticklabels(top_10['subject'])\n",
    "    axes[1, 0].set_title(f'Top {len(top_10)} Subjects by Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Accuracy')\n",
    "    axes[1, 0].invert_yaxis()\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "    # Subject ranking\n",
    "    sorted_results = results_df.sort_values('all_channels_acc')\n",
    "    axes[1, 1].plot(range(len(sorted_results)), sorted_results['all_channels_acc'], marker='o', markersize=4, alpha=0.6)\n",
    "    axes[1, 1].set_title('Subject Ranking', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Rank')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(EXPERIMENT_CONFIG['output']['results_dir'] / 'results_summary.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Visualizations saved to: {EXPERIMENT_CONFIG['output']['results_dir']}\")\n",
    "else:\n",
    "    print(\"No results to visualize. Please ensure subjects were successfully trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Adjacency Matrix (Example Subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_results) > 0:\n",
    "    # Pick best subject\n",
    "    best_idx = results_df['all_channels_acc'].idxmax()\n",
    "    best_result = all_results[best_idx]\n",
    "    \n",
    "    print(f\"Visualizing adjacency matrix for best subject: {best_result['subject']}\")\n",
    "    print(f\"Accuracy: {best_result['all_channels_acc']:.4f}\")\n",
    "    \n",
    "    selector = ChannelSelector(best_result['adjacency_matrix'], best_result['channel_names'])\n",
    "    \n",
    "    fig = selector.visualize_adjacency(\n",
    "        save_path=EXPERIMENT_CONFIG['output']['results_dir'] / f\"adjacency_{best_result['subject']}.png\"\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top edges\n",
    "    print(\"\\nTop 10 Edges (Edge Selection):\")\n",
    "    selected_channels_es, _ = selector.edge_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_es}\")\n",
    "    \n",
    "    print(\"\\nTop 10 Channels (Aggregation Selection):\")\n",
    "    selected_channels_as, _ = selector.aggregation_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_as}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results_df) > 0:\n",
    "    results_dir = EXPERIMENT_CONFIG['output']['results_dir']\n",
    "    subject_results_path = results_dir / EXPERIMENT_CONFIG['output']['subject_results_file']\n",
    "    results_df[['subject', 'num_trials', 'num_channels', 'all_channels_acc', 'all_channels_std']].to_csv(subject_results_path, index=False)\n",
    "\n",
    "    if len(channel_selection_df) > 0:\n",
    "        channel_selection_path = results_dir / EXPERIMENT_CONFIG['output']['channel_selection_results_file']\n",
    "        channel_selection_df.to_csv(channel_selection_path, index=False)\n",
    "    else:\n",
    "        channel_selection_path = None\n",
    "\n",
    "    config_path = results_dir / EXPERIMENT_CONFIG['output']['config_file']\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(EXPERIMENT_CONFIG, f, indent=2, default=str)\n",
    "\n",
    "    print('All results exported successfully!')\n",
    "    print(f'  - Subject results: {subject_results_path}')\n",
    "    if channel_selection_path:\n",
    "        print(f'  - Channel selection: {channel_selection_path}')\n",
    "    print(f'  - Config: {config_path}')\n",
    "else:\n",
    "    print('No results to export.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
