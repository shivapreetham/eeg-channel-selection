{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI 2a EEG-ARNN Training Pipeline\n",
    "\n",
    "This notebook trains subject-specific EEG-ARNN models on the BCI Competition IV 2a dataset with:\n",
    "- Subject-specific 3-fold cross-validation (20 epochs per fold)\n",
    "- Channel selection experiments reused from the PhysioNet pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION: Checking if train_utils.py fix is loaded...\n",
      "================================================================================\n",
      "✓ GOOD: train_utils.py has the annotations fix!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mne\n",
    "\n",
    "# IMPORTANT: Force reload train_utils to get latest fixes\n",
    "import importlib\n",
    "import train_utils\n",
    "importlib.reload(train_utils)\n",
    "\n",
    "from models import EEGARNN, ChannelSelector\n",
    "from train_utils import (\n",
    "    load_preprocessed_data, filter_classes, normalize_data,\n",
    "    cross_validate_subject, EEGDataset\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('ERROR')\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Verify the fix is loaded\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION: Checking if train_utils.py fix is loaded...\")\n",
    "print(\"=\"*80)\n",
    "import inspect\n",
    "source = inspect.getsource(load_preprocessed_data)\n",
    "if 'events_from_annotations' in source:\n",
    "    print(\"✓ GOOD: train_utils.py has the annotations fix!\")\n",
    "else:\n",
    "    print(\"✗ ERROR: train_utils.py is still using old code!\")\n",
    "    print(\"  → Please restart Jupyter kernel: Kernel → Restart Kernel\")\n",
    "    print(\"  → Then re-run all cells from the top\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Configuration:\n",
      "{\n",
      "  \"data\": {\n",
      "    \"raw_dir\": \"data\\\\BCI_2a\",\n",
      "    \"subjects\": [\n",
      "      \"A01\",\n",
      "      \"A02\",\n",
      "      \"A03\",\n",
      "      \"A04\",\n",
      "      \"A05\",\n",
      "      \"A06\",\n",
      "      \"A07\",\n",
      "      \"A08\",\n",
      "      \"A09\"\n",
      "    ],\n",
      "    \"selected_classes\": [\n",
      "      769,\n",
      "      770,\n",
      "      771,\n",
      "      772\n",
      "    ],\n",
      "    \"tmin\": 0.0,\n",
      "    \"tmax\": 4.0,\n",
      "    \"baseline\": null\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"hidden_dim\": 40,\n",
      "    \"epochs\": 20,\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"batch_size\": 32,\n",
      "    \"n_folds\": 3\n",
      "  },\n",
      "  \"channel_selection\": {\n",
      "    \"k_values\": [\n",
      "      10,\n",
      "      15,\n",
      "      20,\n",
      "      25,\n",
      "      \"all\"\n",
      "    ],\n",
      "    \"methods\": [\n",
      "      \"ES\",\n",
      "      \"AS\"\n",
      "    ]\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"results_dir\": \"results\\\\bci_2a\",\n",
      "    \"models_dir\": \"saved_models\\\\bci_2a\",\n",
      "    \"subject_results_file\": \"bci2a_baseline_subject_results.csv\",\n",
      "    \"channel_selection_results_file\": \"bci2a_channel_selection_results.csv\",\n",
      "    \"retrain_results_file\": \"bci2a_baseline_retrain_results.csv\",\n",
      "    \"config_file\": \"bci2a_baseline_experiment_config.json\",\n",
      "    \"results_summary_figure\": \"bci2a_baseline_results_summary.png\"\n",
      "  },\n",
      "  \"max_subjects\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_CONFIG = {\n",
    "    'data': {\n",
    "        'raw_dir': Path('data/BCI_2a'),\n",
    "        'subjects': [f'A0{i}' for i in range(1, 10)],\n",
    "        'selected_classes': [769, 770, 771, 772],\n",
    "        'tmin': 0.0,\n",
    "        'tmax': 4.0,\n",
    "        'baseline': None\n",
    "    },\n",
    "    'model': {\n",
    "        'hidden_dim': 40,\n",
    "        'epochs': 20,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 32,\n",
    "        'n_folds': 3\n",
    "    },\n",
    "    'channel_selection': {\n",
    "        'k_values': [10, 15, 20, 25, 'all'],\n",
    "        'methods': ['ES', 'AS']\n",
    "    },\n",
    "    'output': {\n",
    "        'results_dir': Path('results/bci_2a'),\n",
    "        'models_dir': Path('saved_models/bci_2a'),\n",
    "        'subject_results_file': 'bci2a_baseline_subject_results.csv',\n",
    "        'channel_selection_results_file': 'bci2a_channel_selection_results.csv',\n",
    "        'retrain_results_file': 'bci2a_baseline_retrain_results.csv',\n",
    "        'config_file': 'bci2a_baseline_experiment_config.json',\n",
    "        'results_summary_figure': 'bci2a_baseline_results_summary.png'\n",
    "    },\n",
    "    'max_subjects': None\n",
    "}\n",
    "\n",
    "EXPERIMENT_CONFIG['output']['results_dir'].mkdir(parents=True, exist_ok=True)\n",
    "EXPERIMENT_CONFIG['output']['models_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Experiment Configuration:')\n",
    "print(json.dumps(EXPERIMENT_CONFIG, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build BCI 2a Session Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects configured: 9\n",
      "Subjects with labelled training data: 9\n",
      "Total labelled trials: 2592\n"
     ]
    }
   ],
   "source": [
    "raw_dir = EXPERIMENT_CONFIG['data']['raw_dir']\n",
    "selected_classes = EXPERIMENT_CONFIG['data']['selected_classes']\n",
    "\n",
    "records = []\n",
    "missing_subjects = []\n",
    "\n",
    "for subject_id in EXPERIMENT_CONFIG['data']['subjects']:\n",
    "    gdf_path = raw_dir / f\"{subject_id}T.gdf\"\n",
    "    if not gdf_path.exists():\n",
    "        missing_subjects.append(subject_id)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        raw = mne.io.read_raw_gdf(gdf_path, preload=False, verbose='ERROR')\n",
    "        events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "        selected_event_ids = [event_ids[str(cls)] for cls in selected_classes if str(cls) in event_ids]\n",
    "        trial_mask = np.isin(events[:, 2], selected_event_ids) if selected_event_ids else np.array([])\n",
    "        num_trials = int(trial_mask.sum()) if trial_mask.size else 0\n",
    "    except Exception as exc:\n",
    "        print(f\"[warn] Could not parse {gdf_path.name}: {exc}\")\n",
    "        num_trials = 0\n",
    "\n",
    "    records.append({\n",
    "        'subject': subject_id,\n",
    "        'session': 'T',\n",
    "        'path': gdf_path,\n",
    "        'num_trials': num_trials\n",
    "    })\n",
    "\n",
    "bci_sessions = pd.DataFrame(records)\n",
    "motor_runs = bci_sessions[bci_sessions['num_trials'] > 0].copy()\n",
    "\n",
    "print(f\"Total subjects configured: {len(EXPERIMENT_CONFIG['data']['subjects'])}\")\n",
    "print(f\"Subjects with labelled training data: {motor_runs['subject'].nunique()}\")\n",
    "print(f\"Total labelled trials: {int(motor_runs['num_trials'].sum())}\")\n",
    "\n",
    "if missing_subjects:\n",
    "    print('Missing training files for subjects:', missing_subjects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Selection\n",
    "\n",
    "Identify BCI 2a subjects with labelled training (T) sessions and aggregate their available trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject trial counts:\n",
      "subject  num_trials\n",
      "    A01         288\n",
      "    A02         288\n",
      "    A03         288\n",
      "    A04         288\n",
      "    A05         288\n",
      "    A06         288\n",
      "    A07         288\n",
      "    A08         288\n",
      "    A09         288\n",
      "Will train on 9 subjects\n",
      "Selected subjects: ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09']\n"
     ]
    }
   ],
   "source": [
    "subject_counts = (motor_runs.groupby('subject')['num_trials']\n",
    "                  .sum()\n",
    "                  .reset_index()\n",
    "                  .sort_values('subject'))\n",
    "\n",
    "selected_subjects = subject_counts['subject'].tolist()\n",
    "\n",
    "if not selected_subjects:\n",
    "    raise RuntimeError('No BCI 2a subjects with labelled trials were found.')\n",
    "\n",
    "max_subjects = EXPERIMENT_CONFIG.get('max_subjects')\n",
    "if max_subjects:\n",
    "    selected_subjects = selected_subjects[:max_subjects]\n",
    "    subject_counts = subject_counts[subject_counts['subject'].isin(selected_subjects)]\n",
    "\n",
    "print('Subject trial counts:')\n",
    "print(subject_counts.to_string(index=False))\n",
    "print(f\"Will train on {len(selected_subjects)} subjects\")\n",
    "print(f\"Selected subjects: {selected_subjects}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_data(subject_id, subject_sessions_df, config):\n",
    "    '''\n",
    "    Load all labelled motor imagery trials for a BCI 2a subject.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : np.ndarray or None\n",
    "        (n_trials, n_channels, n_timepoints)\n",
    "    labels : np.ndarray or None\n",
    "        (n_trials,)\n",
    "    channel_names : list[str] or None\n",
    "        Channel labels preserved from the recording\n",
    "    '''\n",
    "    subject_rows = subject_sessions_df[subject_sessions_df['subject'] == subject_id]\n",
    "\n",
    "    if subject_rows.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    selected_classes = config['data']['selected_classes']\n",
    "\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    channel_names = None\n",
    "\n",
    "    for _, row in subject_rows.iterrows():\n",
    "        gdf_path = Path(row['path'])\n",
    "        if not gdf_path.exists():\n",
    "            print(f\"[warn] Missing file: {gdf_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_gdf(gdf_path, preload=True, verbose='ERROR')\n",
    "            events, event_ids = mne.events_from_annotations(raw, verbose='ERROR')\n",
    "\n",
    "            selected_event_ids = {str(cls): event_ids[str(cls)] for cls in selected_classes if str(cls) in event_ids}\n",
    "            if not selected_event_ids:\n",
    "                print(f\"[warn] No target events found in {gdf_path.name}\")\n",
    "                continue\n",
    "\n",
    "            epochs = mne.Epochs(\n",
    "                raw,\n",
    "                events,\n",
    "                event_id=selected_event_ids,\n",
    "                tmin=config['data']['tmin'],\n",
    "                tmax=config['data']['tmax'],\n",
    "                baseline=config['data']['baseline'],\n",
    "                preload=True,\n",
    "                event_repeated='merge',\n",
    "                picks='eeg',\n",
    "                verbose='ERROR'\n",
    "            )\n",
    "\n",
    "            data = epochs.get_data()\n",
    "            label_lookup = {event_ids[key]: int(key) for key in selected_event_ids}\n",
    "            labels = np.array([label_lookup[event_code] for event_code in epochs.events[:, 2]])\n",
    "\n",
    "            data, labels = filter_classes(data, labels, selected_classes)\n",
    "\n",
    "            if data.size == 0:\n",
    "                continue\n",
    "\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "            if channel_names is None:\n",
    "                channel_names = epochs.ch_names\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(f\"[warn] Failed to load {gdf_path.name}: {exc}\")\n",
    "            continue\n",
    "\n",
    "    if not all_data:\n",
    "        return None, None, None\n",
    "\n",
    "    data = np.concatenate(all_data, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return data, labels, channel_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop\n",
    "\n",
    "Train subject-specific models with 3-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training subjects:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training subject: A01\n",
      "================================================================================\n",
      "Data shape: (288, 25, 1001)\n",
      "Labels: (array([0, 1, 2, 3]), array([72, 72, 72, 72], dtype=int64))\n",
      "Channels: 25\n",
      "  Fold 1/3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training subjects:   0%|          | 0/9 [01:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m num_timepoints = data.shape[\u001b[32m2\u001b[39m]\n\u001b[32m     24\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(np.unique(labels))\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m cv_results = \u001b[43mcross_validate_subject\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_timepoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_timepoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEXPERIMENT_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_folds\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEXPERIMENT_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEXPERIMENT_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAverage accuracy (all channels): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_results[\u001b[33m'\u001b[39m\u001b[33mavg_accuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_results[\u001b[33m'\u001b[39m\u001b[33mstd_accuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m result = {\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msubject\u001b[39m\u001b[33m'\u001b[39m: subject_id,\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnum_trials\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(data),\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mchannel_names\u001b[39m\u001b[33m'\u001b[39m: channel_names\n\u001b[32m     49\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\eeg-channel-selection\\train_utils.py:344\u001b[39m, in \u001b[36mcross_validate_subject\u001b[39m\u001b[34m(data, labels, num_channels, num_timepoints, num_classes, device, n_splits, epochs, lr, batch_size, patience)\u001b[39m\n\u001b[32m    335\u001b[39m val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m0\u001b[39m)\n\u001b[32m    337\u001b[39m model = EEGARNN(\n\u001b[32m    338\u001b[39m     num_channels=num_channels,\n\u001b[32m    339\u001b[39m     num_timepoints=num_timepoints,\n\u001b[32m    340\u001b[39m     num_classes=num_classes,\n\u001b[32m    341\u001b[39m     hidden_dim=\u001b[32m40\u001b[39m\n\u001b[32m    342\u001b[39m ).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m history, best_state = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m model.load_state_dict(best_state)\n\u001b[32m    350\u001b[39m _, val_acc, val_preds, val_labels = evaluate(\n\u001b[32m    351\u001b[39m     model, val_loader, nn.CrossEntropyLoss(), device\n\u001b[32m    352\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\eeg-channel-selection\\train_utils.py:243\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, device, epochs, lr, patience)\u001b[39m\n\u001b[32m    240\u001b[39m epochs_no_improve = \u001b[32m0\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, device)\n\u001b[32m    246\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\eeg-channel-selection\\train_utils.py:151\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device)\u001b[39m\n\u001b[32m    149\u001b[39m outputs = model(data)\n\u001b[32m    150\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m optimizer.step()\n\u001b[32m    154\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_tensor.py:521\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    513\u001b[39m         Tensor.backward,\n\u001b[32m    514\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m         inputs=inputs,\n\u001b[32m    520\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\autograd\\__init__.py:289\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    284\u001b[39m     retain_graph = create_graph\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\autograd\\graph.py:769\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    767\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    770\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for subject_id in tqdm(selected_subjects, desc='Training subjects'):\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training subject: {subject_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data, labels, channel_names = load_subject_data(\n",
    "        subject_id,\n",
    "        motor_runs,\n",
    "        EXPERIMENT_CONFIG\n",
    "    )\n",
    "\n",
    "    if data is None or len(data) < 30:\n",
    "        print(f\"Skipping {subject_id}: insufficient data\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(f\"Labels: {np.unique(labels, return_counts=True)}\")\n",
    "    print(f\"Channels: {len(channel_names)}\")\n",
    "\n",
    "    num_channels = data.shape[1]\n",
    "    num_timepoints = data.shape[2]\n",
    "    num_classes = len(np.unique(labels))\n",
    "\n",
    "    cv_results = cross_validate_subject(\n",
    "        data, labels,\n",
    "        num_channels=num_channels,\n",
    "        num_timepoints=num_timepoints,\n",
    "        num_classes=num_classes,\n",
    "        device=device,\n",
    "        n_splits=EXPERIMENT_CONFIG['model']['n_folds'],\n",
    "        epochs=EXPERIMENT_CONFIG['model']['epochs'],\n",
    "        lr=EXPERIMENT_CONFIG['model']['learning_rate']\n",
    "    )\n",
    "\n",
    "    print(f\"Average accuracy (all channels): {cv_results['avg_accuracy']:.4f} +/- {cv_results['std_accuracy']:.4f}\")\n",
    "\n",
    "    result = {\n",
    "        'subject': subject_id,\n",
    "        'num_trials': len(data),\n",
    "        'num_channels': num_channels,\n",
    "        'num_timepoints': num_timepoints,\n",
    "        'num_classes': num_classes,\n",
    "        'all_channels_acc': cv_results['avg_accuracy'],\n",
    "        'all_channels_std': cv_results['std_accuracy'],\n",
    "        'adjacency_matrix': cv_results['adjacency_matrix'],\n",
    "        'channel_names': channel_names\n",
    "    }\n",
    "\n",
    "    all_results.append(result)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Training complete for {len(all_results)} subjects\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Selection Experiments\n",
    "\n",
    "Test different k values with Edge Selection and Aggregation Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_selection_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    for result in tqdm(all_results, desc=\"Channel selection experiments\"):\n",
    "        subject_id = result['subject']\n",
    "        adj_matrix = result['adjacency_matrix']\n",
    "        channel_names = result['channel_names']\n",
    "        \n",
    "        print(f\"\\nProcessing channel selection for {subject_id}\")\n",
    "        \n",
    "        selector = ChannelSelector(adj_matrix, channel_names)\n",
    "        \n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            print(f\"  Method: {method}\")\n",
    "            \n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    k_val = result['num_channels']\n",
    "                    selected_channels = channel_names\n",
    "                else:\n",
    "                    k_val = min(k, result['num_channels'])  # Don't exceed available channels\n",
    "                    \n",
    "                    if method == 'ES':\n",
    "                        selected_channels, _ = selector.edge_selection(k_val)\n",
    "                    else:  # AS\n",
    "                        selected_channels, _ = selector.aggregation_selection(k_val)\n",
    "                \n",
    "                print(f\"    k={k_val}: {len(selected_channels)} channels selected\")\n",
    "                \n",
    "                channel_selection_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy_full': result['all_channels_acc']\n",
    "                })\n",
    "\n",
    "    channel_selection_df = pd.DataFrame(channel_selection_results)\n",
    "    print(f\"\\nChannel selection results: {len(channel_selection_df)} experiments\")\n",
    "    display(channel_selection_df.head(10))\n",
    "else:\n",
    "    channel_selection_df = pd.DataFrame()\n",
    "    print(\"\\nNo results available for channel selection experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import retrain_with_selected_channels\n",
    "\n",
    "# Store all retraining results\n",
    "retrain_results = []\n",
    "\n",
    "if len(all_results) > 0:\n",
    "    # We need the original data for each subject\n",
    "    subject_data_cache = {}\n",
    "\n",
    "    for result in all_results:\n",
    "        subject_id = result['subject']\n",
    "        print(f\"Loading data for {subject_id}\")\n",
    "\n",
    "        data, labels, channel_names = load_subject_data(\n",
    "            subject_id,\n",
    "            motor_runs,\n",
    "            EXPERIMENT_CONFIG\n",
    "        )\n",
    "\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        subject_data_cache[subject_id] = {\n",
    "            'data': data,\n",
    "            'labels': labels,\n",
    "            'channel_names': channel_names\n",
    "        }\n",
    "\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"RETRAINING WITH SELECTED CHANNELS\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    for result in tqdm(all_results, desc=\"Retraining subjects\"):\n",
    "        subject_id = result['subject']\n",
    "\n",
    "        if subject_id not in subject_data_cache:\n",
    "            continue\n",
    "\n",
    "        cache = subject_data_cache[subject_id]\n",
    "        data = cache['data']\n",
    "        labels = cache['labels']\n",
    "        channel_names = cache['channel_names']\n",
    "\n",
    "        print(f\"Retraining {subject_id}\")\n",
    "\n",
    "        selector = ChannelSelector(result['adjacency_matrix'], channel_names)\n",
    "\n",
    "        for method in EXPERIMENT_CONFIG['channel_selection']['methods']:\n",
    "            for k in EXPERIMENT_CONFIG['channel_selection']['k_values']:\n",
    "                if k == 'all':\n",
    "                    continue\n",
    "\n",
    "                k_val = min(k, result['num_channels'])\n",
    "\n",
    "                if method == 'ES':\n",
    "                    selected_channels, selected_indices = selector.edge_selection(k_val)\n",
    "                else:\n",
    "                    selected_channels, selected_indices = selector.aggregation_selection(k_val)\n",
    "\n",
    "                print(f\"  {method} k={k_val}: Retraining with {len(selected_channels)} channels...\")\n",
    "\n",
    "                retrain_res = retrain_with_selected_channels(\n",
    "                    data, labels,\n",
    "                    selected_channel_indices=selected_indices,\n",
    "                    num_timepoints=result['num_timepoints'],\n",
    "                    num_classes=result['num_classes'],\n",
    "                    device=device,\n",
    "                    n_splits=EXPERIMENT_CONFIG['model']['n_folds'],\n",
    "                    epochs=EXPERIMENT_CONFIG['model']['epochs'],\n",
    "                    lr=EXPERIMENT_CONFIG['model']['learning_rate']\n",
    "                )\n",
    "\n",
    "                acc_drop = result['all_channels_acc'] - retrain_res['avg_accuracy']\n",
    "\n",
    "                print(f\"    Accuracy: {retrain_res['avg_accuracy']:.4f} +/- {retrain_res['std_accuracy']:.4f}\")\n",
    "                print(f\"    Drop from full: {acc_drop:.4f} ({acc_drop/result['all_channels_acc']*100:.1f}%)\")\n",
    "\n",
    "                retrain_results.append({\n",
    "                    'subject': subject_id,\n",
    "                    'method': method,\n",
    "                    'k': k_val,\n",
    "                    'num_channels_selected': len(selected_channels),\n",
    "                    'selected_channels': selected_channels,\n",
    "                    'accuracy': retrain_res['avg_accuracy'],\n",
    "                    'std': retrain_res['std_accuracy'],\n",
    "                    'full_channels_acc': result['all_channels_acc'],\n",
    "                    'accuracy_drop': acc_drop,\n",
    "                    'accuracy_drop_pct': acc_drop / result['all_channels_acc'] * 100\n",
    "                })\n",
    "\n",
    "    retrain_df = pd.DataFrame(retrain_results)\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Retraining complete: {len(retrain_df)} experiments\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    retrain_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['retrain_results_file']\n",
    "    retrain_df.to_csv(retrain_path, index=False)\n",
    "    print(f\"Retrain results saved to: {retrain_path}\")\n",
    "else:\n",
    "    retrain_df = pd.DataFrame()\n",
    "    print(\"No results to retrain. Please run training first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain with Selected Channels\n",
    "\n",
    "Now retrain the model using ONLY the selected channels and compare accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OVERALL RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSubjects trained: {len(results_df)}\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"Mean accuracy (all channels): {results_df['all_channels_acc'].mean():.4f} ± {results_df['all_channels_acc'].std():.4f}\")\n",
    "    print(f\"Best subject: {results_df.loc[results_df['all_channels_acc'].idxmax(), 'subject']} ({results_df['all_channels_acc'].max():.4f})\")\n",
    "    print(f\"Worst subject: {results_df.loc[results_df['all_channels_acc'].idxmin(), 'subject']} ({results_df['all_channels_acc'].min():.4f})\")\n",
    "\n",
    "    # Save results\n",
    "    results_path = EXPERIMENT_CONFIG['output']['results_dir'] / 'subject_results.csv'\n",
    "    results_df[['subject', 'num_trials', 'num_channels', 'all_channels_acc', 'all_channels_std']].to_csv(results_path, index=False)\n",
    "    print(f\"\\nResults saved to: {results_path}\")\n",
    "\n",
    "    display(results_df[['subject', 'num_trials', 'num_channels', 'all_channels_acc', 'all_channels_std']].head(10))\n",
    "else:\n",
    "    print(\"\\nNo subjects were successfully trained. Check the data loading and preprocessing steps.\")\n",
    "    results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Accuracy distribution\n",
    "    axes[0, 0].hist(results_df['all_channels_acc'], bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(results_df['all_channels_acc'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[0, 0].set_title('Accuracy Distribution (All Channels)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Accuracy')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy vs num trials\n",
    "    axes[0, 1].scatter(results_df['num_trials'], results_df['all_channels_acc'], alpha=0.6, s=100)\n",
    "    axes[0, 1].set_title('Accuracy vs Number of Trials', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Number of Trials')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Top 10 subjects\n",
    "    top_10 = results_df.nlargest(min(10, len(results_df)), 'all_channels_acc')\n",
    "    axes[1, 0].barh(range(len(top_10)), top_10['all_channels_acc'], color='green', alpha=0.7)\n",
    "    axes[1, 0].set_yticks(range(len(top_10)))\n",
    "    axes[1, 0].set_yticklabels(top_10['subject'])\n",
    "    axes[1, 0].set_title(f'Top {len(top_10)} Subjects by Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Accuracy')\n",
    "    axes[1, 0].invert_yaxis()\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "    # Subject ranking\n",
    "    sorted_results = results_df.sort_values('all_channels_acc')\n",
    "    axes[1, 1].plot(range(len(sorted_results)), sorted_results['all_channels_acc'], marker='o', markersize=4, alpha=0.6)\n",
    "    axes[1, 1].set_title('Subject Ranking', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Rank')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    summary_path = EXPERIMENT_CONFIG['output']['results_dir'] / EXPERIMENT_CONFIG['output']['results_summary_figure']\n",
    "    plt.savefig(summary_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Visualizations saved to: {summary_path}\")\n",
    "else:\n",
    "    print('No results to visualize. Please ensure subjects were successfully trained.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Adjacency Matrix (Example Subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(all_results) > 0:\n",
    "    # Pick best subject\n",
    "    best_idx = results_df['all_channels_acc'].idxmax()\n",
    "    best_result = all_results[best_idx]\n",
    "    \n",
    "    print(f\"Visualizing adjacency matrix for best subject: {best_result['subject']}\")\n",
    "    print(f\"Accuracy: {best_result['all_channels_acc']:.4f}\")\n",
    "    \n",
    "    selector = ChannelSelector(best_result['adjacency_matrix'], best_result['channel_names'])\n",
    "    \n",
    "    fig = selector.visualize_adjacency(\n",
    "        save_path=EXPERIMENT_CONFIG['output']['results_dir'] / f\"adjacency_{best_result['subject']}.png\"\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top edges\n",
    "    print(\"\\nTop 10 Edges (Edge Selection):\")\n",
    "    selected_channels_es, _ = selector.edge_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_es}\")\n",
    "    \n",
    "    print(\"\\nTop 10 Channels (Aggregation Selection):\")\n",
    "    selected_channels_as, _ = selector.aggregation_selection(10)\n",
    "    print(f\"Selected channels: {selected_channels_as}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results_df) > 0:\n",
    "    results_dir = EXPERIMENT_CONFIG['output']['results_dir']\n",
    "    subject_results_path = results_dir / EXPERIMENT_CONFIG['output']['subject_results_file']\n",
    "    results_df[['subject', 'num_trials', 'num_channels', 'all_channels_acc', 'all_channels_std']].to_csv(subject_results_path, index=False)\n",
    "\n",
    "    if len(channel_selection_df) > 0:\n",
    "        channel_selection_path = results_dir / EXPERIMENT_CONFIG['output']['channel_selection_results_file']\n",
    "        channel_selection_df.to_csv(channel_selection_path, index=False)\n",
    "    else:\n",
    "        channel_selection_path = None\n",
    "\n",
    "    config_path = results_dir / EXPERIMENT_CONFIG['output']['config_file']\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(EXPERIMENT_CONFIG, f, indent=2, default=str)\n",
    "\n",
    "    print('All results exported successfully!')\n",
    "    print(f'  - Subject results: {subject_results_path}')\n",
    "    if channel_selection_path:\n",
    "        print(f'  - Channel selection: {channel_selection_path}')\n",
    "    print(f'  - Config: {config_path}')\n",
    "else:\n",
    "    print('No results to export.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
