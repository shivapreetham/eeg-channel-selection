{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098a6066",
   "metadata": {},
   "source": [
    "\n",
    "# BCI Competition IV 2a - Comprehensive EDA\n",
    "\n",
    "Exploratory analysis of the BCI Competition IV 2a motor imagery dataset, covering session inventory, signal quality metrics, spectral characteristics, and subject-level anomaly detection to support downstream channel selection and modelling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf81b2",
   "metadata": {},
   "source": [
    "\n",
    "## Analysis roadmap\n",
    "- Inspect GDF files and build an inventory for training (T) and evaluation (E) sessions per subject.\n",
    "- Extract session-level signal quality indicators (variance, clipping, spectral balance) using MNE.\n",
    "- Visualise cue/event distributions, amplitude stability, and band-power patterns with Matplotlib/Seaborn/Plotly.\n",
    "- Flag noisy or flat electrodes and subject-level anomalies to guide data cleaning.\n",
    "- Provide interactive utilities and exportable CSV reports for modelling workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mne\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "pio.renderers.default = 'notebook_connected'\n",
    "mne.set_log_level('WARNING')\n",
    "pd.options.display.float_format = lambda x: f\"{x:0.3f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a6b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT = Path('data/BCI_2a')\n",
    "DERIVED_DIR = DATA_ROOT.parent / 'BCI_2a_derived'\n",
    "DERIVED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUN_SUMMARY_CACHE = DERIVED_DIR / 'run_summary.pkl'\n",
    "ERROR_LOG_CACHE = DERIVED_DIR / 'run_summary_errors.json'\n",
    "\n",
    "assert DATA_ROOT.exists(), f\"Expected BCI 2a files under {DATA_ROOT.as_posix()}\"\n",
    "GDF_FILES = sorted(DATA_ROOT.glob('A??[TE].gdf'))\n",
    "print(f'Detected {len(GDF_FILES)} GDF sessions')\n",
    "GDF_FILES[:6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84231427",
   "metadata": {},
   "source": [
    "\n",
    "## Session metadata reference\n",
    "- Subjects: A01-A09 (9 participants)\n",
    "- Session suffix T = training (with labels); E = evaluation\n",
    "- Events of interest (training):\n",
    "  - 769: cue onset (left hand)\n",
    "  - 770: cue onset (right hand)\n",
    "  - 771: cue onset (feet)\n",
    "  - 772: cue onset (tongue)\n",
    "  - 783: start of trial\n",
    "  - 1023/1024/1025/1026: artifact/feedback markers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fde246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SESSION_METADATA = pd.DataFrame({\n",
    "    'code': ['T', 'E'],\n",
    "    'description': ['Training (labelled)', 'Evaluation (unlabelled)']\n",
    "})\n",
    "SESSION_METADATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05320c33",
   "metadata": {},
   "source": [
    "\n",
    "## Inventory check\n",
    "Build a matrix of available sessions per subject and identify missing files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = sorted({path.stem[:3] for path in GDF_FILES})\n",
    "inventory_records = []\n",
    "for subject in subjects:\n",
    "    for session_code in ['T', 'E']:\n",
    "        file_path = DATA_ROOT / f\"{subject}{session_code}.gdf\"\n",
    "        inventory_records.append({\n",
    "            'subject': subject,\n",
    "            'session': session_code,\n",
    "            'available': file_path.exists(),\n",
    "            'file': file_path if file_path.exists() else None\n",
    "        })\n",
    "\n",
    "inventory_df = pd.DataFrame(inventory_records)\n",
    "\n",
    "print('Missing sessions:', inventory_df.loc[~inventory_df['available'], 'session'].count())\n",
    "inventory_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1774f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inv_matrix = (inventory_df.assign(present=lambda df: df['available'].astype(int))\n",
    "                            .pivot(index='subject', columns='session', values='present')\n",
    "                            .fillna(0))\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(inv_matrix, cmap='Greens', annot=True, cbar=False)\n",
    "plt.title('Session availability per subject (1 = present)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be658af6",
   "metadata": {},
   "source": [
    "\n",
    "### Helper utilities for session-level metrics\n",
    "Summaries include amplitude stats, clipping, spectral features, and event counts. Cached outputs prevent repeated heavy computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a93dab",
   "metadata": {},
   "outputs": [],
   "source": "import warnings\nfrom typing import Dict, Any\n\nEEG_DECIM_FOR_STATS = 4\nTARGET_PSD_SFREQ = 125.0\nFLAT_STD_THRESHOLD_UV = 0.25\nNOISY_STD_THRESHOLD_UV = 150.0\nCLIP_THRESHOLD_UV = 200.0\n\nBAND_DEFS = {\n    'delta': (1.0, 4.0),\n    'theta': (4.0, 8.0),\n    'alpha': (8.0, 13.0),\n    'beta': (13.0, 30.0),\n    'gamma': (30.0, 45.0),\n}\n\nEVENT_ID_MAP = {\n    769: 'left_hand',\n    770: 'right_hand',\n    771: 'feet',\n    772: 'tongue',\n    783: 'start_trial',\n}\n\n@lru_cache(maxsize=64)\ndef _load_raw_cache(gdf_path: str) -> mne.io.BaseRaw:\n    raw = mne.io.read_raw_gdf(gdf_path, preload=True, verbose='ERROR')\n    picks = mne.pick_types(raw.info, eeg=True)\n    raw.pick(picks)\n    raw.set_montage('standard_1020', on_missing='ignore', match_case=False)\n    return raw\n\n\ndef summarize_session(gdf_path: Path) -> Dict[str, Any]:\n    gdf_path = Path(gdf_path)\n    subject_id = gdf_path.stem[:3]\n    session_code = gdf_path.stem[3]\n\n    raw = _load_raw_cache(str(gdf_path))\n    raw_copy = raw.copy()\n\n    sfreq = float(raw_copy.info['sfreq'])\n    eeg_names = raw_copy.ch_names\n\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore', category=RuntimeWarning)\n        data_full = raw_copy.get_data()\n    data_uv = data_full[:, ::EEG_DECIM_FOR_STATS] * 1e6\n\n    channel_std = data_uv.std(axis=1)\n    channel_ptp = data_uv.ptp(axis=1)\n\n    flat_channels = [name for name, std in zip(eeg_names, channel_std) if std < FLAT_STD_THRESHOLD_UV]\n    noisy_channels = [name for name, std in zip(eeg_names, channel_std) if std > NOISY_STD_THRESHOLD_UV]\n    clip_fraction = float((np.abs(data_uv) > CLIP_THRESHOLD_UV).mean())\n\n    events, event_id = mne.events_from_annotations(raw_copy, verbose='ERROR')\n    event_counts = {}\n    for code, label in EVENT_ID_MAP.items():\n        count = int((events[:, 2] == code).sum())\n        event_counts[label] = count\n\n    psd_raw = raw_copy.copy()\n    if abs(sfreq - TARGET_PSD_SFREQ) > 1e-6:\n        psd_raw.resample(TARGET_PSD_SFREQ, npad='auto')\n    \n    psd_sfreq = psd_raw.info['sfreq']\n    nyquist = psd_sfreq / 2.0\n    fmax_psd = min(60.0, nyquist - 1.0)\n    \n    psd = psd_raw.compute_psd(method='welch', fmin=1.0, fmax=fmax_psd, n_fft=512,\n                              n_overlap=256, verbose='ERROR')\n    psd_data = psd.get_data()\n    freqs = psd.freqs\n    total_mask = (freqs >= 1.0) & (freqs <= 45.0)\n    total_power = psd_data[:, total_mask].sum(axis=1)\n    total_power[total_power == 0] = np.nan\n\n    band_features = {}\n    for band, (fmin, fmax) in BAND_DEFS.items():\n        mask = (freqs >= fmin) & (freqs < fmax)\n        band_power = psd_data[:, mask].sum(axis=1)\n        band_ratio = band_power / total_power\n        band_features[f'band_{band}_rel_power_mean'] = float(np.nanmean(band_ratio))\n        band_features[f'band_{band}_rel_power_std'] = float(np.nanstd(band_ratio))\n\n    line_mask = (freqs >= 48.0) & (freqs <= 52.0)\n    beta_mask = (freqs >= 13.0) & (freqs <= 30.0)\n    line_power = float(np.nanmean(psd_data[:, line_mask])) if np.any(line_mask) else np.nan\n    beta_power = float(np.nanmean(psd_data[:, beta_mask])) if np.any(beta_mask) else np.nan\n    line_noise_ratio = float(line_power / beta_power) if beta_power and beta_power > 0 else np.nan\n\n    summary = {\n        'subject': subject_id,\n        'session': session_code,\n        'sfreq': sfreq,\n        'n_channels': len(eeg_names),\n        'duration_s': float(raw_copy.times[-1]),\n        'mean_channel_std_uv': float(np.mean(channel_std)),\n        'median_channel_std_uv': float(np.median(channel_std)),\n        'p90_channel_std_uv': float(np.percentile(channel_std, 90)),\n        'max_channel_std_uv': float(np.max(channel_std)),\n        'p95_channel_ptp_uv': float(np.percentile(channel_ptp, 95)),\n        'max_channel_ptp_uv': float(np.max(channel_ptp)),\n        'clip_fraction_over_200uv': clip_fraction,\n        'max_abs_signal_uv': float(np.max(np.abs(data_uv))),\n        'flat_channel_count': len(flat_channels),\n        'noisy_channel_count': len(noisy_channels),\n        'flat_channels': flat_channels,\n        'noisy_channels': noisy_channels,\n        'events_total': int(events.shape[0]),\n    }\n    summary.update(event_counts)\n    summary.update(band_features)\n    summary['line_noise_ratio'] = line_noise_ratio\n    summary['cache_key'] = str(gdf_path.relative_to(DATA_ROOT.parent))\n    return summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_run_summary(subject_subset=None, force_recompute=False):\n",
    "    subject_list = subjects if subject_subset is None else list(subject_subset)\n",
    "    if RUN_SUMMARY_CACHE.exists() and not force_recompute:\n",
    "        run_df = pd.read_pickle(RUN_SUMMARY_CACHE)\n",
    "        error_df = pd.read_json(ERROR_LOG_CACHE) if ERROR_LOG_CACHE.exists() else pd.DataFrame()\n",
    "        if not run_df.empty and 'subject' in run_df.columns:\n",
    "            existing_subjects = set(run_df['subject'].unique())\n",
    "            if set(subject_list).issubset(existing_subjects):\n",
    "                print('Loaded cached summaries from disk')\n",
    "                return run_df[run_df['subject'].isin(subject_list)].reset_index(drop=True), error_df\n",
    "        print('Cached summary incomplete or empty - recomputing')\n",
    "\n",
    "    records = []\n",
    "    errors = []\n",
    "    for subject in tqdm(subject_list, desc='Summarising sessions'):\n",
    "        for session_code in ['T', 'E']:\n",
    "            gdf_path = DATA_ROOT / f\"{subject}{session_code}.gdf\"\n",
    "            if not gdf_path.exists():\n",
    "                continue\n",
    "            try:\n",
    "                records.append(summarize_session(gdf_path))\n",
    "            except Exception as exc:\n",
    "                errors.append({\n",
    "                    'subject': subject,\n",
    "                    'session': session_code,\n",
    "                    'file': str(gdf_path),\n",
    "                    'error': repr(exc)\n",
    "                })\n",
    "    run_df = pd.DataFrame(records)\n",
    "    error_df = pd.DataFrame(errors)\n",
    "    if subject_subset is None:\n",
    "        run_df.to_pickle(RUN_SUMMARY_CACHE)\n",
    "        error_df.to_json(ERROR_LOG_CACHE, orient='records', indent=2)\n",
    "        print(f'Persisted run summary cache to {RUN_SUMMARY_CACHE}')\n",
    "    return run_df, error_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b346b9",
   "metadata": {},
   "source": [
    "\n",
    "### Build or load session-level summaries\n",
    "Set SUBJECT_FILTER to work on a smaller subset while iterating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcd480",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUBJECT_FILTER = None  # e.g. ['A01', 'A02']\n",
    "RUN_DF, ERROR_DF = build_run_summary(subject_subset=SUBJECT_FILTER, force_recompute=False)\n",
    "if RUN_DF.empty:\n",
    "    RUN_DF, ERROR_DF = build_run_summary(subject_subset=SUBJECT_FILTER, force_recompute=True)\n",
    "RUN_DF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "41k545a0qat",
   "source": "if RUN_SUMMARY_CACHE.exists():\n    RUN_SUMMARY_CACHE.unlink()\n    print(f'Deleted cached summary: {RUN_SUMMARY_CACHE}')\nif ERROR_LOG_CACHE.exists():\n    ERROR_LOG_CACHE.unlink()\n    print(f'Deleted error log: {ERROR_LOG_CACHE}')\nprint('Cache cleared. Will force recomputation.')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9848e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Sessions processed: {len(RUN_DF)}')\n",
    "if not ERROR_DF.empty:\n",
    "    display(ERROR_DF)\n",
    "else:\n",
    "    print('No read errors encountered')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8726f",
   "metadata": {},
   "source": [
    "\n",
    "## Event distribution\n",
    "Check cue counts per session and the balance across subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cue_cols = ['left_hand', 'right_hand', 'feet', 'tongue']\n",
    "available_cues = [col for col in cue_cols if col in RUN_DF.columns]\n",
    "trial_summary = (RUN_DF[['subject', 'session'] + available_cues]\n",
    "                 .fillna(0)\n",
    "                 .set_index(['subject', 'session'])\n",
    "                 .astype(int))\n",
    "trial_summary.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960352a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trial_long = RUN_DF.melt(id_vars=['subject', 'session'],\n",
    "                         value_vars=available_cues,\n",
    "                         var_name='cue', value_name='count').dropna()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=trial_long, x='cue', y='count', hue='session')\n",
    "plt.title('Cue count distribution by session type')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6472232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot_counts = (RUN_DF.pivot_table(index='subject', columns='session', values='events_total', aggfunc='sum')\n",
    "                       .fillna(0))\n",
    "fig = px.imshow(pivot_counts, labels=dict(color='Events'), color_continuous_scale='Viridis',\n",
    "                title='Total events per subject/session')\n",
    "fig.update_layout(height=400)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873993b",
   "metadata": {},
   "source": [
    "\n",
    "## Signal amplitude and stability\n",
    "Assess flat or noisy channels and clipping behaviour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN_DF['has_flat_issue'] = RUN_DF['flat_channel_count'] > 0\n",
    "RUN_DF['has_noisy_issue'] = RUN_DF['noisy_channel_count'] > 0\n",
    "RUN_DF['amp_issue_flag'] = (\n",
    "    RUN_DF['has_flat_issue'] |\n",
    "    RUN_DF['has_noisy_issue'] |\n",
    "    (RUN_DF['mean_channel_std_uv'] < 1.0) |\n",
    "    (RUN_DF['mean_channel_std_uv'] > 80.0) |\n",
    "    (RUN_DF['clip_fraction_over_200uv'] > 0.01)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=RUN_DF,\n",
    "                x='mean_channel_std_uv', y='clip_fraction_over_200uv',\n",
    "                hue='amp_issue_flag', style='session')\n",
    "plt.axvline(1.0, linestyle='--', color='grey', linewidth=1)\n",
    "plt.axvline(80.0, linestyle='--', color='grey', linewidth=1)\n",
    "plt.axhline(0.01, linestyle='--', color='grey', linewidth=1)\n",
    "plt.title('Mean channel stdev vs clipping fraction (BCI 2a)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d77a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.box(RUN_DF, x='session', y='mean_channel_std_uv', color='session', title='Channel variance by session')\n",
    "fig.update_traces(notched=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edad07",
   "metadata": {},
   "source": [
    "\n",
    "## Frequency-domain characteristics\n",
    "Inspect relative band power distributions and line noise levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "band_cols = [col for col in RUN_DF.columns if col.startswith('band_') and col.endswith('_mean')]\n",
    "band_long = RUN_DF.melt(id_vars=['subject', 'session'],\n",
    "                        value_vars=band_cols,\n",
    "                        var_name='band', value_name='relative_power').dropna()\n",
    "band_long['band'] = band_long['band'].str.replace('band_', '').str.replace('_rel_power_mean', '')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=band_long, x='band', y='relative_power', hue='session', split=True)\n",
    "plt.title('Relative band power distribution by session type')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(RUN_DF,\n",
    "                 x='line_noise_ratio', y='band_alpha_rel_power_mean',\n",
    "                 color='session', symbol='amp_issue_flag',\n",
    "                 hover_data=['subject'],\n",
    "                 title='Line noise vs alpha power (BCI 2a)')\n",
    "fig.add_vline(x=1.5, line_dash='dash', line_color='red', annotation_text='line/noise threshold')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce601724",
   "metadata": {},
   "source": [
    "\n",
    "### Example topography\n",
    "Display alpha band power for a representative clean session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e4988",
   "metadata": {},
   "outputs": [],
   "source": "from mne.viz import plot_topomap\n\nexample_row = RUN_DF.sort_values('band_alpha_rel_power_mean', ascending=False).iloc[0]\nexample_path = DATA_ROOT / f\"{example_row['subject']}{example_row['session']}.gdf\"\nexample_raw = _load_raw_cache(str(example_path)).copy()\nif abs(example_row['sfreq'] - TARGET_PSD_SFREQ) > 1e-6:\n    example_raw.resample(TARGET_PSD_SFREQ, npad='auto')\n\nexample_sfreq = example_raw.info['sfreq']\nexample_nyquist = example_sfreq / 2.0\nexample_fmax = min(45.0, example_nyquist - 1.0)\n\npsd = example_raw.compute_psd(method='welch', fmin=1.0, fmax=example_fmax, n_fft=512,\n                              n_overlap=256, verbose='ERROR')\nfreqs = psd.freqs\ndata = psd.get_data()\nalpha_mask = (freqs >= 8.0) & (freqs <= 13.0)\nalpha_power = data[:, alpha_mask].mean(axis=1)\nfig, ax = plt.subplots(figsize=(5, 5))\nplot_topomap(alpha_power, example_raw.info, axes=ax, show=False, cmap='viridis')\nax.set_title(f\"Alpha power topography - {example_row['subject']} {example_row['session']}\")\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "36558a01",
   "metadata": {},
   "source": [
    "\n",
    "## Subject-level health summary\n",
    "Aggregate session metrics to flag persistent issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "numeric_cols = [\n",
    "    'mean_channel_std_uv', 'median_channel_std_uv', 'p90_channel_std_uv',\n",
    "    'max_channel_std_uv', 'p95_channel_ptp_uv', 'max_channel_ptp_uv',\n",
    "    'clip_fraction_over_200uv', 'max_abs_signal_uv', 'line_noise_ratio',\n",
    "    'band_alpha_rel_power_mean', 'band_beta_rel_power_mean', 'band_theta_rel_power_mean'\n",
    "]\n",
    "\n",
    "z_df = RUN_DF[['subject', 'session'] + numeric_cols].dropna()\n",
    "z_scores = z_df[numeric_cols].apply(zscore, nan_policy='omit')\n",
    "z_df = z_df.assign(max_abs_z=np.abs(z_scores).max(axis=1))\n",
    "RUN_DF = RUN_DF.merge(z_df[['subject', 'session', 'max_abs_z']], on=['subject', 'session'], how='left')\n",
    "RUN_DF['zscore_flag'] = RUN_DF['max_abs_z'] > 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_summary = (\n",
    "    RUN_DF.groupby('subject').agg({\n",
    "        'session': 'nunique',\n",
    "        'duration_s': 'sum',\n",
    "        'events_total': 'sum',\n",
    "        'left_hand': 'sum',\n",
    "        'right_hand': 'sum',\n",
    "        'feet': 'sum',\n",
    "        'tongue': 'sum',\n",
    "        'mean_channel_std_uv': ['median', 'min', 'max'],\n",
    "        'clip_fraction_over_200uv': ['mean', 'max'],\n",
    "        'line_noise_ratio': ['median', 'max'],\n",
    "        'flat_channel_count': lambda s: int((s > 0).sum()),\n",
    "        'noisy_channel_count': lambda s: int((s > 0).sum()),\n",
    "        'amp_issue_flag': 'sum',\n",
    "        'zscore_flag': 'sum'\n",
    "    })\n",
    ")\n",
    "subject_summary.columns = ['_'.join(filter(None, col)).strip('_') for col in subject_summary.columns]\n",
    "subject_summary = subject_summary.rename(columns={\n",
    "    'session_nunique': 'sessions_available',\n",
    "    'duration_s_sum': 'total_duration_s',\n",
    "    'events_total_sum': 'total_events',\n",
    "    'left_hand_sum': 'total_left',\n",
    "    'right_hand_sum': 'total_right',\n",
    "    'feet_sum': 'total_feet',\n",
    "    'tongue_sum': 'total_tongue',\n",
    "    'mean_channel_std_uv_median': 'median_mean_std_uv',\n",
    "    'mean_channel_std_uv_min': 'min_mean_std_uv',\n",
    "    'mean_channel_std_uv_max': 'max_mean_std_uv',\n",
    "    'clip_fraction_over_200uv_mean': 'avg_clip_fraction',\n",
    "    'clip_fraction_over_200uv_max': 'max_clip_fraction',\n",
    "    'line_noise_ratio_median': 'median_line_noise_ratio',\n",
    "    'line_noise_ratio_max': 'max_line_noise_ratio',\n",
    "    'flat_channel_count_<lambda>': 'sessions_with_flat_channels',\n",
    "    'noisy_channel_count_<lambda>': 'sessions_with_noisy_channels',\n",
    "    'amp_issue_flag_sum': 'sessions_with_amp_issue',\n",
    "    'zscore_flag_sum': 'sessions_with_zscore_outlier'\n",
    "})\n",
    "subject_summary['suspect_subject'] = (\n",
    "    (subject_summary['sessions_with_amp_issue'] > 0) |\n",
    "    (subject_summary['sessions_with_zscore_outlier'] > 0) |\n",
    "    (subject_summary['max_clip_fraction'] > 0.05) |\n",
    "    (subject_summary['median_line_noise_ratio'] > 1.5)\n",
    ")\n",
    "subject_summary.sort_values('sessions_with_amp_issue', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(subject_summary.reset_index(),\n",
    "                 x='median_mean_std_uv', y='median_line_noise_ratio',\n",
    "                 size='sessions_with_amp_issue', color='suspect_subject',\n",
    "                 hover_data=['subject', 'avg_clip_fraction'],\n",
    "                 title='Subject-level signal health overview (BCI 2a)')\n",
    "fig.add_hline(y=1.5, line_dash='dash', line_color='red')\n",
    "fig.add_vline(x=4.0, line_dash='dash', line_color='grey')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412a411",
   "metadata": {},
   "source": [
    "\n",
    "## Interactive session explorer\n",
    "Interactively inspect channel waveforms for a given subject and session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ec3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_session_timeseries(subject_id: str, session_code: str, seconds: float = 8.0, channels=None):\n",
    "    gdf_path = DATA_ROOT / f\"{subject_id}{session_code}.gdf\"\n",
    "    if not gdf_path.exists():\n",
    "        raise FileNotFoundError(gdf_path)\n",
    "    raw = _load_raw_cache(str(gdf_path)).copy().load_data()\n",
    "    if channels is None:\n",
    "        channels = ['C3', 'Cz', 'C4', 'Pz']\n",
    "    available = [ch for ch in channels if ch in raw.ch_names]\n",
    "    data = raw.copy().pick_channels(available)\n",
    "    sfreq = data.info['sfreq']\n",
    "    stop = int(min(seconds * sfreq, data.n_times))\n",
    "    array = data.get_data(stop=stop) * 1e6\n",
    "    time = np.arange(stop) / sfreq\n",
    "    df = pd.DataFrame({\n",
    "        'time_s': np.tile(time, len(available)),\n",
    "        'channel': np.repeat(available, stop),\n",
    "        'amplitude_uV': array.reshape(len(available) * stop)\n",
    "    })\n",
    "    fig = px.line(df, x='time_s', y='amplitude_uV', color='channel',\n",
    "                  title=f'{subject_id}{session_code} - first {seconds} s')\n",
    "    fig.update_layout(xaxis_title='Time (s)', yaxis_title='Amplitude (uV)')\n",
    "    fig.show()\n",
    "\n",
    "plot_session_timeseries('A01', 'T', seconds=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513727d",
   "metadata": {},
   "source": [
    "\n",
    "## Export artefact flags for downstream modelling\n",
    "Save session- and subject-level reports for filtering before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN_REPORT_PATH = DERIVED_DIR / 'bci2a_run_summary.csv'\n",
    "SUBJECT_REPORT_PATH = DERIVED_DIR / 'bci2a_subject_summary.csv'\n",
    "\n",
    "RUN_DF.sort_values(['subject', 'session']).to_csv(RUN_REPORT_PATH, index=False)\n",
    "subject_summary.sort_values('suspect_subject', ascending=False).to_csv(SUBJECT_REPORT_PATH)\n",
    "print(f'Exported session summary -> {RUN_REPORT_PATH}')\n",
    "print(f'Exported subject summary -> {SUBJECT_REPORT_PATH}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6ba26",
   "metadata": {},
   "source": [
    "\n",
    "## Next steps\n",
    "- Filter RUN_DF by \u0007mp_issue_flag or cue counts to select clean sessions.\n",
    "- Use the subject-level summary to exclude problematic participants before per-person model training.\n",
    "- Extend the analysis with ERD/ERS visualisations or connectivity metrics for channel selection.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}