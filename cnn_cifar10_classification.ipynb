{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for CIFAR-10 Image Classification\n",
    "\n",
    "This notebook implements Convolutional Neural Networks (CNNs) for image classification using the CIFAR-10 dataset.\n",
    "\n",
    "## Learning Objectives:\n",
    "- Understand CNN architecture (convolution, pooling, fully connected layers)\n",
    "- Learn about feature maps and filters\n",
    "- Implement data augmentation\n",
    "- Visualize CNN features and training progress\n",
    "- Compare different CNN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 1: Import libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and explore CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Pixel value range: {x_train.min()} to {x_train.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Visualize sample images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(f'{class_names[y_train[i][0]]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Sample CIFAR-10 Images', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show class distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar([class_names[i] for i in unique], counts)\n",
    "plt.title('CIFAR-10 Training Data Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data preprocessing\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Normalized training data shape: {x_train_norm.shape}\")\n",
    "print(f\"Categorical labels shape: {y_train_cat.shape}\")\n",
    "print(f\"Pixel value range after normalization: {x_train_norm.min()} to {x_train_norm.max()}\")\n",
    "print(f\"Sample label before: {y_train[0]}, after: {y_train_cat[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Simple CNN model\n",
    "def create_simple_cnn():\n",
    "    model = models.Sequential([\n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "simple_cnn = create_simple_cnn()\n",
    "simple_cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train the simple CNN\n",
    "print(\"Training Simple CNN...\")\n",
    "history_simple = simple_cnn.fit(\n",
    "    x_train_norm, y_train_cat,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = simple_cnn.evaluate(x_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"\\nSimple CNN Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Improved CNN with data augmentation\n",
    "def create_improved_cnn():\n",
    "    model = models.Sequential([\n",
    "        # Data augmentation layers\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        \n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile improved model\n",
    "improved_cnn = create_improved_cnn()\n",
    "improved_cnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "improved_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Train improved CNN with callbacks\n",
    "# Define callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.0001\n",
    ")\n",
    "\n",
    "print(\"Training Improved CNN with data augmentation...\")\n",
    "history_improved = improved_cnn.fit(\n",
    "    x_train_norm, y_train_cat,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate improved model\n",
    "test_loss_improved, test_accuracy_improved = improved_cnn.evaluate(x_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"\\nImproved CNN Test Accuracy: {test_accuracy_improved:.4f} ({test_accuracy_improved*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Compare training histories\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training accuracy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history_simple.history['accuracy'], label='Simple CNN Train')\n",
    "plt.plot(history_simple.history['val_accuracy'], label='Simple CNN Val')\n",
    "plt.plot(history_improved.history['accuracy'], label='Improved CNN Train')\n",
    "plt.plot(history_improved.history['val_accuracy'], label='Improved CNN Val')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Training loss\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history_simple.history['loss'], label='Simple CNN Train')\n",
    "plt.plot(history_simple.history['val_loss'], label='Simple CNN Val')\n",
    "plt.plot(history_improved.history['loss'], label='Improved CNN Train')\n",
    "plt.plot(history_improved.history['val_loss'], label='Improved CNN Val')\n",
    "plt.title('Model Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Final accuracy comparison\n",
    "plt.subplot(1, 3, 3)\n",
    "models_comparison = ['Simple CNN', 'Improved CNN']\n",
    "accuracies = [test_accuracy, test_accuracy_improved]\n",
    "plt.bar(models_comparison, accuracies, color=['lightblue', 'lightgreen'])\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Visualize CNN filters and feature maps\n",
    "def visualize_filters(model, layer_name, num_filters=8):\n",
    "    # Get the weights of the specified layer\n",
    "    layer = None\n",
    "    for l in model.layers:\n",
    "        if l.name == layer_name:\n",
    "            layer = l\n",
    "            break\n",
    "    \n",
    "    if layer is None:\n",
    "        print(f\"Layer {layer_name} not found\")\n",
    "        return\n",
    "    \n",
    "    weights = layer.get_weights()[0]\n",
    "    \n",
    "    # Normalize weights for visualization\n",
    "    weights = (weights - weights.min()) / (weights.max() - weights.min())\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(min(num_filters, weights.shape[3])):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(weights[:, :, 0, i], cmap='viridis')\n",
    "        plt.title(f'Filter {i+1}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Filters from {layer_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize filters from the first conv layer\n",
    "visualize_filters(simple_cnn, 'conv2d', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Visualize feature maps\n",
    "def visualize_feature_maps(model, image, layer_names):\n",
    "    # Create a model that outputs feature maps\n",
    "    layer_outputs = []\n",
    "    for layer_name in layer_names:\n",
    "        for layer in model.layers:\n",
    "            if layer.name == layer_name:\n",
    "                layer_outputs.append(layer.output)\n",
    "                break\n",
    "    \n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Get activations\n",
    "    activations = activation_model.predict(image[np.newaxis, ...])\n",
    "    \n",
    "    # Plot feature maps\n",
    "    for i, (layer_name, activation) in enumerate(zip(layer_names, activations)):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Show first 16 feature maps\n",
    "        for j in range(min(16, activation.shape[-1])):\n",
    "            plt.subplot(4, 4, j + 1)\n",
    "            plt.imshow(activation[0, :, :, j], cmap='viridis')\n",
    "            plt.title(f'Feature Map {j+1}')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Feature Maps from {layer_name}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Select a test image\n",
    "test_image = x_test_norm[0]\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(test_image)\n",
    "plt.title(f'Test Image: {class_names[y_test[0][0]]}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature maps from different layers\n",
    "layer_names = ['conv2d', 'conv2d_1']  # First two conv layers\n",
    "visualize_feature_maps(simple_cnn, test_image, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Detailed evaluation and confusion matrix\n",
    "# Get predictions\n",
    "y_pred_simple = simple_cnn.predict(x_test_norm)\n",
    "y_pred_improved = improved_cnn.predict(x_test_norm)\n",
    "\n",
    "# Convert to class labels\n",
    "y_pred_simple_labels = np.argmax(y_pred_simple, axis=1)\n",
    "y_pred_improved_labels = np.argmax(y_pred_improved, axis=1)\n",
    "y_test_labels = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "# Confusion matrices\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cm_simple = confusion_matrix(y_test_labels, y_pred_simple_labels)\n",
    "sns.heatmap(cm_simple, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Simple CNN Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_improved = confusion_matrix(y_test_labels, y_pred_improved_labels)\n",
    "sns.heatmap(cm_improved, annot=True, fmt='d', cmap='Greens',\n",
    "           xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Improved CNN Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification reports\n",
    "print(\"Simple CNN Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred_simple_labels, target_names=class_names))\n",
    "\n",
    "print(\"\\nImproved CNN Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred_improved_labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Analyze misclassified images\n",
    "def show_misclassified_images(model, x_test, y_test, class_names, num_images=12):\n",
    "    predictions = model.predict(x_test)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    true_labels = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Find misclassified images\n",
    "    misclassified_indices = np.where(predicted_labels != true_labels)[0]\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(min(num_images, len(misclassified_indices))):\n",
    "        idx = misclassified_indices[i]\n",
    "        \n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(x_test[idx])\n",
    "        plt.title(f'True: {class_names[true_labels[idx]]}\\n'\n",
    "                 f'Pred: {class_names[predicted_labels[idx]]}\\n'\n",
    "                 f'Conf: {predictions[idx][predicted_labels[idx]]:.2f}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Misclassified Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Misclassified images from Improved CNN:\")\n",
    "show_misclassified_images(improved_cnn, x_test_norm, y_test_cat, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Model performance summary\n",
    "print(\"=== CNN CIFAR-10 Classification Results ===\")\n",
    "print(f\"Dataset: {x_train.shape[0]:,} training, {x_test.shape[0]:,} test images\")\n",
    "print(f\"Image size: {x_train.shape[1]}x{x_train.shape[2]}x{x_train.shape[3]}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print()\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Simple CNN:   {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Improved CNN: {test_accuracy_improved:.4f} ({test_accuracy_improved*100:.2f}%)\")\n",
    "print(f\"Improvement:  {test_accuracy_improved - test_accuracy:.4f} ({(test_accuracy_improved - test_accuracy)*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "print(\"Key CNN Concepts Learned:\")\n",
    "print(\"✅ Convolutional layers for feature extraction\")\n",
    "print(\"✅ Pooling layers for spatial dimension reduction\")\n",
    "print(\"✅ Data augmentation for improved generalization\")\n",
    "print(\"✅ Batch normalization and dropout for regularization\")\n",
    "print(\"✅ Filter and feature map visualization\")\n",
    "print(\"✅ Model comparison and evaluation\")\n",
    "print()\n",
    "\n",
    "print(\"Next Steps:\")\n",
    "print(\"- Try transfer learning with pre-trained models (VGG, ResNet)\")\n",
    "print(\"- Experiment with different architectures\")\n",
    "print(\"- Move to larger datasets (ImageNet)\")\n",
    "print(\"- Learn about RNNs for sequential data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
